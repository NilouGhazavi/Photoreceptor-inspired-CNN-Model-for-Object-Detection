{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3ACokReIJDaQO7QoKe29a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NilouGhazavi/Photoreceptor-inspired-CNN-Model-for-Object-Detection/blob/main/PR_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2OJ_U_uX9ps"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlJYW4oPfQGb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import random as random\n",
        "import matplotlib.animation as animation\n",
        "import pandas as pd\n",
        "from random import sample\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.python.keras.utils.data_utils import Sequence\n",
        "from tensorflow.keras.layers import Input, InputLayer\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import Model, regularizers, Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Conv3D, Dense, Activation, Flatten, Reshape, MaxPool3D, MaxPool2D, Permute, BatchNormalization, GaussianNoise,DepthwiseConv2D, Dropout, LayerNormalization\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "import math\n",
        "import sys\n",
        "\n",
        "\n",
        "\n",
        "digit_max=10\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Dataset generating functions (Ines)\n",
        "\n",
        "\n",
        "def generate_frames_dataset(digits_set, labels_set, n_digits=5, n_frames=1000, \n",
        "                            upsample=True, frame_size=280, \n",
        "                            downsample=False, pool_size=7, strides=7, final_size=4, \n",
        "                            movie=False, duration=5, \n",
        "                            perturbations = False, perturbations_time=\"random\", perturbations_duration=2, half=False,\n",
        "                            spot_proba = 1, spot_factor=100, shadow_factor=0.5,\n",
        "                           digit_max = 10):\n",
        "    \n",
        "    \"\"\"Generates a dataset of frames with n_digits, with variable frame_size, and possibilitiy to downsample, or movies (with identical frames) if movie=True. Adds light perturbations if perturbations=True, that can be 2 frames long homogenous or half frame light or shadow, at a specific time or random time. \n",
        "    \n",
        "    Args:\n",
        "    digits_set: np.array of MNIST digits\n",
        "    labels_set: np.array of int type corresponding to the labels\n",
        "    n_digits: int\n",
        "    n_frames: int\n",
        "    upsample; bool, True or False\n",
        "    frame_size: if upsample, size of the frame after the upsampling, before the downsampling\n",
        "    downsample: bool, True or False\n",
        "    pool_size: int, if downsample\n",
        "    strides: int, if downsample\n",
        "    final_size: int\n",
        "    movie: bool, True or False\n",
        "    duration: int, if movie\n",
        "    perturbations: bool, whether to add spotlights and shadows\n",
        "    perturbations_time: str or int, when to start the 2-frames long perturbations\n",
        "    half: bool, whether to add the perturbations on only half of the frame (if False : homogeneous perturbation)\n",
        "    spot_proba: float, between 0 and 1, probability that the perturbation is a spotlight (0.5 if you want equiprobable spotlights and shadows)\n",
        "    spot_factor: float, by how much to multiply the light intensity\n",
        "    shadow_factor: float, but how much to multiply the light intensity as well ( < 1 )\n",
        "    digit_max: maximum of the classes labels, by default 10. Can be less, if you only want to work with some of the classes, and reduce the MNIST dataset you use.\n",
        "   \n",
        "    Returns:\n",
        "    dataset: np.array of frames (n_frames, final_size, final_size) or movies (n_frames, final_size, final_size, duration)\n",
        "    labels_set: np.array of set of digit_max frames, corresponding to the labels for each class (n_frames, final_size, final_size, digit_max+1)\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    digit_shape = np.shape(digits_set[0])\n",
        "    \n",
        "    digit_max = len(list(set(labels_set)))\n",
        "    frames = []\n",
        "    labels = []\n",
        "    \t\n",
        "    \t\n",
        "    if upsample:\n",
        "        \n",
        "        for i in range(n_frames):\n",
        "        \n",
        "            frame = np.zeros((frame_size, frame_size), dtype=\"float32\")\n",
        "            label = [np.zeros((frame_size, frame_size), dtype=\"float32\" ) for i in range(digit_max)]  #build empty frames and labels\n",
        "\n",
        "\n",
        "            indexes = random.sample(range(len(digits_set)), n_digits)  #select the MNIST digits, and get the corresponding labels\n",
        "            digits = digits_set[indexes]\n",
        "            digits_labels = labels_set[indexes]\n",
        "\n",
        "            positions = [random.sample(range(frame_size-digit_shape[0]-1),2) for i in range(n_digits)]  #choose the position of the digits\n",
        "            background = np.ones((frame_size, frame_size), dtype=\"float32\")\n",
        "\n",
        "            if downsample :\n",
        "                \n",
        "                new_frame_size, new_digits, new_positions = little_downsample(frame_size, digits, positions, pool_size, strides)\n",
        "                #computing the downsampled positions and digits\n",
        "                frame, label = create_frame_and_labels(new_frame_size, new_digits, digits_labels, new_positions, digit_max)\n",
        "            \n",
        "            else:\n",
        "                \n",
        "                frame, label = create_frame_and_labels(frame_size, digits, digits_labels, positions, digit_max)\n",
        "            \n",
        "            if movie:\n",
        "            \n",
        "            \tframe = [frame for i in range(duration)]  #making a movie out of identical frames\n",
        "            \t\n",
        "            \tif perturbations:  #adding spotlights and shadows\n",
        "            \t\n",
        "            \t\tframe = add_perturbations(frame, half, spot_proba, spot_factor, shadow_factor, perturbations_time, movie_duration, final_size)\n",
        "\n",
        "            labels.append(label)\n",
        "            frames.append(frame)\n",
        "        \n",
        "    else:  #if not upsampled\n",
        "    \n",
        "        for i in range(n_frames):\n",
        "\n",
        "            n = random.randint(0,len(digits_set)-1)\n",
        "\n",
        "            digit_label = labels_set[n]\n",
        "            \n",
        "            frame = digits_set[n]\n",
        "            label = label_mnist(frame, digit_label, digit_max)\n",
        "\n",
        "            \n",
        "            if downsample:\n",
        "                \n",
        "                new_frame_size, new_digits, new_positions = little_downsample(frame_size, [frame], [[0,0]], pool_size, strides)\n",
        "                frame, label = create_frame_and_labels(new_frame_size, new_digits, [digit_label], new_positions, digit_max)\n",
        "\n",
        "            \n",
        "            if movie:\n",
        "            \n",
        "            \tframe = [frame for i in range(duration)]\n",
        "\n",
        "            \tif perturbations:\n",
        "            \t\n",
        "            \t\tframe = add_perturbations(frame, half, spot_proba, spot_factor, shadow_factor, perturbations_time, perturbations_duration, duration)\n",
        "\t\t\t\t\n",
        "            labels.append(label)\n",
        "            frames.append(frame)\n",
        "            \n",
        "    dataset = np.array(frames)\n",
        "    labels_set = np.array(labels)\n",
        "\n",
        "    #getting the dimensions right for the model\n",
        "    if not movie:\n",
        "        dataset = dataset[:,:,:,None]\n",
        "        labels_set = np.transpose(labels_set, (0,2,3,1))\n",
        "    \n",
        "\n",
        "    dataset = np.transpose(dataset, (0,2,3,1))\n",
        "    labels_set = np.transpose(labels_set, (0,2,3,1))\n",
        "    \n",
        "    return dataset, labels_set\n",
        " \n",
        " \n",
        " \n",
        " \n",
        " \n",
        " \n",
        " \n",
        " \n",
        " \n",
        " \n",
        " \n",
        "\n",
        "\n",
        "def generate_movie_dataset_5(digits_set, labels_set, \n",
        "                            n_movies=1000, duration=5,\n",
        "                            frame_size = 280, n_digits=5,\n",
        "                            depth=2, level=1,\n",
        "                            shadow = False, shadow_ratio = 0.2, light_intensity = 0.1,\n",
        "                            max_jump=1, speed=1,\n",
        "                            digit_max = 10\n",
        "                            ):\n",
        "    \n",
        "    \"\"\"Generates a dataset of movies with moving digits\n",
        "    \n",
        "    Args:\n",
        "    digits_set: np.array of MNIST digits\n",
        "    labels_set: np.array of the corresponding labels\n",
        "    n_movies: int, number of movies\n",
        "    duration: int, duration of the movie\n",
        "    frame_size: int, size of the frame\n",
        "    n_digits: int, numer of digits\n",
        "    shadow: bool, True or False\n",
        "    shadow_ratio: float, usually 1/10**n, shadow surface/total surface, defines the radius. Reasonable circle size with ratio=0.3\n",
        "    light_intensity: float, usually 10**n, factor applied to pixels in the shadow\n",
        "    \n",
        "    Returns:\n",
        "    movies: np.array of movies, shape (n_movies, frame_size, frame_size, duration)\n",
        "    labels: np. array of frames labelling the last frame of each movie for each class\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    radius = int(frame_size*np.sqrt(shadow_ratio/np.pi))\n",
        "    \n",
        "    movies, labels = [], []\n",
        "    \n",
        "    label_size = frame_size/2**(depth-level-1)\n",
        "\n",
        "    digit_size = len(digits_set[0][0])\n",
        "    \n",
        "    for n in range(n_movies):\n",
        "        \n",
        "        # select the digits\n",
        "        \n",
        "        indexes = random.sample(range(len(digits_set)), n_digits)\n",
        "        \n",
        "        digits = digits_set[indexes]\n",
        "        digits_labels = labels_set[indexes]\n",
        "        \n",
        "        #Initial values for the positions and directions of the digits\n",
        "\t\t\n",
        "        positions = [random.sample(range(speed*max_jump, frame_size-digit_size-speed*max_jump),2) for i in range(n_digits)]\n",
        "        directions =  [non_null_sample(max_jump, 2) for i in range(n_digits)]\n",
        "\n",
        "        #create the movie and the movie labels\n",
        "        \n",
        "        movie = []\n",
        "        \n",
        "        for time in range(duration):\n",
        "\n",
        "            for k, digit in enumerate(digits):\n",
        "                \n",
        "                #Compute the new position\n",
        "                \n",
        "                position = new_position(positions[k], directions[k], speed)\n",
        "                positions[k] = position\n",
        "                \n",
        "                #Compute the next position to check it's going to be fine\n",
        "                \n",
        "                next_position = new_position(positions[k], directions[k], speed)\n",
        "\n",
        "                while out_of_frame(next_position, frame_size, digit_size):\n",
        "                \n",
        "                    #Correct the direction if next position is out of frame\n",
        "                    \n",
        "                    rebound_point = closest_frontier(next_position, frame_size, digit_size)\n",
        "                    directions[k] = mirror_direction(directions[k], rebound_point, frame_size)\n",
        "                    next_position = new_position(positions[k], directions[k], speed)\n",
        "\n",
        "                if in_the_center(positions[k], frame_size, speed, digit_size, max_jump):\n",
        "                \n",
        "                    #Randomly change the direction, if far enough from the walls\n",
        "                    directions[k] = change_direction(directions[k], max_jump)\n",
        "                    \n",
        "            #Create the frame with the positions of the digits       \n",
        "            frame = create_frame(frame_size, digits, positions)\n",
        "            \n",
        "\n",
        "            if shadow:\n",
        "                frame = add_shadow(frame, radius, light_intensity)\n",
        "                \n",
        "            movie.append(frame)\n",
        "            \n",
        "            if time == duration-1 :\n",
        "            \n",
        "                    #only label the last time step\n",
        "            \n",
        "                    movie_labels = create_labels(frame_size, digits, digits_labels, positions, digit_max)\n",
        "\n",
        "        movies.append(movie)\n",
        "        labels.append(movie_labels)\n",
        "        \n",
        "    #Get the right shape for the model\n",
        "    movies = np.transpose(movies, (0,2,3,1))\n",
        "    labels = np.transpose(labels, (0,2,3,1))\n",
        "        \n",
        "    return np.array(movies), np.array(labels)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Auxiliary functions for the generating functions (Ines)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def add_perturbations(frame, half, spot_proba, spot_factor, shadow_factor, perturbations_time, perturbations_duration, movie_duration):\n",
        "\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tAdds light level variations to a frame movie. Either on all the frame, or only half, either spotlight or shadow or both with a probability.\n",
        "\t\n",
        "\tArgs:\n",
        "\tframe: 28x28 np array\n",
        "\thalf: boolean\n",
        "\tspot_proba: 0 if only shadows, 1 if only spotlights, 0.5 if randomly one or the other.\n",
        "\tspot_factor: factor to multiply the pixel values if spotlight, usually 10**n\n",
        "\tshadow_factor: factor to multiply pixel values if shadow, usually 1/10**n\n",
        "\tperturbations_time: \"random\" by default, or int, has to be <= movie_duration-perturbations_duration\n",
        "\tperturbations_duration: int, in number of frames\n",
        "\tmovie_duration: int\n",
        "\tfinal_size: int, size of the frame\n",
        "\t\n",
        "\tReturns:\n",
        "\tframe: modified frame\n",
        "\t\n",
        "\t\"\"\"\n",
        "\tframe_size = len(frame)\n",
        "\n",
        "\tif perturbations_time==\"random\":\n",
        "\t\n",
        "\t\tstart_time = random.randint(0,movie_duration-perturbations_duration)\n",
        "\t\t\n",
        "\telse:\n",
        "\t\tstart_time = perturbations_time\n",
        "\t\t\n",
        "\tend_time = start_time + perturbations_duration -1\n",
        "\t\n",
        "\trandom_nb = np.random.random() #to decide if spotlight or shadow\n",
        "\n",
        "\n",
        "\tif half:\n",
        "\t\trandom_half = np.random.randint(0,2)\n",
        "\n",
        "\t\tif random_half==1: #low half perturbated\n",
        "\t\t\n",
        "\t\t\tnew_frames = []\n",
        "\t\t\tfor k in range(perturbations_duration):\n",
        "\t\t\t\n",
        "\t\t\t\tnew_frame = np.vstack([frame[start_time+k][:int(frame_size/2)] * ( (random_nb < spot_proba)*spot_factor + (random_nb >= spot_proba)*shadow_factor ) , frame[start_time+k][int(frame_size/2):]])\n",
        "\t\t\t\tnew_frames.append(new_frame)\n",
        "\t\t\t\t\n",
        "\t\telse: #top half perturbated\n",
        "\t\t\n",
        "\t\t\tnew_frames = []\n",
        "\t\t\tfor k in range(perturbations_duration):\n",
        "\t\t\t\n",
        "\t\t\t\tnew_frame = np.vstack([frame[start_time+k][:int(frame_size/2)], frame[start_time+k][int(frame_size/2):] * ( (random_nb < spot_proba)*spot_factor + (random_nb >= spot_proba)*shadow_factor )])\n",
        "\t\t\t\tnew_frames.append(new_frame)\n",
        "\n",
        "    \t\t\t\n",
        "\telse:  #homogeneous perturbation\n",
        "\t\n",
        "\t\tnew_frames = []\n",
        "\t\tfor k in range(perturbations_duration):\n",
        "\t\t\n",
        "\t\t\tnew_frame = frame[start_time+k] * ( (random_nb < spot_proba)*spot_factor + (random_nb >= spot_proba)*shadow_factor )\n",
        "\t\t\tnew_frames.append(new_frame)\n",
        "\n",
        "\tfor k in range(perturbations_duration):\n",
        "\t\n",
        "\t\tframe[start_time+k] = new_frames[k]\n",
        "\n",
        "\treturn frame\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def add_shadow(frame, radius, intensity):\n",
        "    \n",
        "    \"\"\"Adds a shadow on a frame.\n",
        "    \n",
        "    Args:\n",
        "    frame: np.array\n",
        "    radius: float\n",
        "    intensity: factor applied to the pixels in the shadow\n",
        "    \n",
        "    Returns:\n",
        "    shad_frame: np.array of the frame with the shadow\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    frame_size = len(frame)\n",
        "    shad_frame = frame.copy()\n",
        "    \n",
        "    for i,line in enumerate(frame):\n",
        "        for j,pixel in enumerate(line):\n",
        "            \n",
        "            x,y  = i - frame_size/2, j - frame_size/2\n",
        "            \n",
        "            if np.sqrt(x**2 + y**2) <= radius :\n",
        "                shad_frame[i,j] = intensity*frame[i,j]\n",
        "                \n",
        "    return shad_frame\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_labels(frame_size, digits, digits_labels, positions, digit_max):\n",
        "\n",
        "\n",
        "    \"\"\"Create the labels corresponding to a frame.\n",
        "    \n",
        "    Args:\n",
        "    frame_size: float\n",
        "    digits: MNIST digits present on the frame\n",
        "    digits_labels: labels of the digits\n",
        "    positions: 2-uple (x,y) for each digit\n",
        "    digit_max: 10\n",
        "    \n",
        "    Returns:\n",
        "    labels:frames corresponding to each class\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    labels = np.array([np.zeros((frame_size, frame_size)) for i in range(digit_max)]+ [np.ones((frame_size, frame_size))])\n",
        "\n",
        "    for k, digit in enumerate(digits):\n",
        "\n",
        "        \n",
        "        frame = labels[digits_labels[k]]\n",
        "\n",
        "\n",
        "\n",
        "        label_k = insert(digit, frame, positions[k])\n",
        "\n",
        "\n",
        "        labels[digits_labels[k]] = label_k\n",
        "\n",
        "\n",
        "        labels[-1] = np.maximum(labels[-1]-labels[digits_labels[k]], 0)\n",
        "        \n",
        "    return labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def label_mnist(digit_frame, digit, digit_max=10):\n",
        "\n",
        "\t\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tCreates the labels frames corresponding to an MNIST digit\n",
        "\t\n",
        "\tArgs:\n",
        "\tdigit_frame: 28x28 np array, MNIST digit directly\n",
        "\tdigit: int, MNIST label\n",
        "\tdigit_max: int, default to 10\n",
        "\t\n",
        "\tReturns:\n",
        "\tlabels: digit_max+1 frames, shape (digit_max+1, 28,28), with zeros on every frame but the digit frame, where the non zero MNIST pixels are =1.\n",
        "\t\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tlabels = [np.zeros(np.shape(digit_frame), dtype=\"float32\") for i in range(digit_max+1)]\n",
        "\n",
        "\tlabel = np.zeros(np.shape(digit_frame), dtype=\"float32\")\n",
        "\tfor i in range(len(digit_frame)):\n",
        "\t\tfor j in range(len(digit_frame[i])):\n",
        "\t    \t\tif digit_frame[i][j] != 0:\n",
        "\t    \t\t\tlabel[i][j] = 1\n",
        "\n",
        "\tlabels[digit] = label\n",
        "\tlabels[-1] = 1-label\n",
        "\n",
        "\treturn labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def insert(digit, frame, position):\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    Adds a digit in the frame. If there is already a digit, it has priority (the other is \"hidden\" behind)\n",
        "    \n",
        "    Args:\n",
        "    digit: 28x28 array\n",
        "    frame: array\n",
        "    position: x,y for the digit's top left corner\n",
        "    \n",
        "    Outputs:\n",
        "    frame: array\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    max_value = np.max(digit)\n",
        "    for i, line in enumerate(digit):\n",
        "\n",
        "        for j, pixel in enumerate(line):\n",
        "\n",
        "            frame_value = frame[position[0]+i, position[1]+j]\n",
        "            \n",
        "            if frame_value == 0 :\n",
        "                frame[position[0]+i, position[1]+j] = pixel\n",
        "                \n",
        "            #else : already a prioritary digit here\n",
        "\n",
        "    \n",
        "    return frame\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_frame_and_labels(frame_size, digits, digits_labels, positions, digit_max):\n",
        "    \n",
        "    \"\"\"Create a frame and the corresponding labels.\n",
        "    \n",
        "    Args:\n",
        "    frame_size: int\n",
        "    digits: np.array of MNIST digits to put on the frame\n",
        "    digits_labels: np.array of int labels corresponding to the digits\n",
        "    positions: 2-uple (x,y) for each digit\n",
        "    digit_max: 10\n",
        "    \n",
        "    Returns:\n",
        "    frame: the created frame\n",
        "    labels: the associated label frames for each class\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    frame = np.zeros((frame_size, frame_size))\n",
        "    background = np.ones((frame_size, frame_size))\n",
        "    labels = [np.zeros((frame_size, frame_size)) for i in range(digit_max)]\n",
        "    \n",
        "    for k, digit in enumerate(digits):\n",
        "        \n",
        "        digit_label = digits_labels[k]\n",
        "        position = positions[k]\n",
        "        \n",
        "        frame, labels[int(digit_label)], background = insert_and_label(digit, digit_label, frame, labels[int(digit_label)], position, background)\n",
        "        \n",
        "    labels.append(background)\n",
        "        \n",
        "    return np.array(frame), np.array(labels)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def insert_and_label(digit, digit_label, frame, proba, position, background):\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    Adds a digit to a frame and to the corresponding labels\n",
        "    \n",
        "    Args:\n",
        "    digit: MNIST digit\n",
        "    digit_label: int\n",
        "    frame: frame to insert the digit in\n",
        "    proba: label drame corresponding to the digit\n",
        "    position: (x,y) digit position\n",
        "    background: background frame in the labels\n",
        "    \n",
        "    Returns:\n",
        "    frame: modified frame\n",
        "    new_proba: modified label frame\n",
        "    background: modified background frame\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    new_proba = proba.copy()\n",
        "    max_value = np.max(digit)\n",
        "    \n",
        "    for i, line in enumerate(digit):\n",
        "        for j, pixel in enumerate(line):\n",
        "            \n",
        "            frame_value = frame[position[0]+i, position[1]+j]\n",
        "            \n",
        "            if frame_value == 0:\n",
        "                frame[position[0]+i, position[1]+j] = pixel\n",
        "                \n",
        "            #else : already a digit there, priority to the first arrived\n",
        "                \n",
        "            if pixel != 0:\n",
        "                \n",
        "                new_proba[position[0]+i][position[1]+j] = 1\n",
        "                background[position[0]+i][position[1]+j] = 0\n",
        "                #where a non-zero digit pixel is inserted, a one is inserted in the same position of the corresponding matrix\n",
        "\n",
        "\n",
        "    \n",
        "    return frame, new_proba, background\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def downsample_digit(digits_list, \n",
        "                     pool_size, strides\n",
        "                    ):\n",
        "                    \n",
        "    \"\"\"\n",
        "    \n",
        "    Downsamples digits\n",
        "    \n",
        "    Args:\n",
        "    digits_list: list of MNIST digits\n",
        "    pool_size: int, for the downsampling\n",
        "    strides: int, for the downsampling\n",
        "    \n",
        "    Returns:\n",
        "    down_digits: list of downsampled digits\n",
        "    new_digit_size: int\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    down_digits = []\n",
        "    \n",
        "    digit_size = len(digits_list[0][0])\n",
        "\n",
        "    \n",
        "    for digit in digits_list :\n",
        "\n",
        "\n",
        "        down_digit = []\n",
        "        line = 0\n",
        "\n",
        "        while line < len(digit[0])-pool_size+1 :\n",
        "            new_line = []\n",
        "            column = 0\n",
        "            while column < len(digit[0])-pool_size+1 :\n",
        "        \n",
        "                new_line.append(np.max( digit[line:line+pool_size, column:column+pool_size]))\n",
        "                column += strides\n",
        "        \n",
        "            line += strides\n",
        "            down_digit.append(new_line)\n",
        "        \n",
        "        down_digit= np.array(down_digit)\n",
        "\n",
        "\n",
        "        down_digits.append(down_digit)\n",
        "        new_digit_size = len(down_digits[0])\n",
        "        \n",
        "    return down_digits, new_digit_size\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def little_downsample(frame_size, digits, positions, pool_size, strides):\n",
        "    \n",
        "    \"\"\"Computes the new frame size, the new MNIST digits and their new positions after the downsampling. \n",
        "    Allows to create the downsampled frame rather then downsampling a frame, faster.\n",
        "    \n",
        "    Args:\n",
        "    frame_size; int, before downsampling\n",
        "    digits: MNIST digits\n",
        "    positions: 2-uple (x,y) for each digit\n",
        "    pool_size: int\n",
        "    strides: int\n",
        "    \n",
        "    Returns:\n",
        "    down_frame_size: int, new frame size\n",
        "    down_digits: np.array of new digits\n",
        "    down_positions: 2-uple of new (x,y) position for each digit\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    digit_size = len(digits[0][0])\n",
        "    \n",
        "    down_frame_size = (frame_size-pool_size)/strides +1\n",
        "    down_positions = []\n",
        "    down_digits = []\n",
        "    \n",
        "    for position in positions:\n",
        "        x,y = position\n",
        "        down_x, down_y = x//strides, y//strides\n",
        "        down_positions.append([down_x,down_y])\n",
        "        \n",
        "        \n",
        "    down_digits, digit_size = downsample_digit(digits, pool_size, strides)\n",
        "\n",
        "        \n",
        "    return int(down_frame_size), down_digits, down_positions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_frame(frame_size, digits, positions):\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    Creates the frame zith all the digits.\n",
        "    \n",
        "    Args:\n",
        "    frame_size: for a square frame\n",
        "    digits: list of 28x28 arrays\n",
        "    positions: list of x,y corresponding to the digits' top left corners, in the same order\n",
        "    \n",
        "    Outputs:\n",
        "    frame: 280x280 array\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    frame = np.zeros((frame_size, frame_size))\n",
        "    for k, digit in enumerate(digits):\n",
        "        position = positions[k]\n",
        "        frame = insert(digit, frame, position)\n",
        "    return frame\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def mirror_direction(direction, position, frame_size):\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    Finds the new direction when a digit rebounds on a wall.\n",
        "    \n",
        "    Args:\n",
        "    direction: current direction of the digit [dx,dy] \n",
        "    position: current position of the digit [x,y]\n",
        "    frame_size: for a square frame\n",
        "    \n",
        "    Outputs:\n",
        "    direction: [dx,dy]\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    dx, dy = direction\n",
        "    x,y = position\n",
        "    if (x==0 or x==frame_size-1) and y!=0 and y!=frame_size-1:\n",
        "        dx = -dx\n",
        "    if (y==0 or y==frame_size-1) and x!=0 and x!=frame_size-1:\n",
        "        dy = -dy\n",
        "    if (x==0 or x==frame_size-1) and (y==0 or y==frame_size-1):\n",
        "        dx, dy = -dx, -dy\n",
        "    return [dx, dy]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def change_direction(direction, max_jump):\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    Generates a slight change in direction, called with a small probability.\n",
        "    \n",
        "    Args:\n",
        "    direction: current direction [dx,dy]\n",
        "    max_jump: initially defined constant\n",
        "    \n",
        "    Outputs:\n",
        "    direction: new direction[dx,dy]\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    random_nb = random.random()\n",
        "    if random_nb < 0.05:\n",
        "        direction[0] = min(max_jump, max(-max_jump,direction[0]+1))\n",
        "        # to check that still between -max_jump and max_jump\n",
        "    elif random_nb >= 0.05 and random_nb < 0.1 :\n",
        "        direction[0] = min(max_jump, max(-max_jump,direction[0]-1))\n",
        "    if random_nb >= 0.1 and random_nb < 0.15:\n",
        "        direction[1] = min(max_jump, max(-max_jump,direction[1]+1))\n",
        "    elif random_nb >= 0.15 and random_nb < 0.2 :\n",
        "        direction[1] = min(max_jump, max(-max_jump,direction[1]-1))\n",
        "    return direction\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def closest_frontier(position, frame_size, digit_size):\n",
        "\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tFinds the closest point on the walls to a digit\n",
        "\t\n",
        "\tArgs:\n",
        "\tposition: (x,y) position of the top left corner of the digit\n",
        "\tframe_size: int\n",
        "\tdigit_size: int\n",
        "\t\n",
        "\tReturns:\n",
        "\t(x,y) position of the closest point on a wall\n",
        "\t\n",
        "\t\"\"\"\n",
        "    \n",
        "\tx,y = position\n",
        "\tneighbor_frontiers = [(frame_size-1,y), (0,y), (x, frame_size-1), (x,0)]\n",
        "\tdistances = []\n",
        "\tdistances.append(frame_size - (x+digit_size))\n",
        "\tdistances.append(x)\n",
        "\tdistances.append(frame_size - (y+digit_size))\n",
        "\tdistances.append(y)\n",
        "\treturn neighbor_frontiers[distances.index(min(distances))]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def non_null_sample(max_value, number):\n",
        "\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tSelects a number-uple of values different from (0,...,0) for the directions, usually (dx,dy) because 2D\n",
        "\t\n",
        "\tArgs:\n",
        "\tmax_value: int, max value to choose\n",
        "\tnumber: number of numbers to pick\n",
        "\t\n",
        "\tReturns:\n",
        "\tnumber-uple of values not all zero, usually (dx,dy)\n",
        "\t\n",
        "\t\"\"\"\n",
        "    \n",
        "\tvalues = list(np.arange(-max_value, max_value+1))\n",
        "\tsample = []\n",
        "\tfor i in range(number-1):\n",
        "\t\tsample.append(random.choice(values))\n",
        "\t#for the last value, we cannot add a zero if there are only zero in the selected values\n",
        "\tif list(set(sample)) != [0]:\n",
        "\t\tsample.append(random.choice(values))\n",
        "\telse:\n",
        "\t\tvalues.remove(0)\n",
        "\t\tsample.append(random.choice(values))\n",
        "\treturn sample\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def new_position(position, direction, speed):\n",
        "\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tComputes the new position from current position, direction and speed\n",
        "\t\n",
        "\tArgs:\n",
        "\tposition: (x,y) int \n",
        "\tdirection: (dx, dy) int\n",
        "\tspeed: int\n",
        "\t\n",
        "\tReturns:\n",
        "\t(x,y) new position : x += speed*dx\n",
        "\t\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tx,y = position\n",
        "\tdx, dy = direction\n",
        "\treturn [x+speed*dx, y+speed*dy]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def out_of_frame(position, frame_size, digit_size):\n",
        "\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tChecks whether a position would go out of the frame\n",
        "\t\n",
        "\tArgs:\n",
        "\tposition: (x,y) int\n",
        "\tframe_size: int\n",
        "\tdigit_size: int\n",
        "\t\n",
        "\tReturns:\n",
        "\tbool: True if out of frame\n",
        "\t\n",
        "\t\"\"\"\n",
        "\tfor i, dimension in enumerate(position) :\n",
        "\n",
        "\t\tif dimension + digit_size  > frame_size:\n",
        "\t\t\treturn True\n",
        "\t\tif dimension < 0:\n",
        "\t\t\treturn True\n",
        "\treturn False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def in_the_center(position, frame_size, speed, digit_size, max_jump):\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tChecks whether a digit is far enough from the walls (to randomly change direction without danger)\n",
        "\t\n",
        "\tArgs:\n",
        "\tposition: (x,y) int\n",
        "\tframe_size: int\n",
        "\tspeed: int\n",
        "\tdigit_size: int\n",
        "\tmax_jump: int\n",
        "\t\n",
        "\tReturns:\n",
        "\tbool: True if far enough from the walls\n",
        "\t\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tsecurity_distance = abs(speed*max_jump)+ digit_size\n",
        "\tfor dimension in position :\n",
        "\t\tif abs(frame_size-dimension)<security_distance or dimension < security_distance:\n",
        "\t    \t\treturn False\n",
        "\treturn True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_movie(movie, title, directory, time_interval=70):\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    Saves a movie in a directory in GIF format\n",
        "    \n",
        "    Args:\n",
        "    movie: np.array of dimension (n_frames, frame_size, frame_size)\n",
        "    title: string\n",
        "    directory: str of shape \"folder1/folder2/\"\n",
        "    time_interval: int, between two frames. 50 is fast, 150 is slow\n",
        "    \n",
        "    Returns:\n",
        "    nothing, the movie is saved.\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    fig, ax  = plt.subplots()\n",
        "    ims = []\n",
        "    for i, image in enumerate(movie):\n",
        "        im = ax.imshow((image), animated=True)\n",
        "        if i == 0:\n",
        "            ax.imshow(image) \n",
        "        ims.append([im])\n",
        "\n",
        "    gif = animation.ArtistAnimation(fig, ims, interval=time_interval, blit=True,\n",
        "                                repeat_delay=1000)\n",
        "    gif.save(directory+title+\".gif\")\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "#Custom metrics (Ines)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@tf.function(experimental_relax_shapes=True)\n",
        "def new_weighted_loss_0(y_true, y_pred):\n",
        "\n",
        "    \"\"\"\n",
        "    Counts the number of zeros and ones pixels on the labels, then applies the weights on all the frames based on the background to balance the digits and background classes (because a lot more zeros). Then computes the weighted cross-entropy loss (- mean of true_labels * weights * log(predictions) )\n",
        "    \n",
        "    Args:\n",
        "    y_true: true labels\n",
        "    y_pred: predictions\n",
        "    \n",
        "    Returns:\n",
        "    Cross-entropy loss\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    background = y_true[:, :,-1]\n",
        "    w1 = tf.reduce_sum(background)/tf.cast(tf.size(background), tf.float32)\n",
        "    w2 = 1-w1\n",
        "    w = background*w2 + (1-background)*w1\n",
        "    \n",
        "    #loss = tf.reduce_mean(w[:, :, None]*tf.square(tf.subtract(y_true, y_pred))) \n",
        "    #to broadcast (over channels)\n",
        "    #tf.print(tf.math.log(y_pred))\n",
        "\n",
        "    y_pred = tf.clip_by_value(y_pred, 0.0001, 0.9999)\n",
        "    term = w[:,:, None]* (y_true)* tf.math.log(y_pred) \n",
        "    loss =tf.reduce_mean(term)\n",
        "    #tf.print(loss)\n",
        "\n",
        "    return tf.math.abs(loss)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "@tf.function\n",
        "def new_weighted_loss(y_true, y_pred):\n",
        "\n",
        "    \"\"\"\n",
        "    Counts the number of zeros and ones pixels on the labels, then applies the weights on each frame separately to balance the zeros and ones classes (because a lot more zeros). Then computes the weighted cross-entropy loss (- mean of true_labels * weights * log(predictions) )\n",
        "    \n",
        "    Args:\n",
        "    y_true: true labels\n",
        "    y_pred: predictions\n",
        "    \n",
        "    Returns:\n",
        "    Cross-entropy loss\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    w1 = tf.reduce_sum(y_true)/tf.cast(tf.size(y_true), tf.float32)  #proportion of ones pixels\n",
        "    w2 = 1-w1   #proportion of zeros pixels\n",
        "    \n",
        "    N = len(y_true[0,0,0])  # number of classes\n",
        "    weights = tf.TensorArray(tf.float32, size=N)\n",
        "    \n",
        "    #now we build the weights matrix\n",
        "    \n",
        "    for i in range(N):\n",
        "    \n",
        "    \tframe = y_true[:,:,:,i]\n",
        "    \tweights_frame = frame*w2 + (1-frame)*w1   #ones pixels get the zeros pixels proportion as their weight, for each frame\n",
        "    \t\n",
        "    \tweights = weights.write(i, weights_frame)\n",
        "    \t\n",
        "    weights = tf.transpose(weights.stack(), (1, 2, 3, 0))\n",
        "        \n",
        "    y_pred = tf.clip_by_value(y_pred, 0.0001, 0.9999)\n",
        "    #to avoid log(0) that was causing an error\n",
        "    term = weights * (y_true)* tf.math.log(y_pred) \n",
        "    loss = - tf.reduce_mean(term)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@tf.function(experimental_relax_shapes=True)\n",
        "def my_accuracy(y_true, y_pred):\n",
        "\n",
        "\t\"\"\"\n",
        "\tComputes the mean of exp(-abs(relative_error)), only taking into account digit pixels, and not the background. Idea: to get a better range of the accuracy values, we could add a multiplying factor inside the exp.\n",
        "\t\n",
        "\tArgs:\n",
        "\ty_true: true labels\n",
        "\ty_pred: predictions\n",
        "\t\n",
        "\tReturns:\n",
        "\tnon-categorical accuracy\n",
        "\t\n",
        "\t\"\"\"\n",
        "\t\n",
        "\ty_true_digits = y_true[:,:,:,:-1]\n",
        "\ty_pred_digits = y_pred[:,:,:,:-1]\n",
        "\tbackground = y_true[:,:,:,:-1]\n",
        "\tn_classes = y_true.get_shape()[-1]-1\n",
        "\t\n",
        "\t#What I used in my runs\n",
        "\tsimilarity = tf.math.exp(- tf.math.abs( y_pred_digits - y_true_digits) )\n",
        "\t\n",
        "\t#What I realized on the presentation day would have been better\n",
        "\t#1. Using the relative error\n",
        "\t#2. Using a factor to decide how low the accuracy can go (right now, betwen 0.9 and 1...)\n",
        "\t#similarity = tf.math.exp(- tf.math.abs( factor * (y_pred_digits - y_true_digits)/y_true_digits )\n",
        "\t\n",
        "\n",
        "\n",
        "\tdigit_index = tf.math.argmax(tf.math.reduce_max(y_true[:,:,:,:-1], axis=(0,1,2))) \n",
        "\tdigit_frame = y_true_digits[:,:,:,digit_index]\t\n",
        "\t\n",
        "\tweighted_similarity = digit_frame[:,:,:,None] * similarity\n",
        "\n",
        "\n",
        "\n",
        "\tmy_accuracy = tf.cast(tf.reduce_sum( weighted_similarity ), tf.float32) / tf.cast(tf.math.count_nonzero(digit_frame) * n_classes, tf.float32)\n",
        "\t\n",
        "\treturn my_accuracy\n",
        "\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "@tf.function(experimental_relax_shapes=True)\n",
        "def my_cat_accuracy(y_true, y_pred):\n",
        "\n",
        "\t\"\"\"\n",
        "\tComputes the frequency of good predictions, choosing the maximum probability over the classes, only taking into account digit pixels, and not the background.\n",
        "\t\n",
        "\tArgs:\n",
        "\ty_true: true labels\n",
        "\ty_pred: predictions\n",
        "\t\n",
        "\tReturns:\n",
        "\tcategorical accuracy\n",
        "\t\n",
        "\t\"\"\"\n",
        "\n",
        "\tbackground = y_true[:,:,:,-1]\n",
        "\t\n",
        "\t#we \"force the network to choose\" by taking the maximum over the classes\n",
        "\tindexes_true = tf.math.argmax(y_true,axis=3)\n",
        "\tindexes_pred = tf.math.argmax(y_pred,axis=3)\n",
        "\t\n",
        "\t#the \"indexes\" are just one frame wih values between 0 and 10, indicating the class with the maximum probability for each pixel\n",
        "\n",
        "\t#find where the digit actually is\n",
        "\tdigit_index = tf.math.argmax(tf.math.reduce_max(y_true[:,:,:,:-1], axis=(0,1,2))) \n",
        "\t\n",
        "\t#the reduce_max is list of n_classes element, excluding the background. the max is the frame with the actual digit (the others are only zeros)\n",
        "\n",
        "\t#we count the pixels where the predicted class is correct, and is the digit (not background) \n",
        "\tacc = tf.math.reduce_sum(tf.cast((indexes_true == indexes_pred) & (indexes_true==digit_index), tf.float32)) / tf.cast(tf.math.count_nonzero(1-background), tf.float32)\n",
        "\n",
        "\treturn acc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Code for the photoreceptor model (Saad)\n",
        "\n",
        "\n",
        "def conv_oper_multichan(x,kernel_1D):\n",
        "\n",
        "    spatial_dims = x.shape[-1]\n",
        "    x_reshaped = tf.expand_dims(x,axis=2)\n",
        "    kernel_1D = tf.squeeze(kernel_1D,axis=0)\n",
        "    kernel_1D = tf.reverse(kernel_1D,[0])\n",
        "    tile_fac = tf.constant([spatial_dims,1])\n",
        "    kernel_reshaped = tf.tile(kernel_1D,(tile_fac))\n",
        "    kernel_reshaped = tf.reshape(kernel_reshaped,(1,spatial_dims,kernel_1D.shape[0],kernel_1D.shape[-1]))\n",
        "\n",
        "#**** color image ?\n",
        "    # kernel_reshaped = tf.reshape(kernel_reshaped,(1,spatial_dims,kernel_1D.shape[0],kernel_1D.shape[-1],3))\n",
        "\n",
        "    kernel_reshaped = tf.experimental.numpy.moveaxis(kernel_reshaped,-2,0)\n",
        "\n",
        "    pad_vec = [[0,0],[kernel_1D.shape[0]-1,0],[0,0],[0,0]]\n",
        "    # # pad_vec = [[0,0],[0,0],[0,0],[0,0]]\n",
        "\n",
        "    # conv_output = tf.nn.conv2d(x_reshaped,kernel_reshaped,strides=[1,1,1,1],padding=pad_vec,data_format='NHWC')\n",
        "    conv_output = tf.nn.depthwise_conv2d(x_reshaped,kernel_reshaped,strides=[1,1,1,1],padding=pad_vec,data_format='NHWC')\n",
        "    \n",
        "    # print(conv_output.shape)\n",
        "    return conv_output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@tf.function()#experimental_relax_shapes=True)\n",
        "def slice_tensor(inp_tensor,shift_vals):\n",
        "    # print(inp_tensor.shape)\n",
        "    # print(shift_vals.shape)\n",
        "    shift_vals = shift_vals[:,tf.newaxis,:]\n",
        "    shift_vals = tf.tile(shift_vals,[1,inp_tensor.shape[-2],1])\n",
        "    tens_reshape = tf.reshape(inp_tensor,[-1,inp_tensor.shape[1]*inp_tensor.shape[2]*inp_tensor.shape[3]*inp_tensor.shape[4]])\n",
        "    # print('tens_reshape: ',tens_reshape.shape)\n",
        "    shift_vals_new = (inp_tensor.shape[1]-shift_vals[0])*(inp_tensor.shape[-1]*inp_tensor.shape[-2])\n",
        "    rgb = tf.range(0,shift_vals_new.shape[-1])\n",
        "    rgb = rgb[tf.newaxis,:]\n",
        "    rgb = tf.tile(rgb,[shift_vals_new.shape[0],1])\n",
        "    temp = tf.range(0,shift_vals_new.shape[-1]*shift_vals_new.shape[-2],shift_vals_new.shape[-1])\n",
        "    rgb = rgb+temp[:,None]\n",
        "    shift_vals_new = shift_vals_new + rgb\n",
        "    extracted_vals = tf.gather(tens_reshape,shift_vals_new,axis=1)\n",
        "    # print('extracted_vals: ',shift_vals.shape)\n",
        "    extracted_vals_reshaped = tf.reshape(extracted_vals,(-1,1,inp_tensor.shape[2],inp_tensor.shape[3],inp_tensor.shape[4]))\n",
        "    \n",
        "    return extracted_vals_reshaped\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_simple_filter_multichan(tau,n,t):\n",
        "    t_shape = t.shape[0]\n",
        "    t = tf.tile(t,tf.constant([tau.shape[-1]], tf.int32))\n",
        "    t = tf.reshape(t,(tau.shape[-1],t_shape))\n",
        "    t = tf.transpose(t)\n",
        "    f = (t**n[:,None])*tf.math.exp(-t/tau[:,None]) # functional form in paper\n",
        "    rgb = tau**(n+1)\n",
        "    f = (f/rgb[:,None])/tf.math.exp(tf.math.lgamma(n+1))[:,None] # normalize appropriately\n",
        "    # print(t.shape)\n",
        "    # print(n.shape)\n",
        "    # print(tau.shape)\n",
        "   \n",
        "    return f\n",
        "    \n",
        "# class photoreceptor_DA_multichan_randinit(tf.keras.layers.Layer):\n",
        "#     def __init__(self,units=1,kernel_regularizer=None):\n",
        "#         super(photoreceptor_DA_multichan_randinit,self).__init__()\n",
        "#         self.units = units\n",
        "#         self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "\n",
        "\n",
        "\n",
        "class photoreceptor_DA_multichan_randinit(tf.keras.layers.Layer):\n",
        "    def __init__(self, units=1, kernel_regularizer=None, **kwargs):\n",
        "        super(photoreceptor_DA_multichan_randinit, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        \n",
        "    def get_config(self):\n",
        "         config = super().get_config()\n",
        "         config.update({\n",
        "             \"units\": self.units,\n",
        "             \"kernel_regularizer\": self.kernel_regularizer\n",
        "         })\n",
        "         return config      \n",
        "               \n",
        "    def build(self,input_shape):    # random inits\n",
        "\n",
        "\n",
        "        # # # # Constant Values\n",
        "        # zeta_init = tf.keras.initializers.Constant(0.2) \n",
        "        # self.zeta = self.add_weight(name='zeta',initializer=zeta_init,shape=[1,self.units],trainable=False)\n",
        "        # zeta_mulFac = tf.keras.initializers.Constant(1000.) \n",
        "        # self.zeta_mulFac = self.add_weight(name='zeta_mulFac',initializer=zeta_mulFac,shape=[1,self.units],trainable=False)\n",
        "    \n",
        "        # # # you can have a costant value constant value for kappa\n",
        "        # kappa_init = tf.keras.initializers.Constant(0.13) \n",
        "        # self.kappa = self.add_weight(name='kappa',initializer=kappa_init,shape=[1,self.units],trainable=False)\n",
        "        # kappa_mulFac = tf.keras.initializers.Constant(1000.) \n",
        "        # self.kappa_mulFac = self.add_weight(name='kappa_mulFac',initializer=kappa_mulFac,shape=[1,self.units],trainable=False)\n",
        "\n",
        "        # # # # you can have a constant value for alpha \n",
        "        # alpha_init = tf.keras.initializers.Constant(0.0667) \n",
        "        # self.alpha = self.add_weight(name='alpha',initializer=alpha_init,shape=[1,self.units],trainable=False)\n",
        "        # alpha_mulFac = tf.keras.initializers.Constant(1000.) \n",
        "        # self.alpha_mulFac = self.add_weight(name='alpha_mulFac',initializer=alpha_mulFac,shape=[1,self.units],trainable=False)\n",
        "\n",
        "        # # # # you can have a constant value for beta \n",
        "        # beta_init = tf.keras.initializers.Constant(0) \n",
        "        # self.beta = self.add_weight(name='beta',initializer=beta_init,shape=[1,self.units],trainable=False)\n",
        "        # beta_mulFac = tf.keras.initializers.Constant(1000.) \n",
        "        # self.beta_mulFac = self.add_weight(name='beta_mulFac',initializer=beta_mulFac,shape=[1,self.units],trainable=False)\n",
        "\n",
        "        # # # you can have a costant value constant value for gamma\n",
        "        # gamma_init = tf.keras.initializers.Constant(0.1) \n",
        "        # self.gamma = self.add_weight(name='gamma',initializer=gamma_init,shape=[1,self.units],trainable=False)\n",
        "        # gamma_mulFac = tf.keras.initializers.Constant(10.) \n",
        "        # self.gamma_mulFac = self.add_weight(name='gamma_mulFac',initializer=gamma_mulFac,shape=[1,self.units],trainable=False)\n",
        "\n",
        "\n",
        "        # # # you can have a costant value constant value for tauY\n",
        "        # tauY_init = tf.keras.initializers.Constant(0.06) \n",
        "        # self.tauY = self.add_weight(name='tauY',initializer=tauY_init,shape=[1,self.units],trainable=False)\n",
        "        # tauY_mulFac = tf.keras.initializers.Constant(10.) \n",
        "        # self.tauY_mulFac = self.add_weight(name='tauY_mulFac',initializer=tauY_mulFac,shape=[1,self.units],trainable=False)\n",
        "\n",
        "        # # # you can have a costant value constant value for nY\n",
        "        # nY_init = tf.keras.initializers.Constant(0.1) \n",
        "        # self.nY = self.add_weight(name='nY',initializer=nY_init,shape=[1,self.units],trainable=False)\n",
        "        # nY_mulFac = tf.keras.initializers.Constant(10.) \n",
        "        # self.nY_mulFac = self.add_weight(name='nY_mulFac',initializer=nY_mulFac,shape=[1,self.units],trainable=False)\n",
        "\n",
        "        # # # you can have a costant value constant value for tauz\n",
        "        # tauZ_init = tf.keras.initializers.Constant(0.09) \n",
        "        # self.tauZ = self.add_weight(name='tauZ',initializer=tauZ_init,shape=[1,self.units],trainable=False)\n",
        "        # tauZ_mulFac = tf.keras.initializers.Constant(100.) \n",
        "        # self.tauZ_mulFac = self.add_weight(name='tauZ_mulFac',initializer=tauZ_mulFac,shape=[1,self.units],trainable=False)\n",
        "\n",
        "        # # # you can have a costant value constant value for nz\n",
        "        # nZ_init = tf.keras.initializers.Constant(0.09) \n",
        "        # self.nZ = self.add_weight(name='nZ',initializer=nZ_init,shape=[1,self.units],trainable=False)\n",
        "        # nZ_mulFac = tf.keras.initializers.Constant(10.) \n",
        "        # self.nZ_mulFac = self.add_weight(name='nZ_mulFac',initializer=nZ_mulFac,shape=[1,self.units],trainable=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Range of values for each parameter \n",
        "\n",
        "\n",
        "    \n",
        "## \n",
        "        \n",
        "        zeta_range = (0,1)\n",
        "        # zeta_range = (.02602935,.02602935000001)\n",
        "        # zeta_range = (.02,.02000001)\n",
        "        zeta_init = tf.keras.initializers.RandomUniform(minval=zeta_range[0],maxval=zeta_range[1]) #tf.keras.initializers.Constant(0.0159) \n",
        "        self.zeta = self.add_weight(name='zeta',initializer=zeta_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        zeta_mulFac = tf.keras.initializers.Constant(1000.) \n",
        "        self.zeta_mulFac = self.add_weight(name='zeta_mulFac',initializer=zeta_mulFac,shape=[1,self.units],trainable=False)\n",
        "        \n",
        "\n",
        "\n",
        "        # # you can have a range for kappa \n",
        "        kappa_range = (0,1)\n",
        "        # kappa_range = (0.05,0.0500001)\n",
        "        # kappa_range = (0.049,0.049000001)\n",
        "        kappa_init = tf.keras.initializers.RandomUniform(minval=kappa_range[0],maxval=kappa_range[1]) #tf.keras.initializers.Constant(0.0159) \n",
        "        self.kappa = self.add_weight(name='kappa',initializer=kappa_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        kappa_mulFac = tf.keras.initializers.Constant(1000.) \n",
        "        self.kappa_mulFac = self.add_weight(name='kappa_mulFac',initializer=kappa_mulFac,shape=[1,self.units],trainable=False)\n",
        "        \n",
        "\n",
        "\n",
        "        # # you can have a range for alpha \n",
        "        alpha_range = (0,1)\n",
        "        # alpha_range = (0.03487017,0.0348701700001)\n",
        "        # alpha_range = (0.05,0.05000001)\n",
        "        alpha_init = tf.keras.initializers.RandomUniform(minval=alpha_range[0],maxval=alpha_range[1]) #tf.keras.initializers.Constant(0.0159) \n",
        "        self.alpha = self.add_weight(name='alpha',initializer=alpha_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        alpha_mulFac = tf.keras.initializers.Constant(100.) \n",
        "        self.alpha_mulFac = self.add_weight(name='alpha_mulFac',initializer=alpha_mulFac,shape=[1,self.units],trainable=False)\n",
        "        \n",
        "\n",
        "\n",
        "        # # you can have a range for beta\n",
        "        beta_range = (0,1)\n",
        "        # beta_range = (0.02,0.02000001)\n",
        "        # beta_range = (0.04995,0.04995000001)\n",
        "        beta_init = tf.keras.initializers.RandomUniform(minval=beta_range[0],maxval=beta_range[1])  #tf.keras.initializers.Constant(0.02)# \n",
        "        self.beta = self.add_weight(name='beta',initializer=beta_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        beta_mulFac = tf.keras.initializers.Constant(10.) \n",
        "        self.beta_mulFac = self.add_weight(name='beta_mulFac',initializer=beta_mulFac,shape=[1,self.units],trainable=False)\n",
        " \n",
        "  \n",
        "\n",
        "        # # you can have a range for gamma\n",
        "        gamma_range = (0,1)\n",
        "        # gamma_range = (0.02,0.02000001)\n",
        "        gamma_init = tf.keras.initializers.RandomUniform(minval=gamma_range[0],maxval=gamma_range[1])  #tf.keras.initializers.Constant(0.075)# \n",
        "        self.gamma = self.add_weight(name='gamma',initializer=gamma_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        gamma_mulFac = tf.keras.initializers.Constant(10.) \n",
        "        self.gamma_mulFac = self.add_weight(name='gamma_mulFac',initializer=gamma_mulFac,shape=[1,self.units],trainable=False)\n",
        "\n",
        "\n",
        "        #You can have a rannge for tauy, multiplication factor is 1000 from frame 1 to frame 20 \n",
        "        tauY_range = (0,1)\n",
        "        # tauY_range = (0.02,0.0200001)\n",
        "        # tauY_range = (0.04997,0.04997000001)\n",
        "        tauY_init = tf.keras.initializers.RandomUniform(minval=tauY_range[0],maxval=tauY_range[1])  #tf.keras.initializers.Constant(0.01)# \n",
        "        self.tauY = self.add_weight(name='tauY',initializer=tauY_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        tauY_mulFac = tf.keras.initializers.Constant(100.) #tf.keras.initializers.Constant(100.) \n",
        "        self.tauY_mulFac = tf.Variable(name='tauY_mulFac',initial_value=tauY_mulFac(shape=(1,self.units),dtype='float32'),trainable=False)\n",
        " \n",
        "\n",
        "        # you can have a range for nY\n",
        "        nY_range = (0,1)\n",
        "        # nY_range = (0.02,0.0200001)\n",
        "        # nY_range = (0.02,0.02000001)\n",
        "        nY_init = tf.keras.initializers.RandomUniform(minval=nY_range[0],maxval=nY_range[1]) #tf.keras.initializers.Constant(0.01)# \n",
        "        self.nY = self.add_weight(name='nY',initializer=nY_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        nY_mulFac = tf.keras.initializers.Constant(10.) \n",
        "        self.nY_mulFac = tf.Variable(name='nY_mulFac',initial_value=nY_mulFac(shape=(1,self.units),dtype='float32'),trainable=False)\n",
        "\n",
        "\n",
        "        # you can have a range for tauz , multiplication factor is 100 from frame 2 to frame 20 \n",
        "        tauZ_range = (0,1)\n",
        "        # tauZ_range = (0.05,0.0500001)\n",
        "        # tauZ_range = (0.0208,0.0208000001)\n",
        "        tauZ_init = tf.keras.initializers.RandomUniform(minval=tauZ_range[0],maxval=tauZ_range[1]) #tf.keras.initializers.Constant(0.5)# \n",
        "        self.tauZ = self.add_weight(name='tauZ',initializer=tauZ_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        tauZ_mulFac = tf.keras.initializers.Constant(100.) \n",
        "        self.tauZ_mulFac = tf.Variable(name='tauZ_mulFac',initial_value=tauZ_mulFac(shape=(1,self.units),dtype='float32'),trainable=False)\n",
        "                \n",
        "\n",
        "        # you can have a range for nz\n",
        "        nZ_range = (0,1)\n",
        "        # nZ_range = (0.04983,0.04983000001)\n",
        "        nZ_init = tf.keras.initializers.RandomUniform(minval=nZ_range[0],maxval=nZ_range[1])  #tf.keras.initializers.Constant(0.01)# \n",
        "        self.nZ = self.add_weight(name='nZ',initializer=nZ_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        nZ_mulFac = tf.keras.initializers.Constant(10.) \n",
        "        self.nZ_mulFac = tf.Variable(name='nZ_mulFac',initial_value=nZ_mulFac(shape=(1,self.units),dtype='float32'),trainable=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# remove kc \n",
        "        # multiplication factor is 100 from frame 1 to frame 20 \n",
        "        tauC_range = (0.02,0.05)\n",
        "        tauC_init = tf.keras.initializers.RandomUniform(minval=tauC_range[0],maxval=tauC_range[1])  #tf.keras.initializers.Constant(0.2)# \n",
        "        self.tauC = self.add_weight(name='tauC',initializer=tauC_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        tauC_mulFac = tf.keras.initializers.Constant(100.) \n",
        "        self.tauC_mulFac = tf.Variable(name='tauC_mulFac',initial_value=tauC_mulFac(shape=(1,self.units),dtype='float32'),trainable=False)\n",
        "                \n",
        "        nC_range = (1e-5,0.2)\n",
        "        nC_init = tf.keras.initializers.RandomUniform(minval=nC_range[0],maxval=nC_range[1]) \n",
        "        self.nC = self.add_weight(name='nC',initializer=nC_init,shape=[1,self.units],trainable=False,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,nC_range[0],nC_range[1]))\n",
        "        nC_mulFac = tf.keras.initializers.Constant(10.) \n",
        "        self.nC_mulFac = tf.Variable(name='nC_mulFac',initial_value=nC_mulFac(shape=(1,self.units),dtype='float32'),trainable=False)\n",
        "    \n",
        "    def call(self,inputs):\n",
        "       \n",
        "        timeBin = 1\n",
        "        \n",
        "        alpha =  self.alpha*self.alpha_mulFac\n",
        "        beta = self.beta*self.beta_mulFac\n",
        "        gamma =  self.gamma*self.gamma_mulFac\n",
        "        zeta = self.zeta*self.zeta_mulFac\n",
        "        kappa = self.kappa*self.kappa_mulFac\n",
        "        tau_y =  (self.tauY_mulFac*self.tauY) / timeBin\n",
        "        tau_z =  (self.tauZ_mulFac*self.tauZ) / timeBin\n",
        "        tau_c =  (self.tauC_mulFac*self.tauC) / timeBin\n",
        "        n_y =  (self.nY_mulFac*self.nY)\n",
        "        n_z =  (self.nZ_mulFac*self.nZ)\n",
        "        n_c =  (self.nC_mulFac*self.nC)\n",
        "        \n",
        "        # print('tau_z: ',tau_y.shape)\n",
        "        \n",
        "        t = tf.range(0,inputs.shape[1],dtype='float32')\n",
        "        \n",
        "        Ky = generate_simple_filter_multichan(tau_y,n_y,t)   \n",
        "        Kc = generate_simple_filter_multichan(tau_c,n_c,t)  \n",
        "        Kz = generate_simple_filter_multichan(tau_z,n_z,t) \n",
        "        # Kz = (gamma*Kc) + ((1-gamma) * Kz)\n",
        "        # replace kc by ky  \n",
        "        Kz = (gamma*Ky) + ((1-gamma) * Kz)\n",
        "        # print('Kz: ',Kz.shape)\n",
        "        \n",
        "        # Kz = Kz[None,0,:]\n",
        "        # print('Kz_new',Kz.shape)\n",
        "        \n",
        "        # print('inputs: ',inputs.shape)\n",
        "        y_tf = conv_oper_multichan(inputs,Ky)\n",
        "        z_tf = conv_oper_multichan(inputs,Kz)\n",
        "        # print('z_tf: ',z_tf.shape)\n",
        "               \n",
        "        y_tf_reshape = tf.reshape(y_tf,(-1,y_tf.shape[1],y_tf.shape[2],inputs.shape[-1],tau_z.shape[-1]))\n",
        "        z_tf_reshape = tf.reshape(z_tf,(-1,z_tf.shape[1],z_tf.shape[2],inputs.shape[-1],tau_z.shape[-1]))\n",
        "        # print('z_tf_reshape: ',z_tf_reshape.shape)\n",
        "        \n",
        "#***** Colour image\n",
        "\n",
        "        # y_tf_reshape = tf.reshape(y_tf,(-1,y_tf.shape[1],y_tf.shape[2],3,tau_z.shape[-1]))\n",
        "        # z_tf_reshape = tf.reshape(z_tf,(-1,z_tf.shape[1],z_tf.shape[2],3,tau_z.shape[-1]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        ## For time distributed, remove these four lines:\n",
        "        \n",
        "        # y_shift = tf.math.argmax(Ky,axis=1);y_shift = tf.cast(y_shift,tf.int32)\n",
        "        # z_shift = tf.math.argmax(Kz,axis=1);z_shift = tf.cast(z_shift,tf.int32)\n",
        "        \n",
        "        # y_tf_reshape = slice_tensor(y_tf_reshape,y_shift)\n",
        "        # z_tf_reshape = slice_tensor(z_tf_reshape,z_shift)\n",
        "        # print('z_tf_slice: ',z_tf_reshape.shape)\n",
        "               \n",
        "    # the output shape \n",
        "        outputs = (zeta[None,None,0,None,:] + (alpha[None,None,0,None,:]*y_tf_reshape[:,:,0,:,:]))/(kappa[None,None,0,None,:]+1e-6+(beta[None,None,0,None,:]*z_tf_reshape[:,:,0,:,:]))       \n",
        " \n",
        "\n",
        "#****** 3channels: RGB\n",
        "        # # Red \n",
        "        # output_red = (zeta[None,None,0,None,:] + (alpha[None,None,0,None,:]*y_tf_reshape[:,:,0,:,:]))/(kappa[None,None,0,None,:]+1e-6+(beta[None,None,0,None,:]*z_tf_reshape[:,:,0,:,:]))\n",
        "        # # Green \n",
        "        # output_green = (zeta[None,None,1,None,:] + (alpha[None,None,0,None,:]*y_tf_reshape[:,:,1,:,:]))/(kappa[None,None,0,None,:]+1e-6+(beta[None,None,1,None,:]*z_tf_reshape[:,:,1,:,:]))\n",
        "        # # Blue \n",
        "        # output_blue = (zeta[None,None,2,None,:] + (alpha[None,None,2,None,:]*y_tf_reshape[:,:,2,:,:]))/(kappa[None,None,0,None,:]+1e-6+(beta[None,None,2,None,:]*z_tf_reshape[:,:,2,:,:]))\n",
        "        \n",
        "        # # Concatenate \n",
        "        # outputs=tf.concat([output_red,output_green,output_blue], axis=-1)\n",
        "        \n",
        "        # set kappa=1, and zeta=0\n",
        "        # outputs = (0 + (alpha[None,None,0,None,:]*y_tf_reshape[:,:,0,:,:]))/(1+1e-6+(beta[None,None,0,None,:]*z_tf_reshape[:,:,0,:,:]))       \n",
        "\n",
        "        # print(outputs.shape)\n",
        "        \n",
        "        return outputs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Normalize_multichan(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    BatchNorm is where you calculate normalization factors for each dimension seperately based on\n",
        "    the batch data\n",
        "    LayerNorm is where you calculate the normalization factors based on channels and dimensions\n",
        "    Normalize_multichan calculates normalization factors based on all dimensions for each channel seperately\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,units=1):\n",
        "        super(Normalize_multichan,self).__init__()\n",
        "        self.units = units\n",
        "        \n",
        "    def get_config(self):\n",
        "         config = super().get_config()\n",
        "         config.update({\n",
        "             \"units\": self.units,\n",
        "         })\n",
        "         return config   \n",
        "             \n",
        "    def call(self,inputs):\n",
        "        inputs_perChan = tf.reshape(inputs,(-1,inputs.shape[-1]))\n",
        "        value_min = tf.reduce_min(inputs_perChan,axis=0)\n",
        "        value_max = tf.reduce_max(inputs_perChan,axis=0)\n",
        "        \n",
        "        # value_min = tf.expand_dims(value_min,axis=0)\n",
        "        R_norm = (inputs - value_min[None,None,None,None,:])/(value_max[None,None,None,None,:]-value_min[None,None,None,None,:])\n",
        "        R_norm_perChan = tf.reshape(R_norm,(-1,R_norm.shape[-1]))\n",
        "        R_mean = tf.reduce_mean(R_norm_perChan,axis=0)       \n",
        "        R_norm = R_norm - R_mean[None,None,None,None,:]\n",
        "        return R_norm\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "#(Saad)\n",
        "def get_weightsDict(model):\n",
        "    names = [weight.name for layer in model.layers for weight in layer.weights]\n",
        "    weights = model.get_weights()\n",
        "    weights_dict = {}\n",
        "    for i in range(len(names)):\n",
        "        weight_name = names[i][:-2]\n",
        "        weights_dict[weight_name] = np.atleast_1d(np.squeeze(weights[i]))\n",
        "    return weights_dict\n",
        "\t\t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Block functions for the model (Ines)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def conv_block(x, n_filters):\n",
        "    \"\"\"Conv2D then ReLU activation\"\"\"\n",
        "    x = layers.Conv2D(n_filters, 3, \n",
        "                      padding = \"same\", \n",
        "                      activation = \"relu\", \n",
        "                      kernel_initializer = \"he_normal\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def double_conv_block(x, n_filters):\n",
        "    \"\"\" 2 Conv2D \"\"\"\n",
        "    x = layers.Conv2D(n_filters, 3, \n",
        "                      padding = \"same\", \n",
        "                      activation = \"relu\", \n",
        "                      kernel_initializer = \"he_normal\")(x)\n",
        "\n",
        "    x = layers.Conv2D(n_filters, 3, \n",
        "                      padding = \"same\", \n",
        "                      activation = \"relu\", \n",
        "                      kernel_initializer = \"he_normal\")(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def downsample_block(x, n_filters):\n",
        "    \"\"\"conv_bloc, MaxPool and Dropout\"\"\"\n",
        "    f = conv_block(x, n_filters)\n",
        "    p = layers.MaxPool2D(2)(f)\n",
        "    p = layers.Dropout(0.3)(p)\n",
        "    return f, p\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def upsample_block(x, conv_features, n_filters):\n",
        "    \"\"\" Conv2DTranspose, concatenate, Dropout, conv_block\"\"\"\n",
        "\n",
        "    x = layers.Conv2DTranspose(n_filters, 2, 2, padding=\"same\")(x)\n",
        "\n",
        "    x = layers.concatenate([x, conv_features])\n",
        "\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = conv_block(x, n_filters)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Functions to build the models (Ines)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "def build_photo_unet_model(size, duration, photo, digit_max=10, depth =2, level=1, chan1_n = 9):\n",
        "    \n",
        "    \"\"\"\n",
        "    Builds a U-net model with the photoreceptors model, \n",
        "    then a convolutional U-net with \"depth\" blocks on each side.\n",
        "    \n",
        "    Args:\n",
        "    size: int, frame_size of the input\n",
        "    duration: int, duration of the movies\n",
        "    digit_max: int, default to 10\n",
        "    depth: int, number of blocks in the model on each side, default to 2\n",
        "    level: block at which we take the output (default to 1, but I tried pretraining on level 0, with downsampled labels...)\n",
        "    chan1_n: photoreceptor model parameter, default to 9\n",
        "    \n",
        "    Returns:\n",
        "    the model\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    n_filters = [10] + [32*2**i for i in range(depth)]\n",
        "    \n",
        "    # inputs\n",
        "    inputs = layers.Input(shape=(size,size,duration))\n",
        "    \n",
        "    #1st version\n",
        "    #inputs = layers.BatchNormalization()(inputs)\n",
        "    \n",
        "    if photo :\n",
        "        # Saad's photoreceptor layer\n",
        "\n",
        "        y = Reshape((inputs.shape[-1],inputs.shape[-3]*inputs.shape[-2]))(inputs)\n",
        "\n",
        "        y = photoreceptor_DA_multichan_randinit(units=chan1_n,kernel_regularizer=l2(1e-4))(y)\n",
        "\n",
        "        y = Reshape((1,inputs.shape[-3],inputs.shape[-2],chan1_n))(y)\n",
        "        y = y[:,0,:,:,:]      \n",
        "\n",
        "        inputs_unet = Activation('relu')(y) \n",
        "    \n",
        "    else:\n",
        "    \n",
        "    \tinputs_unet = inputs\n",
        "    \n",
        "    #2nd version  \n",
        "    norm_inputs = layers.BatchNormalization()(inputs_unet)\n",
        "    f_list, p_list = [], [norm_inputs]\n",
        "    \n",
        "    for i in range(depth):\n",
        "        f, p = downsample_block(p_list[-1], n_filters[i])\n",
        "        f_list.append(f)\n",
        "        p_list.append(p)\n",
        "        \n",
        "    bottleneck = double_conv_block(p_list[-1], n_filters[depth])\n",
        "    u_list = [bottleneck]\n",
        "    \n",
        "    for i in range(level+1):\n",
        "        u = upsample_block(u_list[-1], f_list[-i-1], n_filters[depth-i-1])\n",
        "        u_list.append(u)\n",
        "        \n",
        "    outputs = layers.Conv2D(digit_max+1, 1, \n",
        "                            padding=\"same\", \n",
        "                            activation = \"softmax\")(u_list[-1])\n",
        "                            \n",
        "    \n",
        "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
        "\n",
        "    return unet_model\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Data generator code from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly (Ines)\n",
        "#I ended up not using it because I had too many errors with the PR model...\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DataGenerator_frames(tf.keras.utils.Sequence):\n",
        "    \n",
        "    def __init__(self, data,labels,\n",
        "                 n_channels=1,\n",
        "                 n_classes=11, \n",
        "                 batch_size=64, \n",
        "                 n_digits = 5, \n",
        "                 upsample=True, frame_size = 280, \n",
        "                 downsample=False, pool_size=7, strides=7, final_size=4,\n",
        "                 movie=False, duration=5,\n",
        "                 digit_max=10,\n",
        "                 nb_batches = 500,\n",
        "                 shuffle=True\n",
        "                ):\n",
        "        \n",
        "        \n",
        "        #'Initialization'\n",
        "        \n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes  \n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        self.n_digits = n_digits\n",
        "        #n_frames = batch_size\n",
        "        self.upsample=upsample\n",
        "        self.frame_size = frame_size\n",
        "        self.downsample=downsample\n",
        "        self.pool_size=pool_size\n",
        "        self.strides=strides\n",
        "        self.final_size=final_size\n",
        "        self.movie=movie\n",
        "        self.duration = duration\n",
        "        self.digit_max = digit_max\n",
        "        \n",
        "        self.nb_batches = nb_batches\n",
        "        self.shuffle = shuffle\n",
        "        self.dim = (duration,self.frame_size,self.frame_size)\n",
        "\n",
        "    \n",
        "    def __len__(self):\n",
        "        #'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(self.nb_batches))\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation()\n",
        "\n",
        "        \n",
        "\n",
        "        return X, y\n",
        "        \n",
        "        \n",
        "    def __data_generation(self):\n",
        "\n",
        "            \n",
        "        X,y = generate_frames_dataset(digits_train, labels_train,\n",
        "                                      n_digits=self.n_digits, n_frames=self.batch_size, \n",
        "                                      upsample=self.upsample, frame_size=self.frame_size,\n",
        "                                      downsample=self.downsample, pool_size = self.pool_size, strides=self.strides,\n",
        "                                      final_size = self.final_size,\n",
        "                                      movie=self.movie, duration=self.duration,\n",
        "                                      digit_max = self.digit_max                                  \n",
        "                                      )\n",
        "\n",
        "        return X, y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DataGenerator_movies(tf.keras.utils.Sequence):\n",
        "    \n",
        "    def __init__(self, data,labels,\n",
        "                 n_channels=1,\n",
        "                 n_classes=11, \n",
        "                 batch_size=64, duration=5,\n",
        "                 frame_size=280, n_digits=5,\n",
        "                 depth=2, level=1,\n",
        "                 \n",
        "                shadow = False, shadow_ratio = 0.5, light_intensity = 0.1,\n",
        "                max_jump=1, max_value=254, speed=1,\n",
        "                digit_max = 10,\n",
        "\n",
        "                 nb_batches = 500,\n",
        "                 shuffle=True\n",
        "                ):\n",
        "        \n",
        "        \n",
        "        #'Initialization'\n",
        "        \n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes  \n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        #n_movies = batch_size\n",
        "        self.duration = duration\n",
        "        self.frame_size = frame_size\n",
        "        self.n_digits = n_digits\n",
        "        self.depth = depth\n",
        "        self.level = level\n",
        "        self.shadow = shadow\n",
        "        self.shadow_ratio = shadow_ratio\n",
        "        self.light_intensity = light_intensity\n",
        "        self.max_jump = max_jump\n",
        "        self.max_value = max_value\n",
        "        self.speed = speed        \n",
        "        self.digit_max = digit_max\n",
        "        \n",
        "        self.nb_batches = nb_batches\n",
        "        self.shuffle = shuffle\n",
        "        self.dim = (duration,self.frame_size,self.frame_size)\n",
        "    \n",
        "    def __len__(self):\n",
        "        #'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(self.nb_batches))\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation()\n",
        "        \n",
        "\n",
        "        return X, y\n",
        "\n",
        "        \n",
        "        \n",
        "    def __data_generation(self):\n",
        "\n",
        "            \n",
        "        X,y = generate_movie_dataset_5(digits_train, labels_train,  \n",
        "                                             n_movies = self.batch_size, duration = self.duration,\n",
        "                                            frame_size = self.frame_size, n_digits = self.n_digits,\n",
        "                                            depth = self.depth, level = self.level,\n",
        "                                            shadow = self.shadow, shadow_ratio = self.shadow_ratio, \n",
        "                                             light_intensity = self.light_intensity,\n",
        "                                            max_jump=self.max_jump, max_value=self.max_value, speed=self.speed,\n",
        "                                            digit_max = self.digit_max\n",
        "                                                      )\n",
        "\n",
        "        return X, y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Useful function to put arguments in the python command then get them in the script (Richard)\n",
        "def read_args(data):\n",
        "    for arg in sys.argv[1:]:\n",
        "        if arg.startswith(\"--\") and \"=\" in arg:\n",
        "            try:\n",
        "                name, value, type_var = arg[2:].split(\"=\")\n",
        "            except:\n",
        "                raise ValueError(f\"Unknown variable format {arg}\")\t\n",
        "\n",
        "            if name in data:\n",
        "\n",
        "                if type_var==\"bool\":\n",
        "\n",
        "                    value= value==\"True\"\n",
        "                elif type_var==\"int\":\n",
        "\n",
        "                    value=int(value)\n",
        "                elif type_var==\"float\":\n",
        "\n",
        "                    value=float(value)\n",
        "\n",
        "                data[name] = value\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown variable {name}\")\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown variable format {arg}\")"
      ]
    }
  ]
}