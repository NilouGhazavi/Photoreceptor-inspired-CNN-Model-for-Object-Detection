{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NilouGhazavi/Photoreceptor-inspired-CNN-Model-for-Object-Detection/blob/main/PRModel_with_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Functions**\n"
      ],
      "metadata": {
        "id": "MHmmBrOJyj2u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUP5kEXmM2ck"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import random as random\n",
        "import matplotlib.animation as animation\n",
        "import pandas as pd\n",
        "from random import sample\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.python.keras.utils.data_utils import Sequence\n",
        "from tensorflow.keras.layers import Input, InputLayer\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import Model, regularizers, Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Conv3D, Dense, Activation, Flatten, Reshape, MaxPool3D, MaxPool2D, Permute, BatchNormalization, GaussianNoise,DepthwiseConv2D, Dropout, LayerNormalization\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "import math\n",
        "import sys\n",
        "\n",
        "\n",
        "\n",
        "digit_max=10\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Dataset generating functions (Ines)\n",
        "\n",
        "\n",
        "def generate_frames_dataset(digits_set, labels_set, n_digits=5, n_frames=1000, \n",
        "                            upsample=True, frame_size=280, \n",
        "                            downsample=False, pool_size=7, strides=7, final_size=4, \n",
        "                            movie=False, duration=5, \n",
        "                            perturbations = False, perturbations_time=\"random\", perturbations_duration=2, half=False,\n",
        "                            spot_proba = 1, spot_factor=100, shadow_factor=0.5,\n",
        "                           digit_max = 10):\n",
        "    \n",
        "    \"\"\"Generates a dataset of frames with n_digits, with variable frame_size, and possibilitiy to downsample, or movies (with identical frames) if movie=True. Adds light perturbations if perturbations=True, that can be 2 frames long homogenous or half frame light or shadow, at a specific time or random time. \n",
        "    \n",
        "    Args:\n",
        "    digits_set: np.array of MNIST digits\n",
        "    labels_set: np.array of int type corresponding to the labels\n",
        "    n_digits: int\n",
        "    n_frames: int\n",
        "    upsample; bool, True or False\n",
        "    frame_size: if upsample, size of the frame after the upsampling, before the downsampling\n",
        "    downsample: bool, True or False\n",
        "    pool_size: int, if downsample\n",
        "    strides: int, if downsample\n",
        "    final_size: int\n",
        "    movie: bool, True or False\n",
        "    duration: int, if movie\n",
        "    perturbations: bool, whether to add spotlights and shadows\n",
        "    perturbations_time: str or int, when to start the 2-frames long perturbations\n",
        "    half: bool, whether to add the perturbations on only half of the frame (if False : homogeneous perturbation)\n",
        "    spot_proba: float, between 0 and 1, probability that the perturbation is a spotlight (0.5 if you want equiprobable spotlights and shadows)\n",
        "    spot_factor: float, by how much to multiply the light intensity\n",
        "    shadow_factor: float, but how much to multiply the light intensity as well ( < 1 )\n",
        "    digit_max: maximum of the classes labels, by default 10. Can be less, if you only want to work with some of the classes, and reduce the MNIST dataset you use.\n",
        "   \n",
        "    Returns:\n",
        "    dataset: np.array of frames (n_frames, final_size, final_size) or movies (n_frames, final_size, final_size, duration)\n",
        "    labels_set: np.array of set of digit_max frames, corresponding to the labels for each class (n_frames, final_size, final_size, digit_max+1)\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    digit_shape = np.shape(digits_set[0])\n",
        "    \n",
        "    digit_max = len(list(set(labels_set)))\n",
        "    frames = []\n",
        "    labels = []\n",
        "    \t\n",
        "    \t\n",
        "    if upsample:\n",
        "        \n",
        "        for i in range(n_frames):\n",
        "        \n",
        "            frame = np.zeros((frame_size, frame_size), dtype=\"float32\")\n",
        "            label = [np.zeros((frame_size, frame_size), dtype=\"float32\" ) for i in range(digit_max)]  #build empty frames and labels\n",
        "\n",
        "\n",
        "            indexes = random.sample(range(len(digits_set)), n_digits)  #select the MNIST digits, and get the corresponding labels\n",
        "            digits = digits_set[indexes]\n",
        "            digits_labels = labels_set[indexes]\n",
        "\n",
        "            positions = [random.sample(range(frame_size-digit_shape[0]-1),2) for i in range(n_digits)]  #choose the position of the digits\n",
        "            background = np.ones((frame_size, frame_size), dtype=\"float32\")\n",
        "\n",
        "            if downsample :\n",
        "                \n",
        "                new_frame_size, new_digits, new_positions = little_downsample(frame_size, digits, positions, pool_size, strides)\n",
        "                #computing the downsampled positions and digits\n",
        "                frame, label = create_frame_and_labels(new_frame_size, new_digits, digits_labels, new_positions, digit_max)\n",
        "            \n",
        "            else:\n",
        "                \n",
        "                frame, label = create_frame_and_labels(frame_size, digits, digits_labels, positions, digit_max)\n",
        "            \n",
        "            if movie:\n",
        "            \n",
        "            \tframe = [frame for i in range(duration)]  #making a movie out of identical frames\n",
        "            \t\n",
        "            \tif perturbations:  #adding spotlights and shadows\n",
        "            \t\n",
        "            \t\tframe = add_perturbations(frame, half, spot_proba, spot_factor, shadow_factor, perturbations_time, movie_duration, final_size)\n",
        "\n",
        "            labels.append(label)\n",
        "            frames.append(frame)\n",
        "        \n",
        "    else:  #if not upsampled\n",
        "    \n",
        "        for i in range(n_frames):\n",
        "\n",
        "            n = random.randint(0,len(digits_set)-1)\n",
        "\n",
        "            digit_label = labels_set[n]\n",
        "            \n",
        "            frame = digits_set[n]\n",
        "            label = label_mnist(frame, digit_label, digit_max)\n",
        "\n",
        "            \n",
        "            if downsample:\n",
        "                \n",
        "                new_frame_size, new_digits, new_positions = little_downsample(frame_size, [frame], [[0,0]], pool_size, strides)\n",
        "                frame, label = create_frame_and_labels(new_frame_size, new_digits, [digit_label], new_positions, digit_max)\n",
        "\n",
        "            \n",
        "            if movie:\n",
        "            \n",
        "            \tframe = [frame for i in range(duration)]\n",
        "\n",
        "            \tif perturbations:\n",
        "            \t\n",
        "            \t\tframe = add_perturbations(frame, half, spot_proba, spot_factor, shadow_factor, perturbations_time, perturbations_duration, duration)\n",
        "\t\t\t\t\n",
        "            labels.append(label)\n",
        "            frames.append(frame)\n",
        "            \n",
        "    dataset = np.array(frames)\n",
        "    labels_set = np.array(labels)\n",
        "\n",
        "    #getting the dimensions right for the model\n",
        "    if not movie:\n",
        "        dataset = dataset[:,:,:,None]\n",
        "        labels_set = np.transpose(labels_set, (0,2,3,1))\n",
        "    \n",
        "\n",
        "    dataset = np.transpose(dataset, (0,2,3,1))\n",
        "    labels_set = np.transpose(labels_set, (0,2,3,1))\n",
        "    \n",
        "    return dataset, labels_set\n",
        " \n",
        " \n",
        " \n",
        " \n",
        " \n",
        " \n",
        " \n",
        " \n",
        " \n",
        " \n",
        " \n",
        "\n",
        "\n",
        "def generate_movie_dataset_5(digits_set, labels_set, \n",
        "                            n_movies=1000, duration=5,\n",
        "                            frame_size = 280, n_digits=5,\n",
        "                            depth=2, level=1,\n",
        "                            shadow = False, shadow_ratio = 0.2, light_intensity = 0.1,\n",
        "                            max_jump=1, speed=1,\n",
        "                            digit_max = 10\n",
        "                            ):\n",
        "    \n",
        "    \"\"\"Generates a dataset of movies with moving digits\n",
        "    \n",
        "    Args:\n",
        "    digits_set: np.array of MNIST digits\n",
        "    labels_set: np.array of the corresponding labels\n",
        "    n_movies: int, number of movies\n",
        "    duration: int, duration of the movie\n",
        "    frame_size: int, size of the frame\n",
        "    n_digits: int, numer of digits\n",
        "    shadow: bool, True or False\n",
        "    shadow_ratio: float, usually 1/10**n, shadow surface/total surface, defines the radius. Reasonable circle size with ratio=0.3\n",
        "    light_intensity: float, usually 10**n, factor applied to pixels in the shadow\n",
        "    \n",
        "    Returns:\n",
        "    movies: np.array of movies, shape (n_movies, frame_size, frame_size, duration)\n",
        "    labels: np. array of frames labelling the last frame of each movie for each class\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    radius = int(frame_size*np.sqrt(shadow_ratio/np.pi))\n",
        "    \n",
        "    movies, labels = [], []\n",
        "    \n",
        "    label_size = frame_size/2**(depth-level-1)\n",
        "\n",
        "    digit_size = len(digits_set[0][0])\n",
        "    \n",
        "    for n in range(n_movies):\n",
        "        \n",
        "        # select the digits\n",
        "        \n",
        "        indexes = random.sample(range(len(digits_set)), n_digits)\n",
        "        \n",
        "        digits = digits_set[indexes]\n",
        "        digits_labels = labels_set[indexes]\n",
        "        \n",
        "        #Initial values for the positions and directions of the digits\n",
        "\t\t\n",
        "        positions = [random.sample(range(speed*max_jump, frame_size-digit_size-speed*max_jump),2) for i in range(n_digits)]\n",
        "        directions =  [non_null_sample(max_jump, 2) for i in range(n_digits)]\n",
        "\n",
        "        #create the movie and the movie labels\n",
        "        \n",
        "        movie = []\n",
        "        \n",
        "        for time in range(duration):\n",
        "\n",
        "            for k, digit in enumerate(digits):\n",
        "                \n",
        "                #Compute the new position\n",
        "                \n",
        "                position = new_position(positions[k], directions[k], speed)\n",
        "                positions[k] = position\n",
        "                \n",
        "                #Compute the next position to check it's going to be fine\n",
        "                \n",
        "                next_position = new_position(positions[k], directions[k], speed)\n",
        "\n",
        "                while out_of_frame(next_position, frame_size, digit_size):\n",
        "                \n",
        "                    #Correct the direction if next position is out of frame\n",
        "                    \n",
        "                    rebound_point = closest_frontier(next_position, frame_size, digit_size)\n",
        "                    directions[k] = mirror_direction(directions[k], rebound_point, frame_size)\n",
        "                    next_position = new_position(positions[k], directions[k], speed)\n",
        "\n",
        "                if in_the_center(positions[k], frame_size, speed, digit_size, max_jump):\n",
        "                \n",
        "                    #Randomly change the direction, if far enough from the walls\n",
        "                    directions[k] = change_direction(directions[k], max_jump)\n",
        "                    \n",
        "            #Create the frame with the positions of the digits       \n",
        "            frame = create_frame(frame_size, digits, positions)\n",
        "            \n",
        "\n",
        "            if shadow:\n",
        "                frame = add_shadow(frame, radius, light_intensity)\n",
        "                \n",
        "            movie.append(frame)\n",
        "            \n",
        "            if time == duration-1 :\n",
        "            \n",
        "                    #only label the last time step\n",
        "            \n",
        "                    movie_labels = create_labels(frame_size, digits, digits_labels, positions, digit_max)\n",
        "\n",
        "        movies.append(movie)\n",
        "        labels.append(movie_labels)\n",
        "        \n",
        "    #Get the right shape for the model\n",
        "    movies = np.transpose(movies, (0,2,3,1))\n",
        "    labels = np.transpose(labels, (0,2,3,1))\n",
        "        \n",
        "    return np.array(movies), np.array(labels)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Auxiliary functions for the generating functions (Ines)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def add_perturbations(frame, half, spot_proba, spot_factor, shadow_factor, perturbations_time, perturbations_duration, movie_duration):\n",
        "\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tAdds light level variations to a frame movie. Either on all the frame, or only half, either spotlight or shadow or both with a probability.\n",
        "\t\n",
        "\tArgs:\n",
        "\tframe: 28x28 np array\n",
        "\thalf: boolean\n",
        "\tspot_proba: 0 if only shadows, 1 if only spotlights, 0.5 if randomly one or the other.\n",
        "\tspot_factor: factor to multiply the pixel values if spotlight, usually 10**n\n",
        "\tshadow_factor: factor to multiply pixel values if shadow, usually 1/10**n\n",
        "\tperturbations_time: \"random\" by default, or int, has to be <= movie_duration-perturbations_duration\n",
        "\tperturbations_duration: int, in number of frames\n",
        "\tmovie_duration: int\n",
        "\tfinal_size: int, size of the frame\n",
        "\t\n",
        "\tReturns:\n",
        "\tframe: modified frame\n",
        "\t\n",
        "\t\"\"\"\n",
        "\tframe_size = len(frame)\n",
        "\n",
        "\tif perturbations_time==\"random\":\n",
        "\t\n",
        "\t\tstart_time = random.randint(0,movie_duration-perturbations_duration)\n",
        "\t\t\n",
        "\telse:\n",
        "\t\tstart_time = perturbations_time\n",
        "\t\t\n",
        "\tend_time = start_time + perturbations_duration -1\n",
        "\t\n",
        "\trandom_nb = np.random.random() #to decide if spotlight or shadow\n",
        "\n",
        "\n",
        "\tif half:\n",
        "\t\trandom_half = np.random.randint(0,2)\n",
        "\n",
        "\t\tif random_half==1: #low half perturbated\n",
        "\t\t\n",
        "\t\t\tnew_frames = []\n",
        "\t\t\tfor k in range(perturbations_duration):\n",
        "\t\t\t\n",
        "\t\t\t\tnew_frame = np.vstack([frame[start_time+k][:int(frame_size/2)] * ( (random_nb < spot_proba)*spot_factor + (random_nb >= spot_proba)*shadow_factor ) , frame[start_time+k][int(frame_size/2):]])\n",
        "\t\t\t\tnew_frames.append(new_frame)\n",
        "\t\t\t\t\n",
        "\t\telse: #top half perturbated\n",
        "\t\t\n",
        "\t\t\tnew_frames = []\n",
        "\t\t\tfor k in range(perturbations_duration):\n",
        "\t\t\t\n",
        "\t\t\t\tnew_frame = np.vstack([frame[start_time+k][:int(frame_size/2)], frame[start_time+k][int(frame_size/2):] * ( (random_nb < spot_proba)*spot_factor + (random_nb >= spot_proba)*shadow_factor )])\n",
        "\t\t\t\tnew_frames.append(new_frame)\n",
        "\n",
        "    \t\t\t\n",
        "\telse:  #homogeneous perturbation\n",
        "\t\n",
        "\t\tnew_frames = []\n",
        "\t\tfor k in range(perturbations_duration):\n",
        "\t\t\n",
        "\t\t\tnew_frame = frame[start_time+k] * ( (random_nb < spot_proba)*spot_factor + (random_nb >= spot_proba)*shadow_factor )\n",
        "\t\t\tnew_frames.append(new_frame)\n",
        "\n",
        "\tfor k in range(perturbations_duration):\n",
        "\t\n",
        "\t\tframe[start_time+k] = new_frames[k]\n",
        "\n",
        "\treturn frame\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def add_shadow(frame, radius, intensity):\n",
        "    \n",
        "    \"\"\"Adds a shadow on a frame.\n",
        "    \n",
        "    Args:\n",
        "    frame: np.array\n",
        "    radius: float\n",
        "    intensity: factor applied to the pixels in the shadow\n",
        "    \n",
        "    Returns:\n",
        "    shad_frame: np.array of the frame with the shadow\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    frame_size = len(frame)\n",
        "    shad_frame = frame.copy()\n",
        "    \n",
        "    for i,line in enumerate(frame):\n",
        "        for j,pixel in enumerate(line):\n",
        "            \n",
        "            x,y  = i - frame_size/2, j - frame_size/2\n",
        "            \n",
        "            if np.sqrt(x**2 + y**2) <= radius :\n",
        "                shad_frame[i,j] = intensity*frame[i,j]\n",
        "                \n",
        "    return shad_frame\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_labels(frame_size, digits, digits_labels, positions, digit_max):\n",
        "\n",
        "\n",
        "    \"\"\"Create the labels corresponding to a frame.\n",
        "    \n",
        "    Args:\n",
        "    frame_size: float\n",
        "    digits: MNIST digits present on the frame\n",
        "    digits_labels: labels of the digits\n",
        "    positions: 2-uple (x,y) for each digit\n",
        "    digit_max: 10\n",
        "    \n",
        "    Returns:\n",
        "    labels:frames corresponding to each class\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    labels = np.array([np.zeros((frame_size, frame_size)) for i in range(digit_max)]+ [np.ones((frame_size, frame_size))])\n",
        "\n",
        "    for k, digit in enumerate(digits):\n",
        "\n",
        "        \n",
        "        frame = labels[digits_labels[k]]\n",
        "\n",
        "\n",
        "\n",
        "        label_k = insert(digit, frame, positions[k])\n",
        "\n",
        "\n",
        "        labels[digits_labels[k]] = label_k\n",
        "\n",
        "\n",
        "        labels[-1] = np.maximum(labels[-1]-labels[digits_labels[k]], 0)\n",
        "        \n",
        "    return labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def label_mnist(digit_frame, digit, digit_max=10):\n",
        "\n",
        "\t\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tCreates the labels frames corresponding to an MNIST digit\n",
        "\t\n",
        "\tArgs:\n",
        "\tdigit_frame: 28x28 np array, MNIST digit directly\n",
        "\tdigit: int, MNIST label\n",
        "\tdigit_max: int, default to 10\n",
        "\t\n",
        "\tReturns:\n",
        "\tlabels: digit_max+1 frames, shape (digit_max+1, 28,28), with zeros on every frame but the digit frame, where the non zero MNIST pixels are =1.\n",
        "\t\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tlabels = [np.zeros(np.shape(digit_frame), dtype=\"float32\") for i in range(digit_max+1)]\n",
        "\n",
        "\tlabel = np.zeros(np.shape(digit_frame), dtype=\"float32\")\n",
        "\tfor i in range(len(digit_frame)):\n",
        "\t\tfor j in range(len(digit_frame[i])):\n",
        "\t    \t\tif digit_frame[i][j] != 0:\n",
        "\t    \t\t\tlabel[i][j] = 1\n",
        "\n",
        "\tlabels[digit] = label\n",
        "\tlabels[-1] = 1-label\n",
        "\n",
        "\treturn labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def insert(digit, frame, position):\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    Adds a digit in the frame. If there is already a digit, it has priority (the other is \"hidden\" behind)\n",
        "    \n",
        "    Args:\n",
        "    digit: 28x28 array\n",
        "    frame: array\n",
        "    position: x,y for the digit's top left corner\n",
        "    \n",
        "    Outputs:\n",
        "    frame: array\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    max_value = np.max(digit)\n",
        "    for i, line in enumerate(digit):\n",
        "\n",
        "        for j, pixel in enumerate(line):\n",
        "\n",
        "            frame_value = frame[position[0]+i, position[1]+j]\n",
        "            \n",
        "            if frame_value == 0 :\n",
        "                frame[position[0]+i, position[1]+j] = pixel\n",
        "                \n",
        "            #else : already a prioritary digit here\n",
        "\n",
        "    \n",
        "    return frame\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_frame_and_labels(frame_size, digits, digits_labels, positions, digit_max):\n",
        "    \n",
        "    \"\"\"Create a frame and the corresponding labels.\n",
        "    \n",
        "    Args:\n",
        "    frame_size: int\n",
        "    digits: np.array of MNIST digits to put on the frame\n",
        "    digits_labels: np.array of int labels corresponding to the digits\n",
        "    positions: 2-uple (x,y) for each digit\n",
        "    digit_max: 10\n",
        "    \n",
        "    Returns:\n",
        "    frame: the created frame\n",
        "    labels: the associated label frames for each class\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    frame = np.zeros((frame_size, frame_size))\n",
        "    background = np.ones((frame_size, frame_size))\n",
        "    labels = [np.zeros((frame_size, frame_size)) for i in range(digit_max)]\n",
        "    \n",
        "    for k, digit in enumerate(digits):\n",
        "        \n",
        "        digit_label = digits_labels[k]\n",
        "        position = positions[k]\n",
        "        \n",
        "        frame, labels[int(digit_label)], background = insert_and_label(digit, digit_label, frame, labels[int(digit_label)], position, background)\n",
        "        \n",
        "    labels.append(background)\n",
        "        \n",
        "    return np.array(frame), np.array(labels)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def insert_and_label(digit, digit_label, frame, proba, position, background):\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    Adds a digit to a frame and to the corresponding labels\n",
        "    \n",
        "    Args:\n",
        "    digit: MNIST digit\n",
        "    digit_label: int\n",
        "    frame: frame to insert the digit in\n",
        "    proba: label drame corresponding to the digit\n",
        "    position: (x,y) digit position\n",
        "    background: background frame in the labels\n",
        "    \n",
        "    Returns:\n",
        "    frame: modified frame\n",
        "    new_proba: modified label frame\n",
        "    background: modified background frame\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    new_proba = proba.copy()\n",
        "    max_value = np.max(digit)\n",
        "    \n",
        "    for i, line in enumerate(digit):\n",
        "        for j, pixel in enumerate(line):\n",
        "            \n",
        "            frame_value = frame[position[0]+i, position[1]+j]\n",
        "            \n",
        "            if frame_value == 0:\n",
        "                frame[position[0]+i, position[1]+j] = pixel\n",
        "                \n",
        "            #else : already a digit there, priority to the first arrived\n",
        "                \n",
        "            if pixel != 0:\n",
        "                \n",
        "                new_proba[position[0]+i][position[1]+j] = 1\n",
        "                background[position[0]+i][position[1]+j] = 0\n",
        "                #where a non-zero digit pixel is inserted, a one is inserted in the same position of the corresponding matrix\n",
        "\n",
        "\n",
        "    \n",
        "    return frame, new_proba, background\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def downsample_digit(digits_list, \n",
        "                     pool_size, strides\n",
        "                    ):\n",
        "                    \n",
        "    \"\"\"\n",
        "    \n",
        "    Downsamples digits\n",
        "    \n",
        "    Args:\n",
        "    digits_list: list of MNIST digits\n",
        "    pool_size: int, for the downsampling\n",
        "    strides: int, for the downsampling\n",
        "    \n",
        "    Returns:\n",
        "    down_digits: list of downsampled digits\n",
        "    new_digit_size: int\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    down_digits = []\n",
        "    \n",
        "    digit_size = len(digits_list[0][0])\n",
        "\n",
        "    \n",
        "    for digit in digits_list :\n",
        "\n",
        "\n",
        "        down_digit = []\n",
        "        line = 0\n",
        "\n",
        "        while line < len(digit[0])-pool_size+1 :\n",
        "            new_line = []\n",
        "            column = 0\n",
        "            while column < len(digit[0])-pool_size+1 :\n",
        "        \n",
        "                new_line.append(np.max( digit[line:line+pool_size, column:column+pool_size]))\n",
        "                column += strides\n",
        "        \n",
        "            line += strides\n",
        "            down_digit.append(new_line)\n",
        "        \n",
        "        down_digit= np.array(down_digit)\n",
        "\n",
        "\n",
        "        down_digits.append(down_digit)\n",
        "        new_digit_size = len(down_digits[0])\n",
        "        \n",
        "    return down_digits, new_digit_size\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def little_downsample(frame_size, digits, positions, pool_size, strides):\n",
        "    \n",
        "    \"\"\"Computes the new frame size, the new MNIST digits and their new positions after the downsampling. \n",
        "    Allows to create the downsampled frame rather then downsampling a frame, faster.\n",
        "    \n",
        "    Args:\n",
        "    frame_size; int, before downsampling\n",
        "    digits: MNIST digits\n",
        "    positions: 2-uple (x,y) for each digit\n",
        "    pool_size: int\n",
        "    strides: int\n",
        "    \n",
        "    Returns:\n",
        "    down_frame_size: int, new frame size\n",
        "    down_digits: np.array of new digits\n",
        "    down_positions: 2-uple of new (x,y) position for each digit\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    digit_size = len(digits[0][0])\n",
        "    \n",
        "    down_frame_size = (frame_size-pool_size)/strides +1\n",
        "    down_positions = []\n",
        "    down_digits = []\n",
        "    \n",
        "    for position in positions:\n",
        "        x,y = position\n",
        "        down_x, down_y = x//strides, y//strides\n",
        "        down_positions.append([down_x,down_y])\n",
        "        \n",
        "        \n",
        "    down_digits, digit_size = downsample_digit(digits, pool_size, strides)\n",
        "\n",
        "        \n",
        "    return int(down_frame_size), down_digits, down_positions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_frame(frame_size, digits, positions):\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    Creates the frame zith all the digits.\n",
        "    \n",
        "    Args:\n",
        "    frame_size: for a square frame\n",
        "    digits: list of 28x28 arrays\n",
        "    positions: list of x,y corresponding to the digits' top left corners, in the same order\n",
        "    \n",
        "    Outputs:\n",
        "    frame: 280x280 array\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    frame = np.zeros((frame_size, frame_size))\n",
        "    for k, digit in enumerate(digits):\n",
        "        position = positions[k]\n",
        "        frame = insert(digit, frame, position)\n",
        "    return frame\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def mirror_direction(direction, position, frame_size):\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    Finds the new direction when a digit rebounds on a wall.\n",
        "    \n",
        "    Args:\n",
        "    direction: current direction of the digit [dx,dy] \n",
        "    position: current position of the digit [x,y]\n",
        "    frame_size: for a square frame\n",
        "    \n",
        "    Outputs:\n",
        "    direction: [dx,dy]\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    dx, dy = direction\n",
        "    x,y = position\n",
        "    if (x==0 or x==frame_size-1) and y!=0 and y!=frame_size-1:\n",
        "        dx = -dx\n",
        "    if (y==0 or y==frame_size-1) and x!=0 and x!=frame_size-1:\n",
        "        dy = -dy\n",
        "    if (x==0 or x==frame_size-1) and (y==0 or y==frame_size-1):\n",
        "        dx, dy = -dx, -dy\n",
        "    return [dx, dy]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def change_direction(direction, max_jump):\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    Generates a slight change in direction, called with a small probability.\n",
        "    \n",
        "    Args:\n",
        "    direction: current direction [dx,dy]\n",
        "    max_jump: initially defined constant\n",
        "    \n",
        "    Outputs:\n",
        "    direction: new direction[dx,dy]\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    random_nb = random.random()\n",
        "    if random_nb < 0.05:\n",
        "        direction[0] = min(max_jump, max(-max_jump,direction[0]+1))\n",
        "        # to check that still between -max_jump and max_jump\n",
        "    elif random_nb >= 0.05 and random_nb < 0.1 :\n",
        "        direction[0] = min(max_jump, max(-max_jump,direction[0]-1))\n",
        "    if random_nb >= 0.1 and random_nb < 0.15:\n",
        "        direction[1] = min(max_jump, max(-max_jump,direction[1]+1))\n",
        "    elif random_nb >= 0.15 and random_nb < 0.2 :\n",
        "        direction[1] = min(max_jump, max(-max_jump,direction[1]-1))\n",
        "    return direction\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def closest_frontier(position, frame_size, digit_size):\n",
        "\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tFinds the closest point on the walls to a digit\n",
        "\t\n",
        "\tArgs:\n",
        "\tposition: (x,y) position of the top left corner of the digit\n",
        "\tframe_size: int\n",
        "\tdigit_size: int\n",
        "\t\n",
        "\tReturns:\n",
        "\t(x,y) position of the closest point on a wall\n",
        "\t\n",
        "\t\"\"\"\n",
        "    \n",
        "\tx,y = position\n",
        "\tneighbor_frontiers = [(frame_size-1,y), (0,y), (x, frame_size-1), (x,0)]\n",
        "\tdistances = []\n",
        "\tdistances.append(frame_size - (x+digit_size))\n",
        "\tdistances.append(x)\n",
        "\tdistances.append(frame_size - (y+digit_size))\n",
        "\tdistances.append(y)\n",
        "\treturn neighbor_frontiers[distances.index(min(distances))]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def non_null_sample(max_value, number):\n",
        "\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tSelects a number-uple of values different from (0,...,0) for the directions, usually (dx,dy) because 2D\n",
        "\t\n",
        "\tArgs:\n",
        "\tmax_value: int, max value to choose\n",
        "\tnumber: number of numbers to pick\n",
        "\t\n",
        "\tReturns:\n",
        "\tnumber-uple of values not all zero, usually (dx,dy)\n",
        "\t\n",
        "\t\"\"\"\n",
        "    \n",
        "\tvalues = list(np.arange(-max_value, max_value+1))\n",
        "\tsample = []\n",
        "\tfor i in range(number-1):\n",
        "\t\tsample.append(random.choice(values))\n",
        "\t#for the last value, we cannot add a zero if there are only zero in the selected values\n",
        "\tif list(set(sample)) != [0]:\n",
        "\t\tsample.append(random.choice(values))\n",
        "\telse:\n",
        "\t\tvalues.remove(0)\n",
        "\t\tsample.append(random.choice(values))\n",
        "\treturn sample\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def new_position(position, direction, speed):\n",
        "\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tComputes the new position from current position, direction and speed\n",
        "\t\n",
        "\tArgs:\n",
        "\tposition: (x,y) int \n",
        "\tdirection: (dx, dy) int\n",
        "\tspeed: int\n",
        "\t\n",
        "\tReturns:\n",
        "\t(x,y) new position : x += speed*dx\n",
        "\t\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tx,y = position\n",
        "\tdx, dy = direction\n",
        "\treturn [x+speed*dx, y+speed*dy]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def out_of_frame(position, frame_size, digit_size):\n",
        "\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tChecks whether a position would go out of the frame\n",
        "\t\n",
        "\tArgs:\n",
        "\tposition: (x,y) int\n",
        "\tframe_size: int\n",
        "\tdigit_size: int\n",
        "\t\n",
        "\tReturns:\n",
        "\tbool: True if out of frame\n",
        "\t\n",
        "\t\"\"\"\n",
        "\tfor i, dimension in enumerate(position) :\n",
        "\n",
        "\t\tif dimension + digit_size  > frame_size:\n",
        "\t\t\treturn True\n",
        "\t\tif dimension < 0:\n",
        "\t\t\treturn True\n",
        "\treturn False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def in_the_center(position, frame_size, speed, digit_size, max_jump):\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tChecks whether a digit is far enough from the walls (to randomly change direction without danger)\n",
        "\t\n",
        "\tArgs:\n",
        "\tposition: (x,y) int\n",
        "\tframe_size: int\n",
        "\tspeed: int\n",
        "\tdigit_size: int\n",
        "\tmax_jump: int\n",
        "\t\n",
        "\tReturns:\n",
        "\tbool: True if far enough from the walls\n",
        "\t\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tsecurity_distance = abs(speed*max_jump)+ digit_size\n",
        "\tfor dimension in position :\n",
        "\t\tif abs(frame_size-dimension)<security_distance or dimension < security_distance:\n",
        "\t    \t\treturn False\n",
        "\treturn True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_movie(movie, title, directory, time_interval=70):\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    Saves a movie in a directory in GIF format\n",
        "    \n",
        "    Args:\n",
        "    movie: np.array of dimension (n_frames, frame_size, frame_size)\n",
        "    title: string\n",
        "    directory: str of shape \"folder1/folder2/\"\n",
        "    time_interval: int, between two frames. 50 is fast, 150 is slow\n",
        "    \n",
        "    Returns:\n",
        "    nothing, the movie is saved.\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    fig, ax  = plt.subplots()\n",
        "    ims = []\n",
        "    for i, image in enumerate(movie):\n",
        "        im = ax.imshow((image), animated=True)\n",
        "        if i == 0:\n",
        "            ax.imshow(image) \n",
        "        ims.append([im])\n",
        "\n",
        "    gif = animation.ArtistAnimation(fig, ims, interval=time_interval, blit=True,\n",
        "                                repeat_delay=1000)\n",
        "    gif.save(directory+title+\".gif\")\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "#Custom metrics (Ines)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@tf.function(experimental_relax_shapes=True)\n",
        "def new_weighted_loss_0(y_true, y_pred):\n",
        "\n",
        "    \"\"\"\n",
        "    Counts the number of zeros and ones pixels on the labels, then applies the weights on all the frames based on the background to balance the digits and background classes (because a lot more zeros). Then computes the weighted cross-entropy loss (- mean of true_labels * weights * log(predictions) )\n",
        "    \n",
        "    Args:\n",
        "    y_true: true labels\n",
        "    y_pred: predictions\n",
        "    \n",
        "    Returns:\n",
        "    Cross-entropy loss\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    background = y_true[:, :,-1]\n",
        "    w1 = tf.reduce_sum(background)/tf.cast(tf.size(background), tf.float32)\n",
        "    w2 = 1-w1\n",
        "    w = background*w2 + (1-background)*w1\n",
        "    \n",
        "    #loss = tf.reduce_mean(w[:, :, None]*tf.square(tf.subtract(y_true, y_pred))) \n",
        "    #to broadcast (over channels)\n",
        "    #tf.print(tf.math.log(y_pred))\n",
        "\n",
        "    y_pred = tf.clip_by_value(y_pred, 0.0001, 0.9999)\n",
        "    term = w[:,:, None]* (y_true)* tf.math.log(y_pred) \n",
        "    loss =tf.reduce_mean(term)\n",
        "    #tf.print(loss)\n",
        "\n",
        "    return tf.math.abs(loss)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "@tf.function\n",
        "def new_weighted_loss(y_true, y_pred):\n",
        "\n",
        "    \"\"\"\n",
        "    Counts the number of zeros and ones pixels on the labels, then applies the weights on each frame separately to balance the zeros and ones classes (because a lot more zeros). Then computes the weighted cross-entropy loss (- mean of true_labels * weights * log(predictions) )\n",
        "    \n",
        "    Args:\n",
        "    y_true: true labels\n",
        "    y_pred: predictions\n",
        "    \n",
        "    Returns:\n",
        "    Cross-entropy loss\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    w1 = tf.reduce_sum(y_true)/tf.cast(tf.size(y_true), tf.float32)  #proportion of ones pixels\n",
        "    w2 = 1-w1   #proportion of zeros pixels\n",
        "    \n",
        "    N = len(y_true[0,0,0])  # number of classes\n",
        "    weights = tf.TensorArray(tf.float32, size=N)\n",
        "    \n",
        "    #now we build the weights matrix\n",
        "    \n",
        "    for i in range(N):\n",
        "    \n",
        "    \tframe = y_true[:,:,:,i]\n",
        "    \tweights_frame = frame*w2 + (1-frame)*w1   #ones pixels get the zeros pixels proportion as their weight, for each frame\n",
        "    \t\n",
        "    \tweights = weights.write(i, weights_frame)\n",
        "    \t\n",
        "    weights = tf.transpose(weights.stack(), (1, 2, 3, 0))\n",
        "        \n",
        "    y_pred = tf.clip_by_value(y_pred, 0.0001, 0.9999)\n",
        "    #to avoid log(0) that was causing an error\n",
        "    term = weights * (y_true)* tf.math.log(y_pred) \n",
        "    loss = - tf.reduce_mean(term)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@tf.function(experimental_relax_shapes=True)\n",
        "def my_accuracy(y_true, y_pred):\n",
        "\n",
        "\t\"\"\"\n",
        "\tComputes the mean of exp(-abs(relative_error)), only taking into account digit pixels, and not the background. Idea: to get a better range of the accuracy values, we could add a multiplying factor inside the exp.\n",
        "\t\n",
        "\tArgs:\n",
        "\ty_true: true labels\n",
        "\ty_pred: predictions\n",
        "\t\n",
        "\tReturns:\n",
        "\tnon-categorical accuracy\n",
        "\t\n",
        "\t\"\"\"\n",
        "\t\n",
        "\ty_true_digits = y_true[:,:,:,:-1]\n",
        "\ty_pred_digits = y_pred[:,:,:,:-1]\n",
        "\tbackground = y_true[:,:,:,:-1]\n",
        "\tn_classes = y_true.get_shape()[-1]-1\n",
        "\t\n",
        "\t#What I used in my runs\n",
        "\tsimilarity = tf.math.exp(- tf.math.abs( y_pred_digits - y_true_digits) )\n",
        "\t\n",
        "\t#What I realized on the presentation day would have been better\n",
        "\t#1. Using the relative error\n",
        "\t#2. Using a factor to decide how low the accuracy can go (right now, betwen 0.9 and 1...)\n",
        "\t#similarity = tf.math.exp(- tf.math.abs( factor * (y_pred_digits - y_true_digits)/y_true_digits )\n",
        "\t\n",
        "\n",
        "\n",
        "\tdigit_index = tf.math.argmax(tf.math.reduce_max(y_true[:,:,:,:-1], axis=(0,1,2))) \n",
        "\tdigit_frame = y_true_digits[:,:,:,digit_index]\t\n",
        "\t\n",
        "\tweighted_similarity = digit_frame[:,:,:,None] * similarity\n",
        "\n",
        "\n",
        "\n",
        "\tmy_accuracy = tf.cast(tf.reduce_sum( weighted_similarity ), tf.float32) / tf.cast(tf.math.count_nonzero(digit_frame) * n_classes, tf.float32)\n",
        "\t\n",
        "\treturn my_accuracy\n",
        "\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "@tf.function(experimental_relax_shapes=True)\n",
        "def my_cat_accuracy(y_true, y_pred):\n",
        "\n",
        "\t\"\"\"\n",
        "\tComputes the frequency of good predictions, choosing the maximum probability over the classes, only taking into account digit pixels, and not the background.\n",
        "\t\n",
        "\tArgs:\n",
        "\ty_true: true labels\n",
        "\ty_pred: predictions\n",
        "\t\n",
        "\tReturns:\n",
        "\tcategorical accuracy\n",
        "\t\n",
        "\t\"\"\"\n",
        "\n",
        "\tbackground = y_true[:,:,:,-1]\n",
        "\t\n",
        "\t#we \"force the network to choose\" by taking the maximum over the classes\n",
        "\tindexes_true = tf.math.argmax(y_true,axis=3)\n",
        "\tindexes_pred = tf.math.argmax(y_pred,axis=3)\n",
        "\t\n",
        "\t#the \"indexes\" are just one frame wih values between 0 and 10, indicating the class with the maximum probability for each pixel\n",
        "\n",
        "\t#find where the digit actually is\n",
        "\tdigit_index = tf.math.argmax(tf.math.reduce_max(y_true[:,:,:,:-1], axis=(0,1,2))) \n",
        "\t\n",
        "\t#the reduce_max is list of n_classes element, excluding the background. the max is the frame with the actual digit (the others are only zeros)\n",
        "\n",
        "\t#we count the pixels where the predicted class is correct, and is the digit (not background) \n",
        "\tacc = tf.math.reduce_sum(tf.cast((indexes_true == indexes_pred) & (indexes_true==digit_index), tf.float32)) / tf.cast(tf.math.count_nonzero(1-background), tf.float32)\n",
        "\n",
        "\treturn acc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Code for the photoreceptor model (Saad)\n",
        "\n",
        "\n",
        "def conv_oper_multichan(x,kernel_1D):\n",
        "\n",
        "    spatial_dims = x.shape[-1]\n",
        "    x_reshaped = tf.expand_dims(x,axis=2)\n",
        "    kernel_1D = tf.squeeze(kernel_1D,axis=0)\n",
        "    kernel_1D = tf.reverse(kernel_1D,[0])\n",
        "    tile_fac = tf.constant([spatial_dims,1])\n",
        "    kernel_reshaped = tf.tile(kernel_1D,(tile_fac))\n",
        "    kernel_reshaped = tf.reshape(kernel_reshaped,(1,spatial_dims,kernel_1D.shape[0],kernel_1D.shape[-1]))\n",
        "    kernel_reshaped = tf.experimental.numpy.moveaxis(kernel_reshaped,-2,0)\n",
        "    pad_vec = [[0,0],[kernel_1D.shape[0]-1,0],[0,0],[0,0]]\n",
        "    # # pad_vec = [[0,0],[0,0],[0,0],[0,0]]\n",
        "    # conv_output = tf.nn.conv2d(x_reshaped,kernel_reshaped,strides=[1,1,1,1],padding=pad_vec,data_format='NHWC')\n",
        "    conv_output = tf.nn.depthwise_conv2d(x_reshaped,kernel_reshaped,strides=[1,1,1,1],padding=pad_vec,data_format='NHWC')\n",
        "    \n",
        "    # print(conv_output.shape)\n",
        "    return conv_output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@tf.function()#experimental_relax_shapes=True)\n",
        "def slice_tensor(inp_tensor,shift_vals):\n",
        "    # print(inp_tensor.shape)\n",
        "    # print(shift_vals.shape)\n",
        "    shift_vals = shift_vals[:,tf.newaxis,:]\n",
        "    shift_vals = tf.tile(shift_vals,[1,inp_tensor.shape[-2],1])\n",
        "    tens_reshape = tf.reshape(inp_tensor,[-1,inp_tensor.shape[1]*inp_tensor.shape[2]*inp_tensor.shape[3]*inp_tensor.shape[4]])\n",
        "    # print('tens_reshape: ',tens_reshape.shape)\n",
        "    shift_vals_new = (inp_tensor.shape[1]-shift_vals[0])*(inp_tensor.shape[-1]*inp_tensor.shape[-2])\n",
        "    rgb = tf.range(0,shift_vals_new.shape[-1])\n",
        "    rgb = rgb[tf.newaxis,:]\n",
        "    rgb = tf.tile(rgb,[shift_vals_new.shape[0],1])\n",
        "    temp = tf.range(0,shift_vals_new.shape[-1]*shift_vals_new.shape[-2],shift_vals_new.shape[-1])\n",
        "    rgb = rgb+temp[:,None]\n",
        "    shift_vals_new = shift_vals_new + rgb\n",
        "    extracted_vals = tf.gather(tens_reshape,shift_vals_new,axis=1)\n",
        "    # print('extracted_vals: ',shift_vals.shape)\n",
        "    extracted_vals_reshaped = tf.reshape(extracted_vals,(-1,1,inp_tensor.shape[2],inp_tensor.shape[3],inp_tensor.shape[4]))\n",
        "    \n",
        "    return extracted_vals_reshaped\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_simple_filter_multichan(tau,n,t):\n",
        "    t_shape = t.shape[0]\n",
        "    t = tf.tile(t,tf.constant([tau.shape[-1]], tf.int32))\n",
        "    t = tf.reshape(t,(tau.shape[-1],t_shape))\n",
        "    t = tf.transpose(t)\n",
        "    f = (t**n[:,None])*tf.math.exp(-t/tau[:,None]) # functional form in paper\n",
        "    rgb = tau**(n+1)\n",
        "    f = (f/rgb[:,None])/tf.math.exp(tf.math.lgamma(n+1))[:,None] # normalize appropriately\n",
        "    # print(t.shape)\n",
        "    # print(n.shape)\n",
        "    # print(tau.shape)\n",
        "   \n",
        "    return f\n",
        "    \n",
        "class photoreceptor_DA_multichan_randinit(tf.keras.layers.Layer):\n",
        "    def __init__(self,units=1,kernel_regularizer=None):\n",
        "        super(photoreceptor_DA_multichan_randinit,self).__init__()\n",
        "        self.units = units\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        \n",
        "    def get_config(self):\n",
        "         config = super().get_config()\n",
        "         config.update({\n",
        "             \"units\": self.units,\n",
        "             \"kernel_regularizer\": self.kernel_regularizer\n",
        "         })\n",
        "         return config      \n",
        "               \n",
        "    def build(self,input_shape):    # random inits\n",
        "\n",
        "\n",
        "        # # # # Constant Values\n",
        "        # zeta_init = tf.keras.initializers.Constant(0.2) \n",
        "        # self.zeta = self.add_weight(name='zeta',initializer=zeta_init,shape=[1,self.units],trainable=False)\n",
        "        # zeta_mulFac = tf.keras.initializers.Constant(1000.) \n",
        "        # self.zeta_mulFac = self.add_weight(name='zeta_mulFac',initializer=zeta_mulFac,shape=[1,self.units],trainable=False)\n",
        "    \n",
        "        # # # you can have a costant value constant value for kappa\n",
        "        # kappa_init = tf.keras.initializers.Constant(0.13) \n",
        "        # self.kappa = self.add_weight(name='kappa',initializer=kappa_init,shape=[1,self.units],trainable=False)\n",
        "        # kappa_mulFac = tf.keras.initializers.Constant(1000.) \n",
        "        # self.kappa_mulFac = self.add_weight(name='kappa_mulFac',initializer=kappa_mulFac,shape=[1,self.units],trainable=False)\n",
        "\n",
        "        # # # # you can have a constant value for alpha \n",
        "        # alpha_init = tf.keras.initializers.Constant(0.0667) \n",
        "        # self.alpha = self.add_weight(name='alpha',initializer=alpha_init,shape=[1,self.units],trainable=False)\n",
        "        # alpha_mulFac = tf.keras.initializers.Constant(1000.) \n",
        "        # self.alpha_mulFac = self.add_weight(name='alpha_mulFac',initializer=alpha_mulFac,shape=[1,self.units],trainable=False)\n",
        "\n",
        "        # # # # you can have a constant value for beta \n",
        "        # beta_init = tf.keras.initializers.Constant(0) \n",
        "        # self.beta = self.add_weight(name='beta',initializer=beta_init,shape=[1,self.units],trainable=False)\n",
        "        # beta_mulFac = tf.keras.initializers.Constant(1000.) \n",
        "        # self.beta_mulFac = self.add_weight(name='beta_mulFac',initializer=beta_mulFac,shape=[1,self.units],trainable=False)\n",
        "\n",
        "        # # # you can have a costant value constant value for gamma\n",
        "        # gamma_init = tf.keras.initializers.Constant(0.1) \n",
        "        # self.gamma = self.add_weight(name='gamma',initializer=gamma_init,shape=[1,self.units],trainable=False)\n",
        "        # gamma_mulFac = tf.keras.initializers.Constant(10.) \n",
        "        # self.gamma_mulFac = self.add_weight(name='gamma_mulFac',initializer=gamma_mulFac,shape=[1,self.units],trainable=False)\n",
        "\n",
        "\n",
        "        # # # you can have a costant value constant value for tauY\n",
        "        # tauY_init = tf.keras.initializers.Constant(0.06) \n",
        "        # self.tauY = self.add_weight(name='tauY',initializer=tauY_init,shape=[1,self.units],trainable=False)\n",
        "        # tauY_mulFac = tf.keras.initializers.Constant(10.) \n",
        "        # self.tauY_mulFac = self.add_weight(name='tauY_mulFac',initializer=tauY_mulFac,shape=[1,self.units],trainable=False)\n",
        "\n",
        "        # # # you can have a costant value constant value for nY\n",
        "        # nY_init = tf.keras.initializers.Constant(0.1) \n",
        "        # self.nY = self.add_weight(name='nY',initializer=nY_init,shape=[1,self.units],trainable=False)\n",
        "        # nY_mulFac = tf.keras.initializers.Constant(10.) \n",
        "        # self.nY_mulFac = self.add_weight(name='nY_mulFac',initializer=nY_mulFac,shape=[1,self.units],trainable=False)\n",
        "\n",
        "        # # # you can have a costant value constant value for tauz\n",
        "        # tauZ_init = tf.keras.initializers.Constant(0.09) \n",
        "        # self.tauZ = self.add_weight(name='tauZ',initializer=tauZ_init,shape=[1,self.units],trainable=False)\n",
        "        # tauZ_mulFac = tf.keras.initializers.Constant(100.) \n",
        "        # self.tauZ_mulFac = self.add_weight(name='tauZ_mulFac',initializer=tauZ_mulFac,shape=[1,self.units],trainable=False)\n",
        "\n",
        "        # # # you can have a costant value constant value for nz\n",
        "        # nZ_init = tf.keras.initializers.Constant(0.09) \n",
        "        # self.nZ = self.add_weight(name='nZ',initializer=nZ_init,shape=[1,self.units],trainable=False)\n",
        "        # nZ_mulFac = tf.keras.initializers.Constant(10.) \n",
        "        # self.nZ_mulFac = self.add_weight(name='nZ_mulFac',initializer=nZ_mulFac,shape=[1,self.units],trainable=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Range of values for each parameter \n",
        "\n",
        "\n",
        "    \n",
        "## \n",
        "        \n",
        "        zeta_range = (0,1)\n",
        "        # zeta_range = (.02602935,.02602935000001)\n",
        "        # zeta_range = (.02,.02000001)\n",
        "        zeta_init = tf.keras.initializers.RandomUniform(minval=zeta_range[0],maxval=zeta_range[1]) #tf.keras.initializers.Constant(0.0159) \n",
        "        self.zeta = self.add_weight(name='zeta',initializer=zeta_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        zeta_mulFac = tf.keras.initializers.Constant(1000.) \n",
        "        self.zeta_mulFac = self.add_weight(name='zeta_mulFac',initializer=zeta_mulFac,shape=[1,self.units],trainable=False)\n",
        "        \n",
        "\n",
        "\n",
        "        # # you can have a range for kappa \n",
        "        kappa_range = (0,1)\n",
        "        # kappa_range = (0.05,0.0500001)\n",
        "        # kappa_range = (0.049,0.049000001)\n",
        "        kappa_init = tf.keras.initializers.RandomUniform(minval=kappa_range[0],maxval=kappa_range[1]) #tf.keras.initializers.Constant(0.0159) \n",
        "        self.kappa = self.add_weight(name='kappa',initializer=kappa_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        kappa_mulFac = tf.keras.initializers.Constant(1000.) \n",
        "        self.kappa_mulFac = self.add_weight(name='kappa_mulFac',initializer=kappa_mulFac,shape=[1,self.units],trainable=False)\n",
        "        \n",
        "\n",
        "\n",
        "        # # you can have a range for alpha \n",
        "        alpha_range = (0,1)\n",
        "        # alpha_range = (0.03487017,0.0348701700001)\n",
        "        # alpha_range = (0.05,0.05000001)\n",
        "        alpha_init = tf.keras.initializers.RandomUniform(minval=alpha_range[0],maxval=alpha_range[1]) #tf.keras.initializers.Constant(0.0159) \n",
        "        self.alpha = self.add_weight(name='alpha',initializer=alpha_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        alpha_mulFac = tf.keras.initializers.Constant(100.) \n",
        "        self.alpha_mulFac = self.add_weight(name='alpha_mulFac',initializer=alpha_mulFac,shape=[1,self.units],trainable=False)\n",
        "        \n",
        "\n",
        "\n",
        "        # # you can have a range for beta\n",
        "        beta_range = (0,1)\n",
        "        # beta_range = (0.02,0.02000001)\n",
        "        # beta_range = (0.04995,0.04995000001)\n",
        "        beta_init = tf.keras.initializers.RandomUniform(minval=beta_range[0],maxval=beta_range[1])  #tf.keras.initializers.Constant(0.02)# \n",
        "        self.beta = self.add_weight(name='beta',initializer=beta_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        beta_mulFac = tf.keras.initializers.Constant(10.) \n",
        "        self.beta_mulFac = self.add_weight(name='beta_mulFac',initializer=beta_mulFac,shape=[1,self.units],trainable=False)\n",
        " \n",
        "  \n",
        "\n",
        "        # # you can have a range for gamma\n",
        "        gamma_range = (0,1)\n",
        "        # gamma_range = (0.02,0.02000001)\n",
        "        gamma_init = tf.keras.initializers.RandomUniform(minval=gamma_range[0],maxval=gamma_range[1])  #tf.keras.initializers.Constant(0.075)# \n",
        "        self.gamma = self.add_weight(name='gamma',initializer=gamma_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        gamma_mulFac = tf.keras.initializers.Constant(10.) \n",
        "        self.gamma_mulFac = self.add_weight(name='gamma_mulFac',initializer=gamma_mulFac,shape=[1,self.units],trainable=False)\n",
        "\n",
        "\n",
        "        #You can have a rannge for tauy, multiplication factor is 1000 from frame 1 to frame 20 \n",
        "        tauY_range = (0,1)\n",
        "        # tauY_range = (0.02,0.0200001)\n",
        "        # tauY_range = (0.04997,0.04997000001)\n",
        "        tauY_init = tf.keras.initializers.RandomUniform(minval=tauY_range[0],maxval=tauY_range[1])  #tf.keras.initializers.Constant(0.01)# \n",
        "        self.tauY = self.add_weight(name='tauY',initializer=tauY_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        tauY_mulFac = tf.keras.initializers.Constant(100.) #tf.keras.initializers.Constant(100.) \n",
        "        self.tauY_mulFac = tf.Variable(name='tauY_mulFac',initial_value=tauY_mulFac(shape=(1,self.units),dtype='float32'),trainable=False)\n",
        " \n",
        "\n",
        "        # you can have a range for nY\n",
        "        nY_range = (0,1)\n",
        "        # nY_range = (0.02,0.0200001)\n",
        "        # nY_range = (0.02,0.02000001)\n",
        "        nY_init = tf.keras.initializers.RandomUniform(minval=nY_range[0],maxval=nY_range[1]) #tf.keras.initializers.Constant(0.01)# \n",
        "        self.nY = self.add_weight(name='nY',initializer=nY_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        nY_mulFac = tf.keras.initializers.Constant(10.) \n",
        "        self.nY_mulFac = tf.Variable(name='nY_mulFac',initial_value=nY_mulFac(shape=(1,self.units),dtype='float32'),trainable=False)\n",
        "\n",
        "\n",
        "        # you can have a range for tauz , multiplication factor is 100 from frame 2 to frame 20 \n",
        "        tauZ_range = (0,1)\n",
        "        # tauZ_range = (0.05,0.0500001)\n",
        "        # tauZ_range = (0.0208,0.0208000001)\n",
        "        tauZ_init = tf.keras.initializers.RandomUniform(minval=tauZ_range[0],maxval=tauZ_range[1]) #tf.keras.initializers.Constant(0.5)# \n",
        "        self.tauZ = self.add_weight(name='tauZ',initializer=tauZ_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        tauZ_mulFac = tf.keras.initializers.Constant(100.) \n",
        "        self.tauZ_mulFac = tf.Variable(name='tauZ_mulFac',initial_value=tauZ_mulFac(shape=(1,self.units),dtype='float32'),trainable=False)\n",
        "                \n",
        "\n",
        "        # you can have a range for nz\n",
        "        nZ_range = (0,1)\n",
        "        # nZ_range = (0.04983,0.04983000001)\n",
        "        nZ_init = tf.keras.initializers.RandomUniform(minval=nZ_range[0],maxval=nZ_range[1])  #tf.keras.initializers.Constant(0.01)# \n",
        "        self.nZ = self.add_weight(name='nZ',initializer=nZ_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        nZ_mulFac = tf.keras.initializers.Constant(10.) \n",
        "        self.nZ_mulFac = tf.Variable(name='nZ_mulFac',initial_value=nZ_mulFac(shape=(1,self.units),dtype='float32'),trainable=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# remove kc \n",
        "        # multiplication factor is 100 from frame 1 to frame 20 \n",
        "        tauC_range = (0.02,0.05)\n",
        "        tauC_init = tf.keras.initializers.RandomUniform(minval=tauC_range[0],maxval=tauC_range[1])  #tf.keras.initializers.Constant(0.2)# \n",
        "        self.tauC = self.add_weight(name='tauC',initializer=tauC_init,shape=[1,self.units],trainable=True,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,tauC_range[0],tauC_range[1]))\n",
        "        tauC_mulFac = tf.keras.initializers.Constant(100.) \n",
        "        self.tauC_mulFac = tf.Variable(name='tauC_mulFac',initial_value=tauC_mulFac(shape=(1,self.units),dtype='float32'),trainable=False)\n",
        "                \n",
        "        nC_range = (1e-5,0.2)\n",
        "        nC_init = tf.keras.initializers.RandomUniform(minval=nC_range[0],maxval=nC_range[1]) \n",
        "        self.nC = self.add_weight(name='nC',initializer=nC_init,shape=[1,self.units],trainable=False,regularizer=self.kernel_regularizer,constraint=lambda x: tf.clip_by_value(x,nC_range[0],nC_range[1]))\n",
        "        nC_mulFac = tf.keras.initializers.Constant(10.) \n",
        "        self.nC_mulFac = tf.Variable(name='nC_mulFac',initial_value=nC_mulFac(shape=(1,self.units),dtype='float32'),trainable=False)\n",
        "    \n",
        "    def call(self,inputs):\n",
        "       \n",
        "        timeBin = 1\n",
        "        \n",
        "        alpha =  self.alpha*self.alpha_mulFac\n",
        "        beta = self.beta*self.beta_mulFac\n",
        "        gamma =  self.gamma*self.gamma_mulFac\n",
        "        zeta = self.zeta*self.zeta_mulFac\n",
        "        kappa = self.kappa*self.kappa_mulFac\n",
        "        tau_y =  (self.tauY_mulFac*self.tauY) / timeBin\n",
        "        tau_z =  (self.tauZ_mulFac*self.tauZ) / timeBin\n",
        "        tau_c =  (self.tauC_mulFac*self.tauC) / timeBin\n",
        "        n_y =  (self.nY_mulFac*self.nY)\n",
        "        n_z =  (self.nZ_mulFac*self.nZ)\n",
        "        n_c =  (self.nC_mulFac*self.nC)\n",
        "        \n",
        "        # print('tau_z: ',tau_y.shape)\n",
        "        \n",
        "        t = tf.range(0,inputs.shape[1],dtype='float32')\n",
        "        \n",
        "        Ky = generate_simple_filter_multichan(tau_y,n_y,t)   \n",
        "        Kc = generate_simple_filter_multichan(tau_c,n_c,t)  \n",
        "        Kz = generate_simple_filter_multichan(tau_z,n_z,t) \n",
        "        # Kz = (gamma*Kc) + ((1-gamma) * Kz)\n",
        "        # replace kc by ky  \n",
        "        Kz = (gamma*Ky) + ((1-gamma) * Kz)\n",
        "        # print('Kz: ',Kz.shape)\n",
        "        \n",
        "        # Kz = Kz[None,0,:]\n",
        "        # print('Kz_new',Kz.shape)\n",
        "        \n",
        "        # print('inputs: ',inputs.shape)\n",
        "        y_tf = conv_oper_multichan(inputs,Ky)\n",
        "        z_tf = conv_oper_multichan(inputs,Kz)\n",
        "        # print('z_tf: ',z_tf.shape)\n",
        "               \n",
        "        y_tf_reshape = tf.reshape(y_tf,(-1,y_tf.shape[1],y_tf.shape[2],inputs.shape[-1],tau_z.shape[-1]))\n",
        "        z_tf_reshape = tf.reshape(z_tf,(-1,z_tf.shape[1],z_tf.shape[2],inputs.shape[-1],tau_z.shape[-1]))\n",
        "        # print('z_tf_reshape: ',z_tf_reshape.shape)\n",
        "        \n",
        "\n",
        "        ## For time distributed, remove these four lines:\n",
        "        \n",
        "        # y_shift = tf.math.argmax(Ky,axis=1);y_shift = tf.cast(y_shift,tf.int32)\n",
        "        # z_shift = tf.math.argmax(Kz,axis=1);z_shift = tf.cast(z_shift,tf.int32)\n",
        "        \n",
        "        # y_tf_reshape = slice_tensor(y_tf_reshape,y_shift)\n",
        "        # z_tf_reshape = slice_tensor(z_tf_reshape,z_shift)\n",
        "        # print('z_tf_slice: ',z_tf_reshape.shape)\n",
        "               \n",
        "    \n",
        "        outputs = (zeta[None,None,0,None,:] + (alpha[None,None,0,None,:]*y_tf_reshape[:,:,0,:,:]))/(kappa[None,None,0,None,:]+1e-6+(beta[None,None,0,None,:]*z_tf_reshape[:,:,0,:,:]))       \n",
        "\n",
        "        # set kappa=1, and zeta=0\n",
        "        # outputs = (0 + (alpha[None,None,0,None,:]*y_tf_reshape[:,:,0,:,:]))/(1+1e-6+(beta[None,None,0,None,:]*z_tf_reshape[:,:,0,:,:]))       \n",
        "\n",
        "        # print(outputs.shape)\n",
        "        \n",
        "        return outputs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Normalize_multichan(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    BatchNorm is where you calculate normalization factors for each dimension seperately based on\n",
        "    the batch data\n",
        "    LayerNorm is where you calculate the normalization factors based on channels and dimensions\n",
        "    Normalize_multichan calculates normalization factors based on all dimensions for each channel seperately\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,units=1):\n",
        "        super(Normalize_multichan,self).__init__()\n",
        "        self.units = units\n",
        "        \n",
        "    def get_config(self):\n",
        "         config = super().get_config()\n",
        "         config.update({\n",
        "             \"units\": self.units,\n",
        "         })\n",
        "         return config   \n",
        "             \n",
        "    def call(self,inputs):\n",
        "        inputs_perChan = tf.reshape(inputs,(-1,inputs.shape[-1]))\n",
        "        value_min = tf.reduce_min(inputs_perChan,axis=0)\n",
        "        value_max = tf.reduce_max(inputs_perChan,axis=0)\n",
        "        \n",
        "        # value_min = tf.expand_dims(value_min,axis=0)\n",
        "        R_norm = (inputs - value_min[None,None,None,None,:])/(value_max[None,None,None,None,:]-value_min[None,None,None,None,:])\n",
        "        R_norm_perChan = tf.reshape(R_norm,(-1,R_norm.shape[-1]))\n",
        "        R_mean = tf.reduce_mean(R_norm_perChan,axis=0)       \n",
        "        R_norm = R_norm - R_mean[None,None,None,None,:]\n",
        "        return R_norm\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "#(Saad)\n",
        "def get_weightsDict(model):\n",
        "    names = [weight.name for layer in model.layers for weight in layer.weights]\n",
        "    weights = model.get_weights()\n",
        "    weights_dict = {}\n",
        "    for i in range(len(names)):\n",
        "        weight_name = names[i][:-2]\n",
        "        weights_dict[weight_name] = np.atleast_1d(np.squeeze(weights[i]))\n",
        "    return weights_dict\n",
        "\t\t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Block functions for the model (Ines)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def conv_block(x, n_filters):\n",
        "    \"\"\"Conv2D then ReLU activation\"\"\"\n",
        "    x = layers.Conv2D(n_filters, 3, \n",
        "                      padding = \"same\", \n",
        "                      activation = \"relu\", \n",
        "                      kernel_initializer = \"he_normal\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def double_conv_block(x, n_filters):\n",
        "    \"\"\" 2 Conv2D \"\"\"\n",
        "    x = layers.Conv2D(n_filters, 3, \n",
        "                      padding = \"same\", \n",
        "                      activation = \"relu\", \n",
        "                      kernel_initializer = \"he_normal\")(x)\n",
        "\n",
        "    x = layers.Conv2D(n_filters, 3, \n",
        "                      padding = \"same\", \n",
        "                      activation = \"relu\", \n",
        "                      kernel_initializer = \"he_normal\")(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def downsample_block(x, n_filters):\n",
        "    \"\"\"conv_bloc, MaxPool and Dropout\"\"\"\n",
        "    f = conv_block(x, n_filters)\n",
        "    p = layers.MaxPool2D(2)(f)\n",
        "    p = layers.Dropout(0.3)(p)\n",
        "    return f, p\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def upsample_block(x, conv_features, n_filters):\n",
        "    \"\"\" Conv2DTranspose, concatenate, Dropout, conv_block\"\"\"\n",
        "\n",
        "    x = layers.Conv2DTranspose(n_filters, 2, 2, padding=\"same\")(x)\n",
        "\n",
        "    x = layers.concatenate([x, conv_features])\n",
        "\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = conv_block(x, n_filters)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Functions to build the models (Ines)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "def build_photo_unet_model(size, duration, photo, digit_max=10, depth =2, level=1, chan1_n = 9):\n",
        "    \n",
        "    \"\"\"\n",
        "    Builds a U-net model with the photoreceptors model, \n",
        "    then a convolutional U-net with \"depth\" blocks on each side.\n",
        "    \n",
        "    Args:\n",
        "    size: int, frame_size of the input\n",
        "    duration: int, duration of the movies\n",
        "    digit_max: int, default to 10\n",
        "    depth: int, number of blocks in the model on each side, default to 2\n",
        "    level: block at which we take the output (default to 1, but I tried pretraining on level 0, with downsampled labels...)\n",
        "    chan1_n: photoreceptor model parameter, default to 9\n",
        "    \n",
        "    Returns:\n",
        "    the model\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    n_filters = [10] + [32*2**i for i in range(depth)]\n",
        "    \n",
        "    # inputs\n",
        "    inputs = layers.Input(shape=(size,size,duration))\n",
        "    \n",
        "    #1st version\n",
        "    #inputs = layers.BatchNormalization()(inputs)\n",
        "    \n",
        "    if photo :\n",
        "        # Saad's photoreceptor layer\n",
        "\n",
        "        y = Reshape((inputs.shape[-1],inputs.shape[-3]*inputs.shape[-2]))(inputs)\n",
        "\n",
        "        y = photoreceptor_DA_multichan_randinit(units=chan1_n,kernel_regularizer=l2(1e-4))(y)\n",
        "\n",
        "        y = Reshape((1,inputs.shape[-3],inputs.shape[-2],chan1_n))(y)\n",
        "        y = y[:,0,:,:,:]      \n",
        "\n",
        "        inputs_unet = Activation('relu')(y) \n",
        "    \n",
        "    else:\n",
        "    \n",
        "    \tinputs_unet = inputs\n",
        "    \n",
        "    #2nd version  \n",
        "    norm_inputs = layers.BatchNormalization()(inputs_unet)\n",
        "    f_list, p_list = [], [norm_inputs]\n",
        "    \n",
        "    for i in range(depth):\n",
        "        f, p = downsample_block(p_list[-1], n_filters[i])\n",
        "        f_list.append(f)\n",
        "        p_list.append(p)\n",
        "        \n",
        "    bottleneck = double_conv_block(p_list[-1], n_filters[depth])\n",
        "    u_list = [bottleneck]\n",
        "    \n",
        "    for i in range(level+1):\n",
        "        u = upsample_block(u_list[-1], f_list[-i-1], n_filters[depth-i-1])\n",
        "        u_list.append(u)\n",
        "        \n",
        "    outputs = layers.Conv2D(digit_max+1, 1, \n",
        "                            padding=\"same\", \n",
        "                            activation = \"softmax\")(u_list[-1])\n",
        "                            \n",
        "    \n",
        "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
        "\n",
        "    return unet_model\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Data generator code from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly (Ines)\n",
        "#I ended up not using it because I had too many errors with the PR model...\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DataGenerator_frames(tf.keras.utils.Sequence):\n",
        "    \n",
        "    def __init__(self, data,labels,\n",
        "                 n_channels=1,\n",
        "                 n_classes=11, \n",
        "                 batch_size=64, \n",
        "                 n_digits = 5, \n",
        "                 upsample=True, frame_size = 280, \n",
        "                 downsample=False, pool_size=7, strides=7, final_size=4,\n",
        "                 movie=False, duration=5,\n",
        "                 digit_max=10,\n",
        "                 nb_batches = 500,\n",
        "                 shuffle=True\n",
        "                ):\n",
        "        \n",
        "        \n",
        "        #'Initialization'\n",
        "        \n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes  \n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        self.n_digits = n_digits\n",
        "        #n_frames = batch_size\n",
        "        self.upsample=upsample\n",
        "        self.frame_size = frame_size\n",
        "        self.downsample=downsample\n",
        "        self.pool_size=pool_size\n",
        "        self.strides=strides\n",
        "        self.final_size=final_size\n",
        "        self.movie=movie\n",
        "        self.duration = duration\n",
        "        self.digit_max = digit_max\n",
        "        \n",
        "        self.nb_batches = nb_batches\n",
        "        self.shuffle = shuffle\n",
        "        self.dim = (duration,self.frame_size,self.frame_size)\n",
        "\n",
        "    \n",
        "    def __len__(self):\n",
        "        #'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(self.nb_batches))\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation()\n",
        "\n",
        "        \n",
        "\n",
        "        return X, y\n",
        "        \n",
        "        \n",
        "    def __data_generation(self):\n",
        "\n",
        "            \n",
        "        X,y = generate_frames_dataset(digits_train, labels_train,\n",
        "                                      n_digits=self.n_digits, n_frames=self.batch_size, \n",
        "                                      upsample=self.upsample, frame_size=self.frame_size,\n",
        "                                      downsample=self.downsample, pool_size = self.pool_size, strides=self.strides,\n",
        "                                      final_size = self.final_size,\n",
        "                                      movie=self.movie, duration=self.duration,\n",
        "                                      digit_max = self.digit_max                                  \n",
        "                                      )\n",
        "\n",
        "        return X, y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DataGenerator_movies(tf.keras.utils.Sequence):\n",
        "    \n",
        "    def __init__(self, data,labels,\n",
        "                 n_channels=1,\n",
        "                 n_classes=11, \n",
        "                 batch_size=64, duration=5,\n",
        "                 frame_size=280, n_digits=5,\n",
        "                 depth=2, level=1,\n",
        "                 \n",
        "                shadow = False, shadow_ratio = 0.5, light_intensity = 0.1,\n",
        "                max_jump=1, max_value=254, speed=1,\n",
        "                digit_max = 10,\n",
        "\n",
        "                 nb_batches = 500,\n",
        "                 shuffle=True\n",
        "                ):\n",
        "        \n",
        "        \n",
        "        #'Initialization'\n",
        "        \n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes  \n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        #n_movies = batch_size\n",
        "        self.duration = duration\n",
        "        self.frame_size = frame_size\n",
        "        self.n_digits = n_digits\n",
        "        self.depth = depth\n",
        "        self.level = level\n",
        "        self.shadow = shadow\n",
        "        self.shadow_ratio = shadow_ratio\n",
        "        self.light_intensity = light_intensity\n",
        "        self.max_jump = max_jump\n",
        "        self.max_value = max_value\n",
        "        self.speed = speed        \n",
        "        self.digit_max = digit_max\n",
        "        \n",
        "        self.nb_batches = nb_batches\n",
        "        self.shuffle = shuffle\n",
        "        self.dim = (duration,self.frame_size,self.frame_size)\n",
        "    \n",
        "    def __len__(self):\n",
        "        #'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(self.nb_batches))\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation()\n",
        "        \n",
        "\n",
        "        return X, y\n",
        "\n",
        "        \n",
        "        \n",
        "    def __data_generation(self):\n",
        "\n",
        "            \n",
        "        X,y = generate_movie_dataset_5(digits_train, labels_train,  \n",
        "                                             n_movies = self.batch_size, duration = self.duration,\n",
        "                                            frame_size = self.frame_size, n_digits = self.n_digits,\n",
        "                                            depth = self.depth, level = self.level,\n",
        "                                            shadow = self.shadow, shadow_ratio = self.shadow_ratio, \n",
        "                                             light_intensity = self.light_intensity,\n",
        "                                            max_jump=self.max_jump, max_value=self.max_value, speed=self.speed,\n",
        "                                            digit_max = self.digit_max\n",
        "                                                      )\n",
        "\n",
        "        return X, y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Useful function to put arguments in the python command then get them in the script (Richard)\n",
        "def read_args(data):\n",
        "    for arg in sys.argv[1:]:\n",
        "        if arg.startswith(\"--\") and \"=\" in arg:\n",
        "            try:\n",
        "                name, value, type_var = arg[2:].split(\"=\")\n",
        "            except:\n",
        "                raise ValueError(f\"Unknown variable format {arg}\")\t\n",
        "\n",
        "            if name in data:\n",
        "\n",
        "                if type_var==\"bool\":\n",
        "\n",
        "                    value= value==\"True\"\n",
        "                elif type_var==\"int\":\n",
        "\n",
        "                    value=int(value)\n",
        "                elif type_var==\"float\":\n",
        "\n",
        "                    value=float(value)\n",
        "\n",
        "                data[name] = value\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown variable {name}\")\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown variable format {arg}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Mounting the Drive**\n"
      ],
      "metadata": {
        "id": "OopBEp0vy57T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwQhk57UN7Yx",
        "outputId": "236b3ba8-13d2-4ed0-e503-869dba7d520a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path_to_module= '/content/drive/MyDrive/PhD-Nilou/Project#3_DynamicCoding/Nilou_Codes'\n",
        "import sys\n",
        "sys.path.append(path_to_module)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import the libraries**"
      ],
      "metadata": {
        "id": "AAQxukTvzFfR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFYAJMdMOEih",
        "outputId": "4e67a44b-5798-4d91-ca62-4e1fd1a1e184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting JSAnimation\n",
            "  Downloading JSAnimation-0.1.tar.gz (8.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Building wheels for collected packages: JSAnimation\n",
            "  Building wheel for JSAnimation (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for JSAnimation: filename=JSAnimation-0.1-py3-none-any.whl size=11407 sha256=72a381835f7f9ff988cf7262dde3b7e2a85668516860bdd93a793ac76a2dc61a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/16/64/028f540fe8f5eae5026a423bfd88356248074379b79f27b646\n",
            "Successfully built JSAnimation\n",
            "Installing collected packages: JSAnimation\n",
            "Successfully installed JSAnimation-0.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# install libraries \n",
        "!pip install matplotlib JSAnimation\n",
        "!apt install ffmpeg\n",
        "!pip install -q imageio\n",
        "!pip install -q imageio-ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPdL27zyOSlF"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "# import the libraries \n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation, FFMpegWriter\n",
        "from JSAnimation import IPython_display\n",
        "from IPython.display import HTML\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import cv2\n",
        "\n",
        "\n",
        "# from functions2 import *\n",
        "\n",
        "\n",
        "# Importing necessary libraries\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "# Keras Sequential Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# Importing all the different layers and optimizers\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation, LeakyReLU, TimeDistributed, GlobalAveragePooling1D,Concatenate,Lambda,Input\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from skimage.draw import line\n",
        "\n",
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "from matplotlib.animation import FFMpegWriter\n",
        "from IPython.display import FileLink"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load the MNIST Dataset**"
      ],
      "metadata": {
        "id": "yUOTJPWMzVxn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGlI-xePObbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea984564-35c8-42ee-b76b-c36708c79cac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "## Load MNIST Data\n",
        "\n",
        "# Set a fixed seed value ( to have the same testing dataset )\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42) \n",
        "\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "\n",
        "# image as an input to the CNN model\n",
        "# input_shape = (28, 28, 1)\n",
        "\n",
        "# movie as an input with PR model or time-distributed\n",
        "input_shape = (20, 28, 28)\n",
        "\n",
        "# movie as an input without PR model \n",
        "input_shape_2=(28,28,20)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train_n1 = x_train.astype(\"float32\") / 255\n",
        "x_test_n1 = x_test.astype(\"float32\") / 255\n",
        "\n",
        "# make sure images shape is train=(60000, 28, 28, 1) and test=(10000,28,28,1)\n",
        "x_train_n=np.expand_dims(x_train_n1, -1)\n",
        "x_test_n=np.expand_dims(x_test_n1, -1)\n",
        "\n",
        "\n",
        "# #convert class vectors to binary class matrices ( one hot encoded)\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Apply Gaussian Noise to the Data**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XlCAjZOBz0W3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_O8-LPVO3QF"
      },
      "outputs": [],
      "source": [
        "## Use DataGenerator to apply Gaussian Noise\n",
        "\n",
        "# def add_gaussian_noise(image):\n",
        "#     noise = np.random.normal(0,0.1, image.shape)\n",
        "#     noisy_image = image + noise\n",
        "#     noisy_image = np.clip(noisy_image, 0, 1)\n",
        "#     return noisy_image\n",
        "\n",
        "# # Define the ImageDataGenerator with the custom preprocessing function\n",
        "# datagen = ImageDataGenerator(preprocessing_function=add_gaussian_noise)\n",
        "\n",
        "# # Initialize an empty array to hold the augmented data\n",
        "# x_train_augmented = np.empty_like(x_train_n)\n",
        "# y_train_augmented = np.empty_like(y_train)\n",
        "# x_test_augmented = np.empty_like(x_test_n)\n",
        "# y_test_augmented = np.empty_like(y_test)\n",
        "\n",
        "# # Set the batch size\n",
        "# batch_size = 128\n",
        "\n",
        "# # Create a generator that will generate augmented samples from the original dataset\n",
        "# train_iterator = datagen.flow(x_train_n, y_train, batch_size=batch_size)\n",
        "# test_iterator = datagen.flow(x_test_n, y_test, batch_size=batch_size)\n",
        "\n",
        "# # Iterate through the generator and store the augmented samples\n",
        "# for i, (x_batch, y_batch) in enumerate(train_iterator):\n",
        "#     start_idx = i * batch_size\n",
        "#     end_idx = start_idx + x_batch.shape[0]\n",
        "    \n",
        "#     x_train_augmented[start_idx:end_idx] = x_batch\n",
        "#     y_train_augmented[start_idx:end_idx] = y_batch\n",
        "    \n",
        "#     if end_idx >= x_train.shape[0]:\n",
        "#         break\n",
        "\n",
        "# # Iterate through the generator and store the augmented samples\n",
        "# for i, (x_batch, y_batch) in enumerate(test_iterator):\n",
        "#     start_idx = i * batch_size\n",
        "#     end_idx = start_idx + x_batch.shape[0]\n",
        "    \n",
        "#     x_test_augmented[start_idx:end_idx] = x_batch\n",
        "#     y_test_augmented[start_idx:end_idx] = y_batch\n",
        "    \n",
        "#     if end_idx >= x_test.shape[0]:\n",
        "#         break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sD6K2ZcCO8b_"
      },
      "outputs": [],
      "source": [
        "# Define augmented data \n",
        "\n",
        "# x_test_aug=x_test_augmented\n",
        "# y_test_aug=y_test_augmented \n",
        "# x_train_aug=x_train_augmented\n",
        "# y_train_aug=y_train_augmented\n",
        "# # reshape \n",
        "# x_test_aug=np.squeeze(x_test_aug, axis=-1)\n",
        "# x_train_aug=np.squeeze(x_train_aug, axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create a movie with no mask ( Train Dataset)**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EdMivrIA0H8b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3ITJj6LPH32"
      },
      "outputs": [],
      "source": [
        "# Create a movie with no mask (with labels)\n",
        "def create_movie(data,labels,repeats):\n",
        "  n_samples, img_height, img_width=data.shape\n",
        "  movie_labels=np.zeros((n_samples, num_classes), dtype=int)\n",
        "  movie_data=np.zeros((n_samples,repeats,img_height,img_width,1),dtype=np.float32)\n",
        "  for i in range(n_samples):\n",
        "    movie_data[i]=np.repeat(data[i][np.newaxis, :, :, np.newaxis], repeats, axis=0)\n",
        "\n",
        "  movie_labels[i] = labels[i]\n",
        "  return movie_data,movie_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rb_rymtUPMgO"
      },
      "outputs": [],
      "source": [
        "# Augmented Data/noisy image: create movie for train dataset \n",
        "# # number of frames \n",
        "# repeats=20\n",
        "# x_train_movie, movie_labels_train=create_movie(x_train_aug,y_train_aug,repeats)\n",
        "# x_train_movie_sq=np.squeeze(x_train_movie, axis=-1)\n",
        "# # reshape\n",
        "# x_train_movie_reshaped=np.transpose(x_train_movie_sq,(0,2,3,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZSWwAsvbtF_"
      },
      "outputs": [],
      "source": [
        "# Clean images: create movie for train dataset \n",
        "# number of frames \n",
        "repeats=20\n",
        "x_train_movie, movie_labels_train=create_movie(x_train,y_train,repeats)\n",
        "x_train_movie_sq=np.squeeze(x_train_movie, axis=-1)\n",
        "# reshape\n",
        "x_train_movie_reshaped=np.transpose(x_train_movie_sq,(0,2,3,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxmiaRMsu9XR"
      },
      "outputs": [],
      "source": [
        "# label per frame \n",
        "y_train_frames=np.repeat(y_train,repeats, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualize the train dataset**"
      ],
      "metadata": {
        "id": "1WNEK-dP0m9t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srUg_Z6rPdX1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function to update the frames in the animation ( reshaped dataset )\n",
        "# def update(i):\n",
        "#     im.set_array(x_train_movie_sq[movie_index, i, :, :])\n",
        "#     # frame_label = str(np.argmax(y_train[movie_index * repeats + i]))\n",
        "    \n",
        "#     frame_label = str(np.argmax(y_train_frames[movie_index* repeats + i]))\n",
        "#     ax.set_title(f\"Frame {i+1}, True label: {frame_label}\")\n",
        "#     return [im]\n",
        "\n",
        "# # Choose which movie in the dataset to visualize\n",
        "# movie_index = 7\n",
        "\n",
        "# # true_label=str(np.argmax(y_train[movie_index]))\n",
        "# true_label = str(np.argmax(y_train_frames[movie_index * repeats + i]))\n",
        "\n",
        "# # Create the initial plot\n",
        "# fig, ax = plt.subplots()\n",
        "# im = ax.imshow(x_train_movie_sq[ movie_index, 0, :, :], interpolation='none')\n",
        "\n",
        "# # plt.axis('off')\n",
        "\n",
        "# # set the title with the true label \n",
        "# ax.set_title(f\"True label: {true_label}\")\n",
        "\n",
        "# # Create the animation\n",
        "# ani = FuncAnimation(fig, update, frames=20, interval=200, blit=True)\n",
        "\n",
        "# # Display the animation\n",
        "# HTML(ani.to_jshtml())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-xIlpTxPigR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "4ee02bd6-3141-440f-904c-f5527f1f637b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-dc0065259304>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# save animation as an MP4 video file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFFMpegWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Me'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbitrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mani\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"animation12.mp4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0manimation_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/PhD-Nilou/Project#3_DynamicCoding/Nilou_Codes/Animations/Train Dataset/animation12.mp4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mani\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manimation_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ani' is not defined"
          ]
        }
      ],
      "source": [
        "# save animation as an MP4 video file\n",
        "writer=FFMpegWriter(fps=15,metadata=dict(artist='Me'),bitrate=1800)\n",
        "ani.save(\"animation12.mp4\",writer=writer)\n",
        "animation_path = '/content/drive/MyDrive/PhD-Nilou/Project#3_DynamicCoding/Nilou_Codes/Animations/Train Dataset/animation12.mp4'\n",
        "ani.save(animation_path, writer=writer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-FmbJB_l-kT"
      },
      "outputs": [],
      "source": [
        "# the index of the sample you want to display\n",
        "sample_index =300\n",
        "# the number of frames in each image\n",
        "num_frames =20\n",
        "repeats=20\n",
        "fig, axs = plt.subplots(1, num_frames, figsize=(50, 30), subplot_kw={'aspect': 'equal'})\n",
        "\n",
        "# loop through the frames and display each one separately\n",
        "for i in range(num_frames):\n",
        "    frame_label = str(np.argmax(y_train_frames[sample_index * repeats + i]))\n",
        "    axs[i].set_title(f\"Frame {i+1}, True label: {frame_label}\")\n",
        "    axs[i].imshow(x_train_movie[sample_index, i, :, :, 0])\n",
        "    \n",
        "    \n",
        "\n",
        "    # axs[i].axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Applying Masks to the Test Dataset**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t-N-Z3LP2l8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Binary mask**\n"
      ],
      "metadata": {
        "id": "-RzGISz93oUO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yexUxlvVPjOE"
      },
      "outputs": [],
      "source": [
        "## Binary Mask \n",
        "def modify_brightness_mask7(img,spotlight_intensity):\n",
        "  image_shape = img.shape\n",
        "\n",
        "  # Create a binary mask with the same shape as an MNIST image\n",
        "  mask_2d = np.random.randint(0,5, size=image_shape)\n",
        "\n",
        "  # Shuffle the indices in the 2D mask\n",
        "  shuffled_indices = np.random.permutation(np.arange(mask_2d.size))\n",
        "\n",
        "  # Apply the shuffled indices to the 2D mask ( flatten into 1D)\n",
        "  shuffled_mask = mask_2d.reshape(-1)[shuffled_indices]\n",
        "\n",
        "  # Reshape the shuffled mask back to the original image shape\n",
        "  shuffled_mask_2d = shuffled_mask.reshape(image_shape)\n",
        "\n",
        "\n",
        "\n",
        "      # Apply Gaussian blur to the mask (reduce sharp edges)\n",
        "  blurred_mask = gaussian_filter(shuffled_mask_2d, sigma=1)\n",
        "\n",
        "    # Normalize the blurred mask to the range [0, 1]\n",
        "  normalized_blurred_mask = blurred_mask / np.max(blurred_mask)\n",
        "  \n",
        "  # Normalize input data \n",
        "  normalized_img = img / 255.0\n",
        "\n",
        "    # Apply the mask to the image using element-wise addition\n",
        "  masked_image = normalized_img + normalized_blurred_mask\n",
        "\n",
        "    # Clip the values of the masked_image to the range [0, 1]\n",
        "  masked_image = np.clip(masked_image, 0, 1)\n",
        "\n",
        "    # Rescale the masked_image back to the range [0, 255]\n",
        "  masked_image = (masked_image * 255).astype(np.uint8)\n",
        "\n",
        "  # apply mask\n",
        "  img_mod = img.copy()\n",
        "  img_mod=img_mod*((masked_image*spotlight_intensity)+1)\n",
        "      \n",
        "  return img_mod"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Binary mask2**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I2n5Ydmb3viH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDRpqkY1OJXX"
      },
      "outputs": [],
      "source": [
        "# Rectangular mask \n",
        "\n",
        "# def modify_brightness_mask8(img,spotlight_intensity):\n",
        "#     image_shape = img.shape\n",
        "\n",
        "\n",
        "#      # Generate random threshold value between 0.2 and 0.8\n",
        "#     threshold = np.random.uniform(0.1,0.8)\n",
        "    \n",
        "#     # Generate random mask with threshold value\n",
        "#     mask_rand = np.random.rand(*image_shape) < threshold\n",
        "    \n",
        "#     # # Apply mask to image\n",
        "#     # masked_image = np.where(mask_rand, x_test[i], 0)\n",
        "\n",
        "#     img_mod= ((mask_rand*10)+1)*img\n",
        "\n",
        "#     return img_mod\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Circular mask**"
      ],
      "metadata": {
        "id": "E426kSRw36yS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtEnci8_AB2D"
      },
      "outputs": [],
      "source": [
        "# # circular mask \n",
        "\n",
        "# def modify_brightness_mask6(img, spotlight_intensity):\n",
        "\n",
        "    \n",
        "#     # Generate random circle \n",
        "#     cx = np.random.randint(4, 24)\n",
        "#     cy = np.random.randint(4, 24)\n",
        "#     r = np.random.randint(4,12)\n",
        "\n",
        "#     # create a mask \n",
        "#     mask_circ = np.zeros_like(img)\n",
        "#     y, x = np.ogrid[-cx:img.shape[0]-cx, -cy:img.shape[1]-cy] # adjust size of mask to match image\n",
        "#     mask_circ[(x**2 + y**2) <= r**2] = 1\n",
        "\n",
        "#     # Apply the mask to the image\n",
        "#     img_mod2 = img.copy()\n",
        "#     masked_img_circ = ((mask_circ * spotlight_intensity) + 1) * img_mod2\n",
        "\n",
        "#     return masked_img_circ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create a movie with masked images for the testing the model**"
      ],
      "metadata": {
        "id": "CchQ9B0Y4DcD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Condition1: A movie with the mask being generated for the last 5 frames**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MmcMiBE14Pw7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FDPsu4-PnqF"
      },
      "outputs": [],
      "source": [
        "# # Condition 1: Create a movie with the mask being generated for the last 5 frames \n",
        "# def create_movie_with_mask_last(data, labels, repeats, mask_frames, spotlight_intensity):\n",
        "#     n_samples, img_height, img_width = data.shape\n",
        "#     movie_data = np.zeros((n_samples, repeats, img_height, img_width, 1), dtype=np.float32)\n",
        "#     movie_labels = np.zeros((n_samples, num_classes), dtype=int)\n",
        "#     mask_frames_start = repeats - mask_frames\n",
        "#     for i in range(n_samples):\n",
        "#         # inverted_data=255-data[i]\n",
        "#         # increase the brightness of the digit\n",
        "#         # BK_int=10\n",
        "#         # D_int=200\n",
        "#         # brighter_data=np.clip(data[i]+D_int,0,255)\n",
        "#         # brighter_data[data[i]==0]=BK_int\n",
        "#         mask = None\n",
        "#         for j in range(repeats):\n",
        "#             if mask_frames_start <= j < repeats:\n",
        "#                 if mask is None:\n",
        "#                     mask = modify_brightness_mask7(data[i], spotlight_intensity)\n",
        "#                 movie_data[i, j, :, :, 0] = mask\n",
        "#             else:\n",
        "#                 movie_data[i, j, :, :, 0] = data[i]\n",
        "\n",
        "#         movie_labels[i] = labels[i]\n",
        "\n",
        "#     return movie_data, movie_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Condition2: A movie with the mask being generated for 5 consecutive frames/the starting frame of the mask is different for each movie**"
      ],
      "metadata": {
        "id": "SaJ3dNH-4d62"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KrW0wLO7kZ-"
      },
      "outputs": [],
      "source": [
        "# Condition 2: Create a movie with the mask being generated seperately for each of the 5 consecutive frames ( to keep the mask and brightness the same for 5 frames)\n",
        "import time\n",
        "\n",
        "def create_movie_with_mask(data, labels, repeats, mask_frames, spotlight_intensity):\n",
        "    n_samples, img_height, img_width = data.shape\n",
        "    movie_data = np.zeros((n_samples, repeats, img_height, img_width, 1), dtype=np.float32)\n",
        "    movie_labels = np.zeros((n_samples, num_classes), dtype=int)\n",
        "    category_labels = np.zeros(n_samples, dtype=int)\n",
        "    num_categories = repeats - mask_frames + 1\n",
        "    \n",
        "    for i in range(n_samples):\n",
        "        # Choose a random starting frame for this sample\n",
        "        start_frame = np.random.randint(0, repeats - mask_frames + 1)\n",
        "        category_labels[i] = start_frame\n",
        "        \n",
        "        # Create a mask for this sample\n",
        "        mask_start = np.random.randint(0, repeats - mask_frames + 1)\n",
        "        mask = None\n",
        "        for j in range(repeats):\n",
        "            if j >= mask_start and j < mask_start + mask_frames:\n",
        "                if mask is None:\n",
        "                    mask = modify_brightness_mask7(data[i], spotlight_intensity)\n",
        "                movie_data[i, j, :, :, 0] = mask\n",
        "            else:\n",
        "                movie_data[i, j, :, :, 0] = data[i]\n",
        "        \n",
        "        movie_labels[i] = labels[i]\n",
        "    \n",
        "    return movie_data, movie_labels, category_labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train Dataset with mask**\n",
        "\n"
      ],
      "metadata": {
        "id": "KRGZkGoL_3re"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMMkg1SQSWPr"
      },
      "outputs": [],
      "source": [
        "# Masked images for train dataset: to have masked images for the last 5 five frames (Train Dataset)\n",
        "# # for shadow divide it by something\n",
        "# spotlight=10000\n",
        "# mask_frames=3\n",
        "# repeats=20\n",
        "# x_train_mask_movie, movie_labels_mask_train, category_labels=create_movie_with_mask(x_train,y_train, repeats,mask_frames,spotlight)\n",
        "# # reshape\n",
        "# x_train_mask_movie_sq=np.squeeze(x_train_mask_movie, axis=-1)\n",
        "# x_train_mask_movie_reshaped=np.transpose(x_train_mask_movie_sq, (0,2,3,1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Test Dataset with mask**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WwbmdF9qAF-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Augmented Data/Gaussian Noise**"
      ],
      "metadata": {
        "id": "7f50uHDWAj-Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sK2wAYtXPuqu"
      },
      "outputs": [],
      "source": [
        "# DO NOT RUN THIS: ## to have masked images for the last 5 five frames (Test Dataset)-Augmented data \n",
        "# for shadow divide it by something\n",
        "# spotlight=2\n",
        "# mask_frames=3\n",
        "# repeats=20\n",
        "# x_test_mask_movie, movie_labels_mask_test, category_labels=create_movie_with_mask(x_test_aug,y_test_aug, repeats,mask_frames,spotlight)\n",
        "# # reshape\n",
        "# x_test_mask_movie_sq=np.squeeze(x_test_mask_movie, axis=-1)\n",
        "# x_test_mask_movie_reshaped=np.transpose(x_test_mask_movie_sq, (0,2,3,1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data without Gaussian Noise**"
      ],
      "metadata": {
        "id": "xJBbyl8CArNK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wa30rWoOcKAz"
      },
      "outputs": [],
      "source": [
        "## to have masked images for the last 5 five frames (Test Dataset)\n",
        "# for shadow divide it by something\n",
        "spotlight=2\n",
        "mask_frames=6\n",
        "repeats=20\n",
        "x_test_mask_movie, movie_labels_mask_test, category_labels=create_movie_with_mask(x_test,y_test, repeats,mask_frames,spotlight)\n",
        "# reshape\n",
        "x_test_mask_movie_sq=np.squeeze(x_test_mask_movie, axis=-1)\n",
        "x_test_mask_movie_reshaped=np.transpose(x_test_mask_movie_sq, (0,2,3,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoALWYrBt1xW"
      },
      "outputs": [],
      "source": [
        "## test dataset (labels)\n",
        "movie_labels_mask_test_frames=np.repeat(movie_labels_mask_test,repeats,axis=0)\n",
        "## train dataset (labels)\n",
        "# movie_labels_mask_train_frames=np.repeat(movie_labels_mask_train,repeats,axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3t42hHxQKYu"
      },
      "outputs": [],
      "source": [
        "# assuming x_test_mask_movie[1] is your input array ( test dataset ) for CNN model \n",
        "x_test_mask_movie_reshaped = np.transpose(x_test_mask_movie, (0,2,3,1,4))\n",
        "x_test_mask_movie_reshaped = np.squeeze(x_test_mask_movie_reshaped)  # remove the last singleton dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dnVZxZzsznq"
      },
      "outputs": [],
      "source": [
        "y_test_frames = np.repeat(y_test,repeats, axis=0)\n",
        "y_train_frames=np.repeat(y_train,repeats, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualize Train Dataset-with mask**"
      ],
      "metadata": {
        "id": "vqrl5z3BA8qU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOSpAsg6AEVr"
      },
      "outputs": [],
      "source": [
        "# Function to update the frames in the animation ( initial test data )\n",
        "# def update(i):\n",
        "#     im.set_array(x_train_mask_movie_sq[movie_index, i, :, :])\n",
        "#     frame_label = str(np.argmax(y_train_frames[movie_index * repeats + i]))\n",
        "#     ax.set_title(f\"Frame {i+1}, True label: {frame_label}\")\n",
        "#     return [im]\n",
        "\n",
        "# # Choose which movie in the dataset to visualize\n",
        "# movie_index =5\n",
        "\n",
        "# # True label \n",
        "# true_label=str(np.argmax(movie_labels_mask_train_frames[movie_index]))\n",
        "\n",
        "# # Create the initial plot\n",
        "# fig, ax = plt.subplots()\n",
        "# im = ax.imshow(x_train_mask_movie[movie_index, 0, :, :, 0],interpolation='none')\n",
        "# # plt.axis('off')\n",
        "\n",
        "# # set the title with the true label \n",
        "# ax.set_title(f\"True label: {true_label}\")\n",
        "\n",
        "# # Create the animation\n",
        "# ani = FuncAnimation(fig, update, frames=20, interval=200 , blit=True)\n",
        "\n",
        "# # Display the animation\n",
        "# HTML(ani.to_jshtml())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualize Test Dataset with mask**\n"
      ],
      "metadata": {
        "id": "N8coG4ybA7Rj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K1wzG-2P8K6"
      },
      "outputs": [],
      "source": [
        "# Function to update the frames in the animation ( initial test data )\n",
        "def update(i):\n",
        "    im.set_array(x_test_mask_movie_sq[movie_index, i, :, :])\n",
        "    frame_label = str(np.argmax(y_test_frames[movie_index * repeats + i]))\n",
        "    ax.set_title(f\"Frame {i+1}, True label: {frame_label}\")\n",
        "    return [im]\n",
        "\n",
        "# Choose which movie in the dataset to visualize\n",
        "movie_index =1\n",
        "\n",
        "# True label \n",
        "true_label=str(np.argmax(movie_labels_mask_test_frames[movie_index]))\n",
        "\n",
        "# Create the initial plot\n",
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(x_test_mask_movie[movie_index, 0, :, :, 0],interpolation='none')\n",
        "# plt.axis('off')\n",
        "\n",
        "# set the title with the true label \n",
        "ax.set_title(f\"True label: {true_label}\")\n",
        "\n",
        "# Create the animation\n",
        "ani = FuncAnimation(fig, update, frames=20, interval=200 , blit=True)\n",
        "\n",
        "# Display the animation\n",
        "HTML(ani.to_jshtml())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1K-frosrhrR"
      },
      "outputs": [],
      "source": [
        "# save animation as an MP4 video file\n",
        "writer=FFMpegWriter(fps=15,metadata=dict(artist='Me'),bitrate=1800)\n",
        "ani.save(\"animation_mask49.mp4\",writer=writer)\n",
        "animation_path = '/content/drive/MyDrive/PhD-Nilou/Project#3_DynamicCoding/Nilou_Codes/Animations/Test Dataset/animation_mask49.mp4'\n",
        "ani.save(animation_path, writer=writer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HSEBddFJg5R"
      },
      "outputs": [],
      "source": [
        "# Create a list of images to display in the animation\n",
        "num_frames=20\n",
        "movie_index=1\n",
        "frames = [x_test_mask_movie[movie_index, i, :, :, 0] for i in range(num_frames)]\n",
        "\n",
        "# Create the animation\n",
        "ani = animation.FuncAnimation(fig, func=lambda i: [ax.imshow(frames[i])], frames=num_frames, interval=200, blit=True)\n",
        "\n",
        "# Display the animation\n",
        "HTML(ani.to_jshtml())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2SovV9mq6Mk"
      },
      "outputs": [],
      "source": [
        "# save animation as an MP4 video file\n",
        "writer=FFMpegWriter(fps=15,metadata=dict(artist='Me'),bitrate=1800)\n",
        "ani.save(\"animation_mask48.mp4\",writer=writer)\n",
        "animation_path = '/content/drive/MyDrive/PhD-Nilou/Project#3_DynamicCoding/Nilou_Codes/Animations/Test Dataset/animation_mask48.mp4'\n",
        "ani.save(animation_path, writer=writer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ctOy7XPoIxf"
      },
      "outputs": [],
      "source": [
        "# the index of the sample you want to display\n",
        "sample_index =1\n",
        "# the number of frames in each image\n",
        "num_frames =20\n",
        "repeats=20\n",
        "fig, axs = plt.subplots(1, num_frames, figsize=(50, 30), subplot_kw={'aspect': 'equal'})\n",
        "\n",
        "# loop through the frames and display each one separately\n",
        "for i in range(num_frames):\n",
        "    frame_label = str(np.argmax(y_test_frames[sample_index * repeats + i]))\n",
        "    axs[i].set_title(f\"Frame {i+1}, True label: {frame_label}\")\n",
        "    axs[i].imshow(x_test_mask_movie[sample_index, i, :, :, 0])\n",
        "    \n",
        "    \n",
        "\n",
        "    # axs[i].axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Intensity of each pixel & Convolution Operation**"
      ],
      "metadata": {
        "id": "wPuVN2z7BQsw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ndpfk41u-mhs"
      },
      "outputs": [],
      "source": [
        "# Intensity of each pixel\n",
        "\n",
        "# sample_index=100\n",
        "# rows, cols=3,3\n",
        "\n",
        "# for i in range(rows):\n",
        "#     for j in range(cols):\n",
        "#         # Extract pixel intensities for the given sample and pixel coordinates\n",
        "#         pixel_intensities = x_test_mask_movie[sample_index, :, i, j, 0]\n",
        "\n",
        "#         # Create a new figure\n",
        "#         plt.figure()\n",
        "\n",
        "#         # Plot pixel intensities\n",
        "#         plt.plot(pixel_intensities)\n",
        "#         plt.xlabel('Frame')\n",
        "#         plt.ylabel('Intensity')\n",
        "#         plt.title(f'Intensity of pixel ({i}, {j}) over 20 frames')\n",
        "#         plt.grid(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5wdMbEr7EpS"
      },
      "outputs": [],
      "source": [
        "## Intensity of all pixels \n",
        "# sample_index=100\n",
        "# rows, cols=28,28\n",
        "\n",
        "# # Create a new figure with a specified size\n",
        "# fig, axes = plt.subplots(rows, cols, figsize=(cols, rows), dpi=100)\n",
        "\n",
        "# # Set overall title for the figure\n",
        "# fig.suptitle(f'Pixel intensities over 20 frames for sample {sample_index}')\n",
        "\n",
        "# for i in range(rows):\n",
        "#   for j in range(cols):\n",
        "      \n",
        "#       pixel_intensities= (x_test_mask_movie[100,: ,i, j, 0])\n",
        "#       conv_output = np.convolve(pixel_intensities, ky, mode='full')\n",
        "\n",
        "#         # Plot pixel intensities on the corresponding subplot\n",
        "#       ax = axes[i, j]\n",
        "#       ax.plot(conv_output)\n",
        "#       ax.set_xticks([])  # Hide x-axis ticks\n",
        "#       ax.set_yticks([])  # Hide y-axis ticks\n",
        "\n",
        "# # Adjust the space between subplots\n",
        "# plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "      \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LmWq3XsA7In"
      },
      "outputs": [],
      "source": [
        "# inputs = Input(shape=input_shape)\n",
        "# tau_y=0.02\n",
        "# n_y=0.03\n",
        "# gamma_value=0.07\n",
        "# tau_z=0.07\n",
        "# n_z=0.09\n",
        "# t = tf.range(0,inputs.shape[1],dtype='float32')\n",
        "# multFunc_tau=100;\n",
        "# multFunc_n=10;\n",
        "# multFunc_g=10;\n",
        "\n",
        "# ky = generate_simple_filter_multichan(np.array([tau_y],dtype=np.float32)*multFunc_tau, np.array([n_y],dtype=np.float32)*multFunc_n, t)\n",
        "# kz=generate_simple_filter_multichan(np.array([tau_z],dtype=np.float32)*multFunc_tau, np.array([n_z],dtype=np.float32)*multFunc_n, t)\n",
        "# kz=(gamma_value*multFunc_g*ky)+(1-gamma_value*multFunc_g)*kz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lMIiUMXCgmx"
      },
      "outputs": [],
      "source": [
        "# plt.plot( ky)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIjtOsOAF8nU"
      },
      "outputs": [],
      "source": [
        "# pixel_intensities = x_test_mask_movie[100, :, 0, 2, 0]\n",
        "# pixel_intensities.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqdYXMawGmJ2"
      },
      "outputs": [],
      "source": [
        "# if isinstance(ky, tf.Tensor):\n",
        "#     ky = ky.numpy()\n",
        "\n",
        "# if isinstance(kz, tf.Tensor):\n",
        "#     kz = kz.numpy()\n",
        "\n",
        "# ky=np.squeeze(ky)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxezB7DlFWwI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Squeeze ky to ensure it's a 1-dimensional array\n",
        "# ky = np.squeeze(ky)\n",
        "\n",
        "\n",
        "\n",
        "# pixel_intensities = x_test_mask_movie[100, :, 0, 2, 0]\n",
        "\n",
        "# conv_output = np.convolve(pixel_intensities, kz, mode='full')\n",
        "# plt.figure()\n",
        "# # plt.plot(ky*100, label='fast filter')\n",
        "# plt.plot(kz*100, label='slow filter')\n",
        "# plt.plot(pixel_intensities, label='Pixel intensities')\n",
        "# plt.plot(conv_output, label='Convolution output')\n",
        "# plt.xlabel('Frame')\n",
        "# plt.ylabel('Value')\n",
        "# plt.title('Convolution between pixel intensities and filter ky')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TH4xerc_QAS-"
      },
      "outputs": [],
      "source": [
        "# save animation as an MP4 video file\n",
        "writer=FFMpegWriter(fps=15,metadata=dict(artist='Me'),bitrate=1800)\n",
        "ani.save(\"animation_mask46.mp4\",writer=writer)\n",
        "animation_path = '/content/drive/MyDrive/PhD-Nilou/Project#3_DynamicCoding/Nilou_Codes/Animations/Test Dataset/animation_mask46.mp4'\n",
        "ani.save(animation_path, writer=writer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Size of test and train datasets**\n"
      ],
      "metadata": {
        "id": "8sWdsnZRBgO5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_CG44lZQUS_"
      },
      "outputs": [],
      "source": [
        "# # Plot a bar chart of the sizes\n",
        "\n",
        "train_size=x_train_movie.shape[0]\n",
        "test_size=x_test_mask_movie.shape[0]\n",
        "# train_repeated_size=x_train_repeated.shape[0]\n",
        "plt.bar(['Train', 'Test'], [train_size, test_size])\n",
        "plt.xlabel('Dataset')\n",
        "plt.ylabel('Size')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Models**"
      ],
      "metadata": {
        "id": "jGOhtphMBnqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CNN+PR Model for an image**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Frtqz8aSBy75"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOiYvBLAQeZm"
      },
      "outputs": [],
      "source": [
        "#CNN + PR Model ( Time independent )\n",
        "\n",
        "\n",
        "# from tensorflow.keras.regularizers import l1_l2\n",
        "# ## PR+ CNN Model we have 20 samples of 20 \n",
        "# input_shape = (20, 28, 28)\n",
        "\n",
        "# # define inputs tensor\n",
        "# inputs = Input(shape=input_shape)\n",
        "\n",
        "# chan1_n=1\n",
        "\n",
        "# # PR Architecture ( without time_distributed)- the code is modified so this would get an error\n",
        "# y1 = Reshape((inputs.shape [1],inputs.shape [-2]*inputs.shape [-1]))(inputs)\n",
        "# y1 = photoreceptor_DA_multichan_randinit(units=chan1_n,kernel_regularizer=l2(1e-4))(y1)\n",
        "# y1 = Reshape((1,inputs.shape[-2],inputs.shape[-1],chan1_n))(y1)\n",
        "# y1 = y1[:,0,:,:,:]  \n",
        "\n",
        "# y2=Activation('relu')(y1)\n",
        "# y2=Conv2D(32,kernel_size=(3,3), kernel_regularizer=l1_l2(l1=0.001, l2=0.001))(y2)\n",
        "# y2=(LayerNormalization())(y2)\n",
        "# y2=Activation('relu')(y2)\n",
        "# y2=MaxPooling2D(pool_size=(2,2))(y2)\n",
        "# y2=Conv2D(64,kernel_size=(3,3))(y2)\n",
        "# y2=LayerNormalization()(y2)\n",
        "# y2=Activation('relu')(y2)\n",
        "# y2=MaxPooling2D(pool_size=(2,2))(y2)\n",
        "# y2=Flatten()(y2)\n",
        "# y2=Dropout(0.5)(y2)\n",
        "# y2=Dense(num_classes,activation=\"softmax\")(y2)\n",
        "\n",
        "# # # Define PR+CNN model\n",
        "# model=tf.keras.Model(inputs=inputs,outputs=y2)\n",
        "\n",
        "# # Define the submodule consisting of layers 1 to 4\n",
        "# submodel_PR = tf.keras.Model(inputs=inputs, outputs=y1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5fVykWdQws2"
      },
      "outputs": [],
      "source": [
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mxqkZXeQyLG"
      },
      "outputs": [],
      "source": [
        "# from keras.utils.vis_utils import plot_model\n",
        "# model=model\n",
        "# plot_model(model,to_file='Model.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Comiling and training CNN+PR Model (time-independent)**"
      ],
      "metadata": {
        "id": "cVnLB_muCEvv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3bmZqJKQ2DH"
      },
      "outputs": [],
      "source": [
        "# # PR+CNN Time independent \n",
        "# n=100\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.00001), metrics=['accuracy'])\n",
        "# history=model.fit(x_train_movie_sq,y_train_aug,batch_size=128,epochs=n,validation_data=(x_test_mask_movie_sq,y_test_aug))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hcq88zU4RBcH"
      },
      "outputs": [],
      "source": [
        "# Results\n",
        "### PR + CNN Model (without time_distributed)\n",
        "\n",
        "# dict_hist = history.history # assuming you have already trained your model and stored the history object\n",
        "\n",
        "# list_ep = [i for i in range(1,n+1)]\n",
        "\n",
        "# plt.figure(figsize=(8,8))\n",
        "\n",
        "# plt.subplot(2, 1, 1) # adding a subplot for accuracy\n",
        "# plt.plot(list_ep, dict_hist['accuracy'],ls='--',label='accuracy-train_dataset')\n",
        "# plt.plot(list_ep, dict_hist['val_accuracy'],ls='--',label='accuracy-validation_dataset')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.subplot(2, 1, 2) # adding a subplot for loss\n",
        "# plt.plot(list_ep, dict_hist['loss'],ls='--',label='loss-train_dataset')\n",
        "# plt.plot(list_ep, dict_hist['val_loss'],ls='--',label='loss-validation_dataset')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Accuracy Plot for PR+CNN Model- Time independent**"
      ],
      "metadata": {
        "id": "aLZrBDdzCTQO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ehrSwxbRUQH"
      },
      "outputs": [],
      "source": [
        "# y_pred_new = submodel_PR.predict(x_test_mask_movie_sq)\n",
        "\n",
        "# sample_index = 1000  # Choose the index of the sample you want to visualize\n",
        "\n",
        "# plt.figure(figsize=(5, 5))\n",
        "# plt.imshow(y_pred_new[sample_index, :, :])\n",
        "# plt.title(f\"Output of the PR model - Sample {sample_index}\")\n",
        "# plt.colorbar()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PR+CNN Model- Time Distributed**"
      ],
      "metadata": {
        "id": "xOUOaIo-CcIm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfpS0uKJcH3F"
      },
      "outputs": [],
      "source": [
        "#CNN + PR Model (Time Distributed)\n",
        "\n",
        "\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "## PR+ CNN Model \n",
        "input_shape = (20, 28, 28)\n",
        "\n",
        "# define inputs tensor\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "chan1_n=20\n",
        "\n",
        "# PR Architecture \n",
        "y1 = Reshape((inputs.shape [1],inputs.shape [-2]*inputs.shape [-1]))(inputs)\n",
        "y1 = photoreceptor_DA_multichan_randinit(units=chan1_n,kernel_regularizer=l2(1e-4))(y1)\n",
        "y1 = Reshape((inputs.shape[1],inputs.shape[-2],inputs.shape[-1],chan1_n))(y1)\n",
        "# leave the first 5 frames \n",
        "y1 = y1[:,:,:,:,:]\n",
        "\n",
        "\n",
        "\n",
        "y2=TimeDistributed(keras.layers.Conv2D(32,kernel_size=(3,3), activation='relu'))(y1)\n",
        "y2=TimeDistributed(keras.layers.LayerNormalization())(y2)\n",
        "y2=TimeDistributed(keras.layers.MaxPooling2D(pool_size=(2,2)))(y2)\n",
        "y2=TimeDistributed(keras.layers.Conv2D(64,kernel_size=(3,3), activation='relu'))(y2)\n",
        "y2=TimeDistributed(keras.layers.LayerNormalization())(y2)\n",
        "y2=TimeDistributed(keras.layers.MaxPooling2D(pool_size=(2,2)))(y2)\n",
        "y2=TimeDistributed(keras.layers.Flatten())(y2)\n",
        "# y2=keras.layers.GlobalAveragePooling1D()(y2)\n",
        "y2=keras.layers.Dropout(0.5)(y2)\n",
        "y2=keras.layers.Dense(num_classes,activation=\"softmax\")(y2)\n",
        "\n",
        "\n",
        "# # Define PR+CNN model\n",
        "model2=tf.keras.Model(inputs=inputs,outputs=y2)\n",
        "\n",
        "# Define the submodule consisting of layers 1 to 4\n",
        "submodel_PR2 = tf.keras.Model(inputs=inputs, outputs=y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XiJtza8iPVA"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "model=model2\n",
        "plot_model(model2,to_file='Model1.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Generator: label/frame**"
      ],
      "metadata": {
        "id": "_8gbAGN6DUx9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZ4aQMW_T_32"
      },
      "outputs": [],
      "source": [
        "# 1. Verify data and labels alignment:\n",
        "\n",
        "# Assuming x_data and y_labels are your loaded data and labels\n",
        "num_samples = 5  # Number of random samples to visualize\n",
        "frame_index=0\n",
        "\n",
        "for _ in range(num_samples):\n",
        "    idx = np.random.randint(0, len(x_train_movie_sq))\n",
        "    movie = x_train_movie_sq[idx]\n",
        "    frame=movie[frame_index]\n",
        "    label = np.argmax(y_train[idx])\n",
        "\n",
        "        # Visualize the sample and its label (assuming 28x28 images)\n",
        "    plt.imshow(frame.reshape(28, 28))\n",
        "    plt.title(f\"Label: {label}\")\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jo0nadeBTIya"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_movie_frames(x, y, movie_index):\n",
        "    movie_data = x[movie_index]\n",
        "    movie_labels = np.argmax(y[movie_index])\n",
        "\n",
        "    frames = 20  # Change this to match the number of frames per movie\n",
        "\n",
        "    # Get the digit label for the whole movie sequence\n",
        "    digit_label = (movie_labels)\n",
        "\n",
        "    # Iterate through the frames and visualize them with their corresponding label\n",
        "    for i in range(frames):\n",
        "        frame = movie_data[i]\n",
        "\n",
        "        # Reshape digit to (28, 28) for visualization\n",
        "        frame = frame.reshape(28, 28)\n",
        "\n",
        "        plt.imshow(frame)\n",
        "        plt.title(f\"Frame {i+1}, Digit Label: {digit_label}\")\n",
        "        plt.show()\n",
        "\n",
        "# Call the function with the desired movie_index\n",
        "movie_index = 100  # Change this to the index of the movie you want to visualize\n",
        "visualize_movie_frames(x_test_mask_movie_sq, y_test, movie_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lS6IqAJG51y"
      },
      "outputs": [],
      "source": [
        "def movie_level_data_generator(x, y, batch_size):\n",
        "    n_samples = len(x)\n",
        "    indices = np.arange(n_samples)\n",
        "    frames = 20\n",
        "\n",
        "    while True:\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        for start in range(0, n_samples, batch_size):\n",
        "            end = min(start + batch_size, n_samples)\n",
        "            batch_idx = indices[start:end]\n",
        "\n",
        "            batch_x = np.array([x[i] for i in batch_idx])\n",
        "            batch_y = y[batch_idx]\n",
        "\n",
        "            # Repeat the labels for each frame in the movie\n",
        "            batch_y = np.repeat(batch_y, frames, axis=0)\n",
        "            \n",
        "            # Reshape the labels to match the model's output shape\n",
        "            batch_y = batch_y.reshape(-1, frames, 10)\n",
        "\n",
        "            # Print the frame and its corresponding label for each movie in the batch\n",
        "            for movie_idx, movie_data in enumerate(batch_x):\n",
        "                for i in range(frames):\n",
        "                    frame = movie_data[i, :, :]\n",
        "                    label = batch_y[movie_idx, i, :]\n",
        "\n",
        "                    digit = frame\n",
        "                    digit_label = np.argmax(label)\n",
        "\n",
        "                    # Reshape digit to (28, 28) for visualization\n",
        "                    digit = digit.reshape(28, 28)\n",
        "\n",
        "                    # plt.imshow(digit)\n",
        "                    # plt.title(f\"Movie {movie_idx+1}, Frame {i+1}, Digit Label: {digit_label}\")\n",
        "                    # plt.show()\n",
        "\n",
        "            yield batch_x, batch_y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fth88ReJwwCy"
      },
      "outputs": [],
      "source": [
        "train_generator = movie_level_data_generator(x_train_movie_sq, y_train, batch_size=16)\n",
        "x, y = next(train_generator)\n",
        "validation_generator = movie_level_data_generator(x_test_mask_movie_sq, y_test, batch_size=16)\n",
        "x, y = next(validation_generator)\n",
        "batch_size = 16\n",
        "steps_per_epoch = len(x_train_movie_sq) // batch_size\n",
        "validation_steps = len(x_test_mask_movie_sq) // batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Compiling and Training**"
      ],
      "metadata": {
        "id": "MDc8h6ayDtUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one label per movie\n",
        "# one label per digit \n",
        "\n",
        "# n=30\n",
        "\n",
        "# model2.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.00001), metrics=['accuracy'])\n",
        "# history2=model2.fit(x_train_movie_sq,y_train_aug,batch_size=128,epochs=n,validation_data=(x_test_mask_movie_sq,y_test_aug))"
      ],
      "metadata": {
        "id": "AbTcFqtQEpwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2-RBk4s57EH"
      },
      "outputs": [],
      "source": [
        "# one label per frame\n",
        "n = 10\n",
        "model2.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.00001), metrics=['accuracy'])\n",
        "history2 = model2.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=n, \n",
        "                      validation_data=validation_generator, validation_steps=validation_steps,\n",
        "                      verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Accuracy Plot (label/frame & label/movie)**"
      ],
      "metadata": {
        "id": "_952ehQ5D91C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XL-jqZVIdgh"
      },
      "outputs": [],
      "source": [
        "## Compare the accuracy of the CNN+PR model \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# convert to one-hot encoded \n",
        "y_test=np.argmax(y_test,axis=1)\n",
        "\n",
        "frames_to_exclude = 2\n",
        "frame_num = 20 - frames_to_exclude\n",
        "frame_accs = np.zeros(frame_num)\n",
        "num_movies_all_correct = np.zeros(frame_num)\n",
        "\n",
        "# Loop through each movie in the test set\n",
        "for movie_idx, movie_data in enumerate(x_test_mask_movie_sq):\n",
        "    \n",
        "    movie_labels = y_test[movie_idx]\n",
        "    movie_labels = np.repeat(movie_labels, frame_num+frames_to_exclude, axis=0)\n",
        "    movie_labels = movie_labels.reshape(frame_num+frames_to_exclude, -1)\n",
        "    \n",
        "    # Predict the labels for each frame in the movie\n",
        "    predicted_labels = model2.predict(movie_data.reshape(1, frame_num+frames_to_exclude, 28, 28))\n",
        "    \n",
        "    # Calculate the accuracy for each frame in the movie, starting from the frame after those to exclude\n",
        "    for frame_idx in range(frames_to_exclude, frame_num+frames_to_exclude):\n",
        "        frame_acc = (np.argmax(predicted_labels[0][frame_idx]) == (movie_labels[frame_idx]))\n",
        "        frame_accs[frame_idx - frames_to_exclude] += int(frame_acc)\n",
        "        \n",
        "        # Display the digit image and its predicted label\n",
        "\n",
        "        # Repeat the label for each frame in the movie\n",
        "        label = movie_labels[frame_idx]\n",
        "        # Print the accuracy for this frame\n",
        "        print(f\"Movie {movie_idx+1}, Frame {frame_idx} Accuracy: {frame_acc}, predicted_label: {np.argmax(predicted_labels[0][frame_idx])}, actual label: {(movie_labels[frame_idx])}\")\n",
        "\n",
        "\n",
        "                    # Check if all frames match the labels\n",
        "    all_correct = all(np.argmax(predicted_labels[0][i]) == (movie_labels[i]) for i in range(frames_to_exclude, 20))\n",
        "    if all_correct:\n",
        "        num_movies_all_correct += 1\n",
        "\n",
        "# Print the number of movies where all frames match the labels\n",
        "print(f\"Number of movies where all frames match the labels: {num_movies_all_correct[0]}\")\n",
        "    \n",
        "# Divide by the number of movies to get the mean accuracy for each frame\n",
        "frame_accs /= len(x_test_mask_movie_sq)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n1=10\n",
        "\n",
        "dict_hist = history2.history # assuming you have already trained your model and stored the history object\n",
        "\n",
        "list_ep = [i for i in range(1,n1+1)]\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "\n",
        "plt.subplot(2, 1, 1) # adding a subplot for accuracy\n",
        "plt.plot(list_ep, dict_hist['accuracy'],ls='--',label='accuracy-train_dataset')\n",
        "plt.plot(list_ep, dict_hist['val_accuracy'],ls='--',label='accuracy-validation_dataset')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 1, 2) # adding a subplot for loss\n",
        "plt.plot(list_ep, dict_hist['loss'],ls='--',label='loss-train_dataset')\n",
        "plt.plot(list_ep, dict_hist['val_loss'],ls='--',label='loss-validation_dataset')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xlLg59zODH00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Visualize Predicted Labels**"
      ],
      "metadata": {
        "id": "g1Ek2mhjET-6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNKTK_A4JbVM"
      },
      "outputs": [],
      "source": [
        "# Choose a movie index to plot its frames\n",
        "movie_idx = 9999\n",
        "\n",
        "# Get the data and labels for the chosen movie\n",
        "movie_data = x_test_mask_movie_sq[movie_idx]\n",
        "movie_labels = y_test[movie_idx]\n",
        "\n",
        "# Repeat the labels for each frame in the movie\n",
        "frame_num = 20\n",
        "movie_labels = np.repeat(movie_labels, frame_num, axis=0)\n",
        "movie_labels = movie_labels.reshape(frame_num, -1)\n",
        "\n",
        "# Predict the labels for each frame in the movie\n",
        "predicted_labels = model2.predict(movie_data.reshape(1, 20, 28, 28))\n",
        "\n",
        "# Loop through each frame in the movie and plot it with its predicted label\n",
        "for frame_idx in range(frame_num):\n",
        "    # Display the digit image and its predicted label\n",
        "    digit = movie_data[frame_idx, :, :]\n",
        "    digit_label = np.argmax(predicted_labels[0][frame_idx])\n",
        "    digit = digit.reshape(28, 28)\n",
        "    plt.imshow(digit)\n",
        "    plt.title(f\"Movie {movie_idx+1}, Frame {frame_idx+1}, Digit Label: {digit_label}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bORNlxpn5OYj"
      },
      "outputs": [],
      "source": [
        "# Actual digit vs predicted image \n",
        "movie_idx = 9199\n",
        "# the number of frames in each image\n",
        "num_frames =18\n",
        "\n",
        "# Get the data and labels for the chosen movie\n",
        "movie_data = x_test_mask_movie_sq[movie_idx]\n",
        "movie_labels = y_test[movie_idx]\n",
        "\n",
        "# Repeat the labels for each frame in the movie\n",
        "frame_num = 18\n",
        "movie_labels = np.repeat(movie_labels, frame_num, axis=0)\n",
        "movie_labels = movie_labels.reshape(frame_num, -1)\n",
        "\n",
        "# Predict the labels for each frame in the movie\n",
        "predicted_labels = model2.predict(movie_data.reshape(1, 20, 28, 28))\n",
        "\n",
        "fig, axs = plt.subplots(1, frame_num , figsize=(100, 30), subplot_kw={'aspect': 'equal'})\n",
        "# loop through the frames and display each one separately\n",
        "for i in range(frame_num):\n",
        "    digit = movie_data[i+2, :, :]\n",
        "    digit_label = np.argmax(predicted_labels[0][i+2])\n",
        "    digit = digit.reshape(28, 28)\n",
        "    axs[i].imshow(digit)\n",
        "    axs[i].set_title(f\"Movie {movie_idx+1}, Frame {i+3}, Digit Label: {digit_label}\")\n",
        "    axs[i].axis('off')\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "plt.show()\n",
        "   \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Input to the mode**"
      ],
      "metadata": {
        "id": "CYcxaEw4FAu7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLqLxwgblgmB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4g8CfmHwZG9"
      },
      "outputs": [],
      "source": [
        "### Input \n",
        "# the index of the sample you want to display\n",
        "sample_index = 9199\n",
        "# the number of frames in each image\n",
        "num_frames = 20\n",
        "\n",
        "fig, axs = plt.subplots(1, num_frames, figsize=(50, 30), subplot_kw={'aspect': 'equal'})\n",
        "\n",
        "# loop through the frames and display each one separately\n",
        "for i in range(num_frames):\n",
        "    axs[i].imshow(x_test_mask_movie[sample_index, i, :, :])\n",
        "    axs[i].set_title(f\"Movie {sample_index + 1}, Frame {i + 1}\")\n",
        "    axs[i].axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Output of PR Model**"
      ],
      "metadata": {
        "id": "zZdPRpsRFICT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3fRJq9Cdatl"
      },
      "outputs": [],
      "source": [
        "# ## output of the PR Model \n",
        "# # Check the output of PR ( time series )\n",
        "# output=submodel_PR2.predict(x_test_mask_movie_sq)\n",
        "\n",
        "# # the index of the sample you want to display\n",
        "# sample_index = 6789\n",
        "# # the number of frames in each image\n",
        "# num_frames = 20\n",
        "\n",
        "# fig, axs = plt.subplots(1, num_frames, figsize=(50, 30), subplot_kw={'aspect': 'equal'})\n",
        "\n",
        "# # loop through the frames and display each one separately\n",
        "# for i in range(num_frames):\n",
        "#     axs[i].imshow(output[sample_index, i, :, :,0])\n",
        "#     axs[i].set_title(f\"Movie {sample_index + 1}, Frame {i + 1}\")\n",
        "#     axs[i].axis('off')\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CNN Model- Time independent**"
      ],
      "metadata": {
        "id": "20DcMIeLFOtJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVVwIFeX6aZj"
      },
      "outputs": [],
      "source": [
        "# Model 1: Define CNN Model for a movie ( CNN_input shape= 28,28,20) (time independent )\n",
        "model1=keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape_2),\n",
        "        keras.layers.Conv2D(32,kernel_size=(3,3)),\n",
        "        keras.layers.LayerNormalization(),\n",
        "        keras.layers.Activation('relu'),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "        keras.layers.Conv2D(64,kernel_size=(3,3)),\n",
        "        keras.layers.LayerNormalization(),\n",
        "        keras.layers.Activation('relu'),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(num_classes,activation=\"softmax\")\n",
        "    ]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66hwxr2z_X5w"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "model=model1\n",
        "plot_model(model1,to_file='Model1.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Compiling and Training**"
      ],
      "metadata": {
        "id": "Dnd2LfeVFdd0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptfFWJgA62N2"
      },
      "outputs": [],
      "source": [
        "# # # compile and train the model # 1 (CNN model for a movie)\n",
        "# n1=100\n",
        "# model1.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.00001),metrics=['accuracy'])\n",
        "# history1=model1.fit(x_train_movie_reshaped,y_train_aug,batch_size=128,epochs=n1,validation_data=(x_test_mask_movie_reshaped,y_test_aug))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Accuracy Plot**"
      ],
      "metadata": {
        "id": "zP2iV_5zFnv-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7GQNRU4-_ST"
      },
      "outputs": [],
      "source": [
        "\n",
        "# dict_hist = history1.history # assuming you have already trained your model and stored the history object\n",
        "\n",
        "# list_ep = [i for i in range(1,n1+1)]\n",
        "\n",
        "# plt.figure(figsize=(8,8))\n",
        "\n",
        "# plt.subplot(2, 1, 1) # adding a subplot for accuracy\n",
        "# plt.plot(list_ep, dict_hist['accuracy'],ls='--',label='accuracy-train_dataset')\n",
        "# plt.plot(list_ep, dict_hist['val_accuracy'],ls='--',label='accuracy-validation_dataset')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.subplot(2, 1, 2) # adding a subplot for loss\n",
        "# plt.plot(list_ep, dict_hist['loss'],ls='--',label='loss-train_dataset')\n",
        "# plt.plot(list_ep, dict_hist['val_loss'],ls='--',label='loss-validation_dataset')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CNN Model- Time Distributed**"
      ],
      "metadata": {
        "id": "DmC5MaBLF1MA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgn7yndHXDqm"
      },
      "outputs": [],
      "source": [
        "## Modified CNN model for a sequence of images/movies: Model 3 ( CNN Time Distributed)\n",
        "input_shape = (28, 28, 1)\n",
        "num_frames=20\n",
        "\n",
        "model3=keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(num_frames, input_shape[0], input_shape[1],1)),\n",
        "        TimeDistributed(keras.layers.Conv2D(32,kernel_size=(3,3), activation='relu')),\n",
        "        TimeDistributed(keras.layers.LayerNormalization()),\n",
        "        TimeDistributed(keras.layers.MaxPooling2D(pool_size=(2,2))),\n",
        "        TimeDistributed(keras.layers.Conv2D(64,kernel_size=(3,3), activation='relu')),\n",
        "        TimeDistributed(keras.layers.LayerNormalization()),\n",
        "        TimeDistributed(keras.layers.MaxPooling2D(pool_size=(2,2))),\n",
        "        TimeDistributed(keras.layers.Flatten()),\n",
        "        # keras.layers.GlobalAveragePooling1D(),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(num_classes,activation=\"softmax\")\n",
        "\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRqSUlelxIXA"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "model=model3\n",
        "plot_model(model3,to_file='Model3.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Compiling and Training**"
      ],
      "metadata": {
        "id": "CioJfeXrGHWI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogBvgWiAXFtz"
      },
      "outputs": [],
      "source": [
        "# Compile and train model 3 ( label/movie)\n",
        "# n1=30\n",
        "# model3.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.00001),metrics=['accuracy'])\n",
        "# history3=model3.fit(x_train_movie,y_train_aug,batch_size=128,epochs=n1,validation_data=(x_test_mask_movie,y_test_aug))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLXOqXjwHtJf"
      },
      "outputs": [],
      "source": [
        "# Label/frame\n",
        "n = 10\n",
        "model3.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.00001), metrics=['accuracy'])\n",
        "history3 = model3.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=n, \n",
        "                      validation_data=validation_generator, validation_steps=validation_steps,\n",
        "                      verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Accuracy Plot** *italicized text*"
      ],
      "metadata": {
        "id": "VV7gZDMSGS_a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "majpBH-UJvQT"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "frame_num=20\n",
        "num_movies_all_correct=np.zeros(20)\n",
        "frame_accs=np.zeros(20)\n",
        "mismatched_movies=[]\n",
        "# Loop through each movie in the test set\n",
        "for movie_idx, movie_data in enumerate(x_test_mask_movie_sq):\n",
        "    \n",
        "    movie_labels = (y_test[movie_idx])\n",
        "    movie_labels = np.repeat(movie_labels, frame_num, axis=0)\n",
        "    movie_labels = movie_labels.reshape(frame_num, -1)\n",
        "    \n",
        "    # Predict the labels for each frame in the movieslack\n",
        "    \n",
        "    predicted_labels = model3.predict(movie_data.reshape(1, 20, 28, 28))\n",
        "    \n",
        "    # Calculate the accuracy for each frame in the movie\n",
        "    mismatch_found = False\n",
        "    for frame_idx in range(20):\n",
        "        frame_acc = (np.argmax(predicted_labels[0][frame_idx]) == (movie_labels[frame_idx]))\n",
        "        # eliminate the first frame \n",
        "        frame_accs[frame_idx] += (frame_acc)\n",
        "        \n",
        "        # Display the digit image and its predicted label\n",
        "\n",
        "        # Repeat the label for each frame in the movie\n",
        "        label = movie_labels[frame_idx]\n",
        "        # Print the accuracy for this frame\n",
        "        # print(f\"Movie {movie_idx+1}, Frame {frame_idx+1} Accuracy: {(frame_acc)}\")\n",
        "        print(f\"Movie {movie_idx+1}, Frame {frame_idx+1} Accuracy: {(frame_acc)},predicted_label:{np.argmax(predicted_labels[0][frame_idx])}, actual label:{(movie_labels[frame_idx])}\")\n",
        "        # digit = movie_data[frame_idx, :, :]\n",
        "        # digit_label = np.argmax(predicted_labels[0][frame_idx])\n",
        "        # digit = digit.reshape(28, 28)\n",
        "        # plt.imshow(digit)\n",
        "        # plt.title(f\"Frame {frame_idx+1}, Digit Label: {digit_label}\")\n",
        "        # plt.show()\n",
        "\n",
        "    # if mismatch_found:\n",
        "    #    mismatched_movies.append(movie_idx)\n",
        "    # Check if all frames match the labels\n",
        "\n",
        "    all_correct = all(np.argmax(predicted_labels[0][i]) == (movie_labels[i]) for i in range(1, 20))\n",
        "    if all_correct:\n",
        "        num_movies_all_correct += 1\n",
        "\n",
        "# Print the number of movies where all frames match the labels\n",
        "print(f\"Number of movies where all frames match the labels: {num_movies_all_correct[0]}\")\n",
        "    \n",
        "# Divide by the number of movies to get the mean accuracy for each frame\n",
        "frame_accs /= len(x_test_mask_movie_sq)\n",
        "\n",
        "# Print the mean accuracy for each frame\n",
        "# for frame_idx in range(20):\n",
        "#     print(f\"Frame {frame_idx+1} Accuracy: {frame_accs[frame_idx]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8qE7IwtaM0A"
      },
      "outputs": [],
      "source": [
        "n1=10\n",
        "dict_hist = history3.history # assuming you have already trained your model and stored the history object\n",
        "\n",
        "list_ep = [i for i in range(1,n1+1)]\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "\n",
        "plt.subplot(2, 1, 1) # adding a subplot for accuracy\n",
        "plt.plot(list_ep, dict_hist['accuracy'],ls='--',label='accuracy-train_dataset')\n",
        "plt.plot(list_ep, dict_hist['val_accuracy'],ls='--',label='accuracy-validation_dataset')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 1, 2) # adding a subplot for loss\n",
        "plt.plot(list_ep, dict_hist['loss'],ls='--',label='loss-train_dataset')\n",
        "plt.plot(list_ep, dict_hist['val_loss'],ls='--',label='loss-validation_dataset')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Visualize Predicted Labels**"
      ],
      "metadata": {
        "id": "8PN_8SLMG2Wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a movie index to plot its frames\n",
        "movie_idx =9198\n",
        "\n",
        "# Get the data and labels for the chosen movie\n",
        "movie_data = x_test_mask_movie_sq[movie_idx]\n",
        "movie_labels = y_test[movie_idx]\n",
        "\n",
        "# Repeat the labels for each frame in the movie ( the first frame is eliminated )\n",
        "frame_num = 20\n",
        "movie_labels = np.repeat(movie_labels, frame_num, axis=0)\n",
        "movie_labels = movie_labels.reshape(frame_num, -1)\n",
        "\n",
        "# Predict the labels for each frame in the movie\n",
        "predicted_labels = model3.predict(movie_data.reshape(1, 20, 28, 28))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(1, num_frames, figsize=(100, 30), subplot_kw={'aspect': 'equal'})\n",
        "# loop through the frames and display each one separately\n",
        "for i in range(num_frames):\n",
        "    digit = movie_data[i, :, :]\n",
        "    digit_label = np.argmax(predicted_labels[0][i])\n",
        "    digit = digit.reshape(28, 28)\n",
        "    axs[i].imshow(digit)\n",
        "    axs[i].set_title(f\"Movie {movie_idx+1}, Frame {i+1}, Digit Label: {digit_label}\")\n",
        "    axs[i].axis('off')\n",
        "   \n",
        "\n",
        "\n",
        "plt.show()\n",
        "# # Loop through each frame in the movie and plot it with its predicted label\n",
        "# for frame_idx in range(frame_num):\n",
        "#     # Display the digit image and its predicted label\n",
        "#     digit = movie_data[frame_idx, :, :]\n",
        "#     digit_label = np.argmax(predicted_labels[0][frame_idx])\n",
        "#     digit = digit.reshape(28, 28)\n",
        "#     plt.imshow(digit)\n",
        "#     plt.title(f\"Movie {movie_idx+1}, Frame {frame_idx+1}, Digit Label: {digit_label}\")\n",
        "#     plt.show()"
      ],
      "metadata": {
        "id": "W9CDQvZZGnIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Input \n",
        "# the index of the sample you want to display\n",
        "sample_index = 9198\n",
        "# the number of frames in each image\n",
        "num_frames = 20\n",
        "\n",
        "fig, axs = plt.subplots(1, num_frames, figsize=(50, 30), subplot_kw={'aspect': 'equal'})\n",
        "\n",
        "# loop through the frames and display each one separately\n",
        "for i in range(num_frames):\n",
        "    axs[i].imshow(x_test_mask_movie[sample_index, i, :, :])\n",
        "    axs[i].set_title(f\"Movie {sample_index + 1}, Frame {i + 1}\")\n",
        "    axs[i].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "txNH1NnBGsI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Manually updating the weight values of PR layer**"
      ],
      "metadata": {
        "id": "So5aemb7HJdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## get the weights for PR layer\n",
        "import re\n",
        "import os\n",
        "# get all the weights for all the layers \n",
        "def get_weightsDict(mdl):\n",
        "    names = [weight.name for layer in mdl.layers for weight in layer.weights]\n",
        "    weights = mdl.get_weights()\n",
        "    weights_dict = {}\n",
        "    for i in range(len(names)):\n",
        "        weight_name = names[i][:-2]\n",
        "        weights_dict[weight_name] = np.atleast_1d(np.squeeze(weights[i]))\n",
        "    return weights_dict, names \n",
        "\n",
        "# Get the weights for a specific layer \n",
        "def get_weightsOfLayer(weights_dict,layer_name):\n",
        "    weights_keys = list(weights_dict.keys())\n",
        "    rgb = re.compile(layer_name+'/')\n",
        "    layer_weight_names = list(filter(rgb.match, weights_keys))\n",
        "    weights_layer = {}\n",
        "    for l_name in layer_weight_names:\n",
        "        param_name_full = os.path.basename(l_name)\n",
        "        rgb = re.findall(r'[^0-9]',param_name_full)\n",
        "        rgb = ''.join(rgb)\n",
        "        if rgb[-1] == '_':\n",
        "            rgb = rgb[:-1]\n",
        "        param_name = rgb\n",
        "        weights_layer[param_name] = weights_dict[l_name]\n",
        "    return weights_layer"
      ],
      "metadata": {
        "id": "h5Tz8F5xHea6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pZ8L_CEHZjr"
      },
      "outputs": [],
      "source": [
        "# tauc=0.039\n",
        "# zeta_value=0.2\n",
        "# kappa_value=0.13\n",
        "# alpha_value=0.0667\n",
        "# beta_value=0\n",
        "# gamma=0.1\n",
        "# tauy=0.06\n",
        "# ny=0.1\n",
        "# tauz=0.09\n",
        "# nz=0.09\n",
        "# nc=0.16\n",
        "\n",
        "# new_weights=copy.deepcopy(old_weights)\n",
        "\n",
        "# # tauC \n",
        "# new_weights[weight_name_to_index[\"tauC\"]]=np.reshape((np.array([tauc],dtype=np.float32)),(1,1))\n",
        "                                      \n",
        "# # zeta \n",
        "# new_weights[weight_name_to_index[\"zeta\"]]=np.reshape((np.array([zeta_value],dtype=np.float32)),(1,1))\n",
        "\n",
        "# # zeta_multFac \n",
        "# # new_weights[2]=np.reshape((np.array([zeta_multFac_value],dtype=np.float32)),(1,1))\n",
        "\n",
        "# # kappa \n",
        "# new_weights[weight_name_to_index[\"kappa\"]]=np.reshape((np.array([kappa_value],dtype=np.float32)),(1,1))\n",
        "\n",
        "# # kappa_multFac \n",
        "# # new_weights[4]=np.reshape((np.array([kappa_multFac],dtype=np.float32)),(1,1))\n",
        "\n",
        "# # alpha \n",
        "# new_weights[weight_name_to_index[\"alpha\"]]=np.reshape((np.array([alpha_value],dtype=np.float32)),(1,1))\n",
        "\n",
        "# # alpha_multFac \n",
        "# # new_weights[6]=np.reshape((np.array([alpha_multFac],dtype=np.float32)),(1,1))\n",
        "\n",
        "# # beta \n",
        "# new_weights[weight_name_to_index[\"beta\"]]=np.reshape((np.array([beta_value],dtype=np.float32)),(1,1))\n",
        "\n",
        "# # beta_multFac \n",
        "# # new_weights[8]=np.reshape((np.array([beta_multFac],dtype=np.float32)),(1,1))\n",
        "\n",
        "# # gamma  \n",
        "# new_weights[weight_name_to_index[\"gamma\"]]=np.reshape((np.array([gamma],dtype=np.float32)),(1,1))\n",
        "\n",
        "# # gamma_multFac \n",
        "# # new_weights[10]=np.reshape((np.array([gamma_multFac],dtype=np.float32)),(1,1))\n",
        "\n",
        "# # tau_y \n",
        "# new_weights[weight_name_to_index[\"tauY\"]]=np.reshape((np.array([tauy],dtype=np.float32)),(1,1))\n",
        "\n",
        "# # # tau_y_multFac\n",
        "# # new_weights[12]=np.reshape((np.array([tau_y_multFac],dtype=np.float32)),(1,1))\n",
        "\n",
        "# # # n_y \n",
        "# new_weights[weight_name_to_index[\"nY\"]]=np.reshape((np.array([ny],dtype=np.float32)),(1,1))\n",
        "                                      \n",
        "# # # # n_y_multFac \n",
        "# # new_weights[13]=np.reshape((np.array([n_y_multFac],dtype=np.float32)),(1,1))\n",
        "\n",
        "# # # tauZ \n",
        "# new_weights[weight_name_to_index[\"tauZ\"]]=np.reshape((np.array([tauz],dtype=np.float32)),(1,1))\n",
        "          \n",
        "# # # tauZ_multFac \n",
        "# # new_weights[16]=np.reshape((np.array([tau_z_multFac],dtype=np.float32)),(1,1))\n",
        "\n",
        "# # # n_z \n",
        "# new_weights[weight_name_to_index[\"nZ\"]]=np.reshape((np.array([nz],dtype=np.float32)),(1,1))\n",
        "\n",
        "# # # n_z_multFac \n",
        "# # new_weights[18]=np.reshape((np.array([n_z_multFac],dtype=np.float32)),(1,1))\n",
        "\n",
        "# # # tauC_multFac \n",
        "# # new_weights[19]=np.reshape((np.array([tau_c_multFac],dtype=np.float32)),(1,1))                             \n",
        "\n",
        "# # # nc \n",
        "# new_weights[weight_name_to_index[\"nC\"]]=np.reshape((np.array([nc],dtype=np.float32)),(1,1)) \n",
        "\n",
        "# # # nc_multFac \n",
        "# # new_weights[19]=np.reshape((np.array([n_c_multFac],dtype=np.float32)),(1,1)) \n",
        "\n",
        "# ######### update the model here \n",
        "# submodel_PR.layers[2].set_weights(new_weights)\n",
        "\n",
        "# output=submodel_PR.predict(x_test_mask_movie_sq)\n",
        "\n",
        "# sample_index = 100  # Choose the index of the sample you want to visualize\n",
        "\n",
        "# plt.figure(figsize=(5, 5))\n",
        "# plt.imshow(output[sample_index, :, :])\n",
        "# plt.title(f\"Output of the PR model - Sample {sample_index}\")\n",
        "# plt.colorbar()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ri1OxVeKUTz"
      },
      "outputs": [],
      "source": [
        "# Weight values of PR Layer\n",
        "weights, names=get_weightsDict(model2)\n",
        "s=names[1]\n",
        "substring = s.split(\"/\")[0]\n",
        "layer_name=substring\n",
        "W_L=get_weightsOfLayer(weights,layer_name)\n",
        "print(W_L)\n",
        "weights = submodel_PR2.layers[2].get_weights()\n",
        "# print(weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Optimal Values for PR Parameters**"
      ],
      "metadata": {
        "id": "YEnIungwHwX_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjumNxqKIUdK"
      },
      "outputs": [],
      "source": [
        "for i in range(len(weights)):\n",
        "    print(f\"Weight {i} name: {submodel_PR2.layers[2].weights[i].name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU-kvRYkRpj2"
      },
      "outputs": [],
      "source": [
        "# create a dictionary that maps weight names to their indices \n",
        "weight_name_to_index={}\n",
        "\n",
        "weights = submodel_PR2.layers[2].get_weights()\n",
        "for i in range(len(weights)):\n",
        "    print(f\"Weight {i} name: {submodel_PR2.layers[2].weights[i].name}\")\n",
        "\n",
        "weight_names = []\n",
        "for i, weight in enumerate(weights):\n",
        "    weight_name = submodel_PR2.layers[2].weights[i].name\n",
        "    weight_name = weight_name.split(\"/\")[-1]  # Get the substring after the last slash\n",
        "    weight_name = weight_name.split(\":\")[0]  # Get the substring before the colon\n",
        "    weight_names.append(weight_name)\n",
        "\n",
        "for i, weight_name in enumerate(weight_names):\n",
        "  weight_name_to_index[weight_name]=i\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CynX9pHtSo-p"
      },
      "outputs": [],
      "source": [
        "def compute_rms_error(batch_image1,batch_image2):\n",
        "    assert batch_image1.shape[:1] == batch_image2.shape[:1], \"Input batches must have the same number of samples\"\n",
        "    # use the first frame \n",
        "    first_frames_image1 = batch_image1[:, 0]\n",
        "    error = np.square(first_frames_image1.astype(np.float64) - batch_image2.astype(np.float64))\n",
        "    rms_errors = np.sqrt(np.mean(error, axis=(1, 2)))\n",
        "\n",
        "    return rms_errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t36pagcbSFPf"
      },
      "outputs": [],
      "source": [
        "# Kz\n",
        "# import os\n",
        "# from concurrent.futures import ProcessPoolExecutor, as_completed,ThreadPoolExecutor\n",
        "# import numpy as np\n",
        "# import copy\n",
        "\n",
        "\n",
        "\n",
        "# # ranges of PR model parameters ( firstset )\n",
        "# # tauy_range= np.linspace(0.01, 0.06, 3)\n",
        "# # ny_range = np.linspace(0.00001, 0.1, 3)\n",
        "# # gamma_range=np.linspace(0.01, 0.1, 3)\n",
        "# # tauz_range= np.linspace(0.05, 0.09, 3)\n",
        "# # nz_range = np.linspace(0.01, 0.09, 3)\n",
        "\n",
        "# # # optimal values \n",
        "# # tauy=0.06\n",
        "# # gamma=0.1\n",
        "# # ny=0.1\n",
        "# # tauz=0.09\n",
        "# # nz=0.09\n",
        "# # tauc=0.01\n",
        "# # nc=0.05\n",
        "\n",
        "\n",
        "# # # optimal values \n",
        "# tauy=0.0199\n",
        "# gamma=0.1\n",
        "# ny=0.06\n",
        "# tauz=0.05\n",
        "# nz=0.06\n",
        "# tauc=0.01\n",
        "# nc=0.05\n",
        "\n",
        "\n",
        "# # optimal values \n",
        "# # tauy=0.06\n",
        "# # gamma=0.1\n",
        "# # ny=0.1\n",
        "# # tauz=0.09\n",
        "# # nz=0.09\n",
        "# # tauc=0.01\n",
        "# # nc=0.05\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # ranges of PR model parameters ( secondset )\n",
        "# zeta_range=np.linspace(0,0.2,4)\n",
        "# kappa_range=np.linspace(0,0.2,4)\n",
        "# alpha_range=np.linspace(0,0.2,4)\n",
        "# beta_range=np.linspace(0,0.2,4)\n",
        "\n",
        "# # optimal valuess\n",
        "# # zeta=0\n",
        "# # kappa=0.005\n",
        "# # alpha=0.1\n",
        "# # beta=0.001\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # create a matrix to store the RMS error (5D array)\n",
        "# # rms_errors = np.zeros((len(tauy_range), len(ny_range), len(gamma_range), len(tauz_range), len(nz_range), x_test_mask_movie_sq.shape[0]))\n",
        "# rms_errors = np.zeros((len(zeta_range),len(kappa_range),len(alpha_range),len(beta_range), x_test_mask_movie_sq.shape[0]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Loop through the range of parameters \n",
        "\n",
        "\n",
        "# # for i, tau_y in enumerate(tauy_range):\n",
        "# #     for j, n_y in enumerate(ny_range):\n",
        "# #         for k, gamma_value in enumerate(gamma_range):\n",
        "# #             for l, tau_z in enumerate(tauz_range):\n",
        "# #                 for m, n_z in enumerate(nz_range):\n",
        "\n",
        "# for p, zeta_value in enumerate(zeta_range):\n",
        "#     for q, kappa_value in enumerate(kappa_range):\n",
        "#         for r, alpha_value in enumerate (alpha_range):\n",
        "#             for s, beta_value in enumerate (beta_range):\n",
        "\n",
        "# ###### update the model here \n",
        "\n",
        "#                         old_weights=submodel_PR2.layers[2].get_weights()\n",
        "#                         new_weights=copy.deepcopy(old_weights)\n",
        "\n",
        "#                         # tauC \n",
        "#                         new_weights[weight_name_to_index[\"tauC\"]]=np.reshape((np.array([tauc],dtype=np.float32)),(1,1))\n",
        "                                      \n",
        "#                         # zeta \n",
        "#                         new_weights[weight_name_to_index[\"zeta\"]]=np.reshape((np.array([zeta_value],dtype=np.float32)),(1,1))\n",
        "\n",
        "#                       # zeta_multFac \n",
        "#                         # new_weights[2]=np.reshape((np.array([zeta_multFac_value],dtype=np.float32)),(1,1))\n",
        "\n",
        "#                       # kappa \n",
        "#                         new_weights[weight_name_to_index[\"kappa\"]]=np.reshape((np.array([kappa_value],dtype=np.float32)),(1,1))\n",
        "\n",
        "#                       # kappa_multFac \n",
        "#                         # new_weights[4]=np.reshape((np.array([kappa_multFac],dtype=np.float32)),(1,1))\n",
        "\n",
        "#                       # alpha \n",
        "#                         new_weights[weight_name_to_index[\"alpha\"]]=np.reshape((np.array([alpha_value],dtype=np.float32)),(1,1))\n",
        "\n",
        "#                         # alpha_multFac \n",
        "#                       # new_weights[6]=np.reshape((np.array([alpha_multFac],dtype=np.float32)),(1,1))\n",
        "\n",
        "#                       # beta \n",
        "#                         new_weights[weight_name_to_index[\"beta\"]]=np.reshape((np.array([beta_value],dtype=np.float32)),(1,1))\n",
        "\n",
        "#                     # beta_multFac \n",
        "#                       # new_weights[8]=np.reshape((np.array([beta_multFac],dtype=np.float32)),(1,1))\n",
        "\n",
        "#                       # gamma  \n",
        "#                         new_weights[weight_name_to_index[\"gamma\"]]=np.reshape((np.array([gamma],dtype=np.float32)),(1,1))\n",
        "\n",
        "#                   # gamma_multFac \n",
        "#                     # new_weights[10]=np.reshape((np.array([gamma_multFac],dtype=np.float32)),(1,1))\n",
        "\n",
        "#                       # tau_y \n",
        "#                         new_weights[weight_name_to_index[\"tauY\"]]=np.reshape((np.array([tauy],dtype=np.float32)),(1,1))\n",
        "\n",
        "#                   # # tau_y_multFac\n",
        "#                       # new_weights[12]=np.reshape((np.array([tau_y_multFac],dtype=np.float32)),(1,1))\n",
        "\n",
        "#                       # # n_y \n",
        "#                         new_weights[weight_name_to_index[\"nY\"]]=np.reshape((np.array([ny],dtype=np.float32)),(1,1))\n",
        "                                      \n",
        "#                         # # # n_y_multFac \n",
        "#                       # new_weights[13]=np.reshape((np.array([n_y_multFac],dtype=np.float32)),(1,1))\n",
        "\n",
        "#                       # # tauZ \n",
        "#                         new_weights[weight_name_to_index[\"tauZ\"]]=np.reshape((np.array([tauz],dtype=np.float32)),(1,1))\n",
        "          \n",
        "#                       # # tauZ_multFac \n",
        "#                         # new_weights[16]=np.reshape((np.array([tau_z_multFac],dtype=np.float32)),(1,1))\n",
        "\n",
        "#                         # # n_z \n",
        "#                         new_weights[weight_name_to_index[\"nZ\"]]=np.reshape((np.array([nz],dtype=np.float32)),(1,1))\n",
        "\n",
        "#                       # # n_z_multFac \n",
        "#                       # new_weights[18]=np.reshape((np.array([n_z_multFac],dtype=np.float32)),(1,1))\n",
        "\n",
        "#                         # # tauC_multFac \n",
        "#                       # new_weights[19]=np.reshape((np.array([tau_c_multFac],dtype=np.float32)),(1,1))                             \n",
        "\n",
        "#                       # # nc \n",
        "#                         new_weights[weight_name_to_index[\"nC\"]]=np.reshape((np.array([nc],dtype=np.float32)),(1,1)) \n",
        "\n",
        "#                         # # nc_multFac \n",
        "#                       # new_weights[19]=np.reshape((np.array([n_c_multFac],dtype=np.float32)),(1,1)) \n",
        "\n",
        "#     ######### update the model here \n",
        "#                         submodel_PR2.layers[2].set_weights(new_weights)\n",
        "\n",
        "#                         output=submodel_PR2.predict(x_test_mask_movie_sq)\n",
        "\n",
        "                                      \n",
        "\n",
        "#                         # get the output of photoreceptor \n",
        "#                         sample_index=100\n",
        "#                         plt.figure(figsize=(5, 5))\n",
        "#                         # onlu check the last frame \n",
        "#                         plt.imshow(output[sample_index,2, :, :])\n",
        "#                         # plt.title(f\"tau_y={tauy_range[i]:.3f}, n_y={ny_range[j]:.3f}, gamma={gamma_range[k]:.3f}, tau_z={tauz_range[l]:.3f}, n_z={nz_range[m]:.3f}\", fontsize=8)\n",
        "#                         plt.title(f\"zeta={zeta_range[p]:.3f},kappa={kappa_range[q]:.4f},alpha={alpha_range[r]:.4f},beta={beta_range[s]:.4f}\", fontsize=8)\n",
        "\n",
        "#                         # plt.colorbar()\n",
        "#                         # plt.show()\n",
        "#                         # save animation as an MP4 video file\n",
        "#                         # filename=f\"tau_y={tauy_range[i]:.3f}_n_y={ny_range[j]:.3f}_gamma={gamma_range[k]:.3f}_tau_z={tauz_range[l]:.3f}_n_z={nz_range[m]:.3f}.png\"\n",
        "#                         filename=f\"zeta={zeta_range[p]:.3f}_kappa={kappa_range[q]:.3f}_alpha={alpha_range[r]:.3f}_beta={beta_range[s]:.3f}.png\"\n",
        "#                         digits_path = '/content/drive/MyDrive/PhD-Nilou/Project#3_DynamicCoding/Nilou_Codes/Tests/Test_25/'\n",
        "#                       # Combine the digits_path with the filename\n",
        "#                         output_path = os.path.join(digits_path, filename)\n",
        "#                         plt.savefig(output_path, dpi=300)\n",
        "#                         plt.close()\n",
        "\n",
        "#                         # extract first frame of the onput\n",
        "#                         # first_frame_input=x_test_mask_movie_sq[0]\n",
        "\n",
        "#                       # compute RMS between the input and output \n",
        "#                         # Remove the last dimension of the output if it is (10000, 28, 28, 1)\n",
        "\n",
        "#                         # output = np.squeeze(output, axis=-1)\n",
        "\n",
        "#                         # rms_error=compute_rms_error(x_test_mask_movie_sq,output)\n",
        "#                         # # rms_errors[i, j, k, l, m,:] = rms_error\n",
        "#                         # rms_errors[p, q, r, s,:] = rms_error\n",
        "                              "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Find the min RMS value for each combination \n",
        "# min_rms_value = np.min(rms_errors)\n",
        "# print(min_rms_value)\n",
        "# min_rms_index = np.argmin(rms_errors)\n",
        "# print(min_rms_index)\n",
        "# min_rms_multi_index = np.unravel_index(min_rms_index, rms_errors.shape)\n",
        "# print(min_rms_multi_index)\n",
        "\n",
        "# # min_tau_y=min_rms_multi_index[0]\n",
        "# # min_n_y=min_rms_multi_index[1]\n",
        "# # min_gamma=min_rms_multi_index[2]\n",
        "# # min_tau_z=min_rms_multi_index[3]\n",
        "# # min_n_z=min_rms_multi_index[4]\n",
        "\n",
        "# min_zeta=min_rms_multi_index[0]\n",
        "# min_kappa=min_rms_multi_index[1]\n",
        "# min_alpha=min_rms_multi_index[2]\n",
        "# min_beta=min_rms_multi_index[3]\n",
        "\n",
        "# # min_tau_y = tauy_range[min_rms_multi_index[0]]\n",
        "# # min_n_y = ny_range[min_rms_multi_index[1]]\n",
        "# # min_gamma = gamma_range[min_rms_multi_index[2]]\n",
        "# # min_tau_z = tauz_range[min_rms_multi_index[3]]\n",
        "# # min_n_z = nz_range[min_rms_multi_index[4]]\n",
        "\n",
        "# min_zeta=zeta_range[min_rms_multi_index[0]]\n",
        "# min_kappa=kappa_range[min_rms_multi_index[1]]\n",
        "# min_alpha=alpha_range[min_rms_multi_index[2]]\n",
        "# min_beta=beta_range[min_rms_multi_index[3]]\n",
        "\n",
        "# print(f\"Minimum RMS found at:\")\n",
        "\n",
        "# # print(f\"tau_y: {min_tau_y}\")\n",
        "# # print(f\"n_y: {min_n_y}\")\n",
        "# # print(f\"gamma: {min_gamma}\")\n",
        "# # print(f\"tau_z: {min_tau_z}\")\n",
        "# # print(f\"n_z: {min_n_z}\")\n",
        "\n",
        "# print(f\"zeta: {min_zeta}\")\n",
        "# print(f\"kappa: {min_kappa}\")\n",
        "# print(f\"alpha: {min_alpha}\")\n",
        "# print(f\"beta: {min_beta}\")"
      ],
      "metadata": {
        "id": "8w9Ksg3cILbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ky and Kz Linear Filters**"
      ],
      "metadata": {
        "id": "RQ0ujTo1IBWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the filters \n",
        "def generate_simple_filter(tau,n,t):\n",
        "    t_rep = np.repeat(t[:,None],n.shape[0],axis=-1)\n",
        "    f = (t_rep**n[None,:])*np.exp(-t_rep/tau[None,:]); # functional form in paper\n",
        "    f = (f/tau**(n+1))/scipy_gamma(n+1) # normalize appropriately\n",
        "        # f = f/np.sum(f,axis=0)\n",
        "    return f"
      ],
      "metadata": {
        "id": "kOz36cIf1gw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_simple_filter_multichan(tau,n,t):\n",
        "    t_shape = t.shape[0]\n",
        "    t = tf.tile(t,tf.constant([tau.shape[-1]], tf.int32))\n",
        "    t = tf.reshape(t,(tau.shape[-1],t_shape))\n",
        "    t = tf.transpose(t)\n",
        "    f = (t**n[:,None])*tf.math.exp(-t/tau[:,None]) # functional form in paper\n",
        "    rgb = tau**(n+1)\n",
        "    f = (f/rgb[:,None])/tf.math.exp(tf.math.lgamma(n+1))[:,None] # normalize appropriately\n",
        "    # print(t.shape)\n",
        "    # print(n.shape)\n",
        "    # print(tau.shape)\n",
        "   \n",
        "    return f"
      ],
      "metadata": {
        "id": "ZuqikbqR1uOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Filters For All the Channels**"
      ],
      "metadata": {
        "id": "3vvlJL1pIXnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ky filter for each channel ( there are 20 channels )\n",
        "t = tf.range(0,inputs.shape[1],dtype='float32')\n",
        "\n",
        "\n",
        "# get the weight pf PR layer \n",
        "tau_values=W_L['tauY']*W_L['tauY_mulFac']\n",
        "n_values=W_L['nY']*W_L['nY_mulFac']\n",
        "\n",
        "\n",
        "for i in range(len(tau_values)):\n",
        "    tau = tau_values[i]\n",
        "    n = n_values[i]\n",
        "\n",
        "    # Generate filters using the current tau and n values\n",
        "    filters_random = generate_simple_filter_multichan(np.array([tau], dtype=np.float32), np.array([n], dtype=np.float32), t)\n",
        "\n",
        "    # Plot the filter with a label\n",
        "    plt.plot(filters_random[:, 0], label=f\"tauY = {tau:.4f}, nY = {n:.4f}, channel={i+1}\")\n",
        "\n",
        "# Set the title, x and y axis labels\n",
        "plt.title(\"Ky Linear Filter\", fontsize=30)\n",
        "plt.xlabel(\"Frame\", fontsize=20)\n",
        "plt.ylabel(\"Gain\", fontsize=20)\n",
        "\n",
        "# Get the current x-axis tick locations and round them to the nearest integer\n",
        "# Create an array of evenly spaced values from 0 to 20\n",
        "xticks = np.linspace(0, 20, 21)\n",
        "\n",
        "# Set the x-axis tick locations to the created array\n",
        "plt.xticks(xticks, xticks.astype(int))\n",
        "\n",
        "# Add a legend\n",
        "plt.legend(fontsize=12, loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O1euWmNAAVQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kz filter for each channel ( there are 20 channels )\n",
        "t = tf.range(0,inputs.shape[1],dtype='float32')\n",
        "\n",
        "\n",
        "# get the weight pf PR layer \n",
        "tauY_values=W_L['tauY']*W_L['tauY_mulFac']\n",
        "nY_values=W_L['nY']*W_L['nY_mulFac']\n",
        "nZ_values=W_L['nZ']*W_L['nZ_mulFac']\n",
        "tauZ_values=W_L['tauZ']*W_L['tauZ_mulFac']\n",
        "gamma_values=W_L['gamma']*W_L['gamma_mulFac']\n",
        "\n",
        "for i in range(len(tauY_values)):\n",
        "    tauY = tauY_values[i]\n",
        "    nY = nY_values[i]\n",
        "    tauZ=tauZ_values[i]\n",
        "    nZ=nZ_values[i]\n",
        "    gamma=gamma_values[i]\n",
        "\n",
        "        # Generate filters using the current tau and n values\n",
        "    ky =generate_simple_filter_multichan(np.array([tauY], dtype=np.float32), np.array([nY], dtype=np.float32), t)\n",
        "    kz=generate_simple_filter_multichan(np.array([tauZ], dtype=np.float32), np.array([nZ], dtype=np.float32), t)\n",
        "    kz=(gamma*ky)+(1-gamma)*kz\n",
        "\n",
        "    # Plot the filter with a label\n",
        "    plt.plot(kz[:, 0], label=f\"tauY = {tauY:.4f}, nY = {nY:.4f}, tauZ={tauZ:.4f},nZ={nZ:.4f}, gamma={gamma:.4f}, channel={i+1}\")\n",
        "\n",
        "# Set the title, x and y axis labels\n",
        "plt.title(\"Kz Linear Filter\", fontsize=30)\n",
        "plt.xlabel(\"Frame\", fontsize=20)\n",
        "plt.ylabel(\"Gain\", fontsize=20)\n",
        "# Get the current x-axis tick locations and round them to the nearest integer\n",
        "# Create an array of evenly spaced values from 0 to 20\n",
        "xticks = np.linspace(0, 20, 21)\n",
        "\n",
        "# Set the x-axis tick locations to the created array\n",
        "plt.xticks(xticks, xticks.astype(int))\n",
        "\n",
        "# Add a legend\n",
        "plt.legend(fontsize=12, loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "# Add a legend\n",
        "plt.legend(fontsize=12, loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QVpmt9HdCwPg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNMOQvl9B5OVX1oa31Lgg+A",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}